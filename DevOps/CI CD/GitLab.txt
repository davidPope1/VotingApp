CI/CD 

-CI = continuous integration / CD = continuous deployment 
-vom face un pipeline care ia un proiect simplu de website, ii da build, il testeaza si ii da deploy pe AWS 
-cu ajutoru ci/cd vom integra codu nostru si vom buildui o noua versiune(partea de CI) si ii vom da deploy(partea de CD)
-in timp ce facem asta, focusu nostru e pe automation ca sa eliminam munca repetitiva manuala 
-GitLab este o platforma DevOps care da provide la un wide range de feautures pt a menegiui intregul proces de software developing 
-include componente pt version control folosind Git, CI/CD, project management si inca cateva toate integrate intr-o singura aplicatie
-una dintre featurile originale ale GitLab este posibilitatea de a creea repo-uri git care sa stocheze codu pt multiple proiecte 
-componenta de ci/cd ne permite sa definim pipeline uri. Este ca un robot asistent care poate sa face automat task uri specifice pe un computer legate de building, testing si sa dea deploy la software, trebuie sa ii dam instructiunile necesare doar
-de fiecare data cand un developer scrie sau updateaza o parte din soft, GitLab ci/cd va compila softu sa se asigure ca e scris corect, va rula teste sa se asigure ca totu merge as expected, va creea o versiune ready to use a sfotului si ii da deploy pe un server, facandu-l dispobibil pt useri 
-deci dupa ce developeru a implementat un nou feauture, GitLab ci/cd lucreaza in backround sa scoata o noua versiune realeased 
-acest proces ajuta developeru si echipa sa sa depisteze erorile din timp, se asigura ca softu e mereu intr-un state ok si automatizeaza orice task-uri manuale, facand intregul proces de software development mai eficient si mai putin probabil sa aibe erori 

-facem un cont de GitLab free pe gitlab.com 
-facem un proiect la care bagam group name useru nostru -projects si project name test 
-dam click pe iconu din stanga sus care ne duce la o pagina cu toate projects urile noastre si dam click pe al nostru 
-dupa care dam click pe edit pe proiectu nostru si dam click pe WEB IDE unde mergem la settings la rotita si cautam whitespace si punem pe all prima setare 
-creeam un file nou in folderu TEST pe care il denumim .gitlab-ci.yml , trebuie sa fie exact asa denumirea 
-dupa in el scriem:

test:
  script: echo "Hello!"

-mergem la source control ca sa dam commit la schimbari, cu mesaju Added pipeline 
-ne intoarcem la pagina cu projectu si dam refresh si vedem ca avem commitu si vedem ca avem si failed pipeline
-dam click pe butonu rosu cu x si vedem ca trei sa ne verificam contu 
-apoi dam comit din nou in care punem doar Hello 2 si dam comit cu mesaju hello 2 si vedem ca acuma pipelineu e running 
-revenim pe web la test project si dam click pe bulinuta albastra sau verde din dreptul ultimului commit 
-vedem ca aici vom avea un Pipeline numit test pe care putem da click si vedem ca la final vedem ca scrie la final Hello 2 si comanda noastra $ echo "Hello 2" si vedem ca si job ul a trecut, Job succeeded

Pipeline 

-sa vedem ce este un pipeline 
-facem o analogie cu asamblarea unei masini intr o fabrica 
-ca sa producem o masina trebe sa urmam o serie de pasi: de ex, prima oara avem nevoie de un sasiu, apoi instalam motoru si dupa rotile si asamd
-sunt cateva caracteristici ale unei linii de asamblari ale unei masini
-etapele de mai sus, sunt defapt o serie de pasi care trb facuti intr-o ordine anume. Nu putem incepe sa punem rotile daca nu avem un sasiu si un motor 
-in plus, pasii astia sunt conectati. Rezultatul, sau output ul de la un pas este input-ul pt pasul urmator. Unii pasi pot fi facuti in paralel
-de ex, putem monta toate cele 4 roti in acelasi timp fara sa afectam rezultatul. Normal ca mult mai multi pasi sunt necesari pt a construi masina finita 
-nu doar asamblarea masinii e importanta, dar inainte ca masina sa poata iesi din fabrica, trebuie testata sa se asigura ca consumatorul final primeste o masina complet functionala 
-ultimul goal este sa scoatem masina din fabrica 
-sa construim software este cumva similar cu a construi o masina 
-GitLab CI/CD ne ajuta sa scoatem produsu nostru software dintr-o fabrica pe orice am lucra 

-acum vom face un pipeline simplu in gitlab ca sa intelegem despre ce e gitlab ci/cd si conceptele importante
-vom face ceva similar cu linia de asamblare a masinii si vom defini doua Major Stages: Build and Test. Dar vom lucra cu un file si niste text in loc de car parts 
-bineinteles ca stage-urile de build si test includ multi pasi 
-incepem de pa pagina care ne duce unde dam click pe logo si dam pe new project, alegem blank project, la name bagam Car assembly si dam Create 
-a fost creeat cu succes si vedem ca proiectu are un singur file, cel readme 
-ca sa definim un pipeline, trebuie sa deschidem un web IDE si putem face asta direct din browser de la dropdownu Edit din dreapta numelui proiectului deasupra commit-ului 
-tot aici e un shortcut care e foarte usor de omis, un punct intr un patrat gri 
-deci ce am putea face, mereu cand vrem sa deschidem un proiect, in loc sa dam pe edit si web ide, putem apasa direct pe . pe tastatura si ne trimite direct in web ide pe un tab nou 
-o sa definim pipeline urile intr-un nou file denumit exact asa: .gitlab-ci.yml 
-ce scriem in acest file, foloseste yaml pt a defini pipeline uri in gitlab ci, care e un format foarte popular in general pt a specifica configuratii si in gitlab este singuru mod de a defini un pipeline 
- pt ca gitlab sa faca cv, trebe sa i oferim instructiuni care merg intr o forma de job 
-deci un job este ca un task pe care gitlab ar trebui sa il faca pt noi
-sa zicem ca vrem sa definim un task sa construim o masina: build_car:
-si inauntrul acestui job putem defini o serie de comenzi linux 
-folosim comenzi linux, pt ca gitlab foloseste by default containere docker sa ruleze job uri 
-si containerele docker bazate pe linux sunt o alegere foarte populara, de asta folosim comenzi linux 
-deci, putem sa rulam comenzi in environmentu creeat de containerele docker
-si ne putem gandi la acest environment ca si un vm lightweight, care include tot ce ne trebuie sa rulam comanda asta 
-inauntrul acestui job(build_car), trebuie sa ii zicem lu gitlab ce container vrem sa folosim si astfel, dam enter dupa build_car: si dam tab si scriem image: apline , care este o distributie lightweight de linux ideala pt ce avem nevoie acu 
-sa definim niste comenzi care vrem sa fie executate in containeru Docker, asa ca dupa alpine dam enter si scriem script: , inauntrul acestui script, putem specifica o serie de comenzi
-si pt ca sunt multe comenzi pe care le putem executa, le vom defini ca si o lista 
-deci dam enter dupa script: si dam tab si punem - echo "Building the car"
-daca mai vrem sa executam o comanda, o scriem o line dedesubt si suntem atenti la identare si sa zicem ca vrem sa avem totu in folderu numit build 
-deci folosim comanda - mkdir build pt a creea un folder numit build 
-si pt ca vrem sa facem chestii in interiorul folderului acesta, trebuie sa intram in el  cu cmd: - cb build
-sa zicem ca vrem sa creeam un file care e numit car.txt folosind comanda - touch car.txt 
-comanda touch schimba un timestamp cand un file a fost creeat sau updatat si daca nu exista, pur si simplu creeaza fileu 
-acuma fileu e empty deci sa adaugam si niste informatii in el 
-o sa folosim iar comanda - echo "chassis" > car.txt , in care am folosit operatoru de redirectare > care ia outputu comenzii echo, adica efectiv textu chassis si il redirectioneaza catre fileu din dreapta lui, in cazu nostru car.txt 
-deci cu comanda de mai sus, in loc sa printam un mesaj, o sa il redirectam catre fileu car.txt 
-o sa dam commit direct pe main branch la ce am facut pana acum sa vedem daca merge pipelineu 
-o sa vedem ca merge, dam click pe el si vedem si logul 
-tool-ul care genereaza acest output se numeste GitLab runner 
-vedem comenzile noastre la sf log ului respectiv si vedem ca ultima linie e "Job succeded" deoarece nu s erori din timpul executiei buildului 
-daca avem problema ca nu ruleaza pipelineu, sa ne asiguram ca numele fisierului este .gitlab-ci.yml, ca fisieru de pipeline este in root-ul proiectului, nu intr-un folder si sa nu dam enable la auto devops 

Pipeline Stages 

-daca ne utiam la proiectu nostru Car assembly si nu vedem folderu build cu car.txt 
-chestia e ca gitlab nu salveaza nimic, doar daca i se spune
-ce este si mai important este ca, de obicei, nu dam commit la file uri in timp ce rulam pipelineu si le dam store in repou git 
-deci daca vrem sa vedem contents-urile fileului, trebuie sa ne intoarcem la configuratia noastra aici si putem folosi o comanda ca si cat(folosita pt a citi, afisa, sau combina contents urile file-urilor)
- cat car.txt , si vedem ca dupa ce dam comit si se reexecuta pipelineu, ne va afisa sub comanda cat contentu fileului car.txt 
-deci asta arata ca am reusit cu succes sa creeam acel file si sa punem niste continuturi in el 
-a fost unpic cam manual procesu si amn zis la inceput ca incercam sa automatizam totul
-deci ar avea mult sens sa avem niste comenzi de linux care sa verifice daca exista fileu si sa verifice daca contine ce ar trebui sa contina
-deci pt acest motiv o sa introducem un nou job cu rolul de a testa fileu 
-mergem inapoi in configurare si dedesubt o sa scriem un nou job numit test_car si folosim aceeasi imagine si anume image: alpine 
-si inside the script: vol folosi urm comenzi:
-din fericire, linux are ceva comenzi folositoare pe care le putem folosi, de ex test(e folosit pt a evalua o conditie true sau false, flag-ul -f verifica daca exita fileu)
-deci va arata asa: - test -f build/car.txt  , asta va testa daca un filu car.txt exista. si ca sa fim si mai specifici, vom verifica daca este in folderu build, deci punem build/ inainte de car.txt 
-dar trb sa ne amintim ca inauntrul lui script: scriem, de obicei, o lista de comenzi. Putem avea si o singura comanda, dar de obicei este o lista de comenzi 
-dar totusi, vrem sa ne asiguram ca punem inaintea comenzii sintaxa pt lista de comenzi (- ), spatiul de dupa - e important 
-sa testam daca fileu are si contentu corect. o comanda pe care o putem folosi sa dam search la contentu fileului este grep, care ne va ajuta sa cautam un string specific intr-un text 
-putem sa ii dam string-ul "chassis" si astfel sa verificam daca cuvantul chassis exista in fileu car.txt: - grep "chassis" car.txt si dam commit 
-vedem pe dashboard, dupa ce dam click pe commit, ca build_car a trecut si test_car a dat failed la pipeline
-dam pe cercu rosu de la test_car si vedem ca pe log avem pe ultima linie eroarea ERROR: Job failed: exit code 1. Deci o comanda ii zice lu gitlab ca ceva a mers prost 
-si ca sa intelegem ce comanda a fost, trebuie sa ne uitam in log-uri sa vedem ce comanda am executat ultima 
-deci o sa vedem aici ca ultima comanda care a fost executata este: test -f build/car.txt  si nu vedem comanda cu grep
-ce inseamna asta este ca gitlab a executat aceasta comanda task, ceva a mers prost si executia a fost oprita 
-deci restu de comenzi nu au fost executate(comanda grep in cazu nostru), deci clar este o problema cu comanda test
-daca dam pe bulina rosie din dreptul commit-ului sau intram la pipelines si dam tot pe bulina rosie, vedem ca totu este in test(cele doua job-uri)
-acest test este un stage, de ex, am zis la inceput ca vremsa avem 2 stages: vrem un build stage si un test stage 
-deci aceste doua job-uri(build_car si test_car) au fost executate in paralel, pt ca fac parte din acelasi test stage 
-aceste doua job uri au ajuns in acest test stage by default, deci daca nu specificam un stage, gitlab va adauga un anumit job la testing stage
-daca ne gandim logic, sa buildium ceva si sa si testam in acelasi timp nu prea are sens, deci trebe sa separam aceste job uri si sa le executam unul dupa celalalt si nu in paralel si putem face asta, specificand stages-urile  
-facem asta, prin a defini cele doua stage uri(build si test) inainte de cele doua job-uri stages: - build -test 
-si la fiecare build, asignam unul dintre stage uri: la build_car: adaugam sub image: stage: build si la test_car adaugam sub image: stage:test 
-dupa ce dam commit, vedem ca la bulina rosie, apar doua stage-uri: build si test executate una dupa cealalta in aceasta ordine 
-tot da fail jobu test car chiar daca am separate steage urile si sa se execute una dupa alta 
-ziceam inainte ca noi folosim docker containers si fiecare job este izolat in propriul lui container docker 
-deci inainte s-a executat acest job de build_car si odata ce acest job s-a terminat, acel contaienr docker a fost distrus impreuna cu car.txt 
-deci cand urmatoru job incepe, car.txt nu e in repo si nu e in niciun caz in container pt ca a fost distrus, deci bineinteles ca nu o sa il poata gasi comanda test 
-la prima vedere, ar inseamna ca trebuie sa punem totu intr-un singur job si sa builduim totu aici si sa il si testam imd ceea ce nu mai face scopul si complica tot 
-dar mai e o varianta, gitlab are o modalitate pt noi sa-i spunem runner-ului ca noi am creeat aici(in build_car) ceva super important si vrem sa il pastrezi 
-si asta se face, prin definirea unui job artifact, care e ceva care e facut in timpul procesului de build, ca de ex, fileu car.txt care e pus in fodleru build 
-acesta este un job artifact, ceva ce vrem sa pastram, ceva ce noi am creeat cand builduim software in general, ciclcic, o noua versiune a unui software pe care lucram 
-deci, ce trebuie sa facem este sa ii zicem lu gitlab ca fileu car.txt e important pt noi si vrem sa il pastrezi ca noi sa il putem folosi un stage-uri si job-uri viitoare 
-pe acelasi nivel cu script(2 space-uri), scriem: artifact: si sub identat scriem paths: (alta prop sub artifact), si dupa ca o lista sub paths identnat si cu - , scriem -build/ care indica un folder:

articats:
  paths:
    - build/ 

-cu configuratia asta i am zis lu gitlab sa pastreze tot ce e in folderu build/ 
-vedem ca a dat fail jobu test_car si intram pe log sa vedem de ce. Vedem ca comanda test -f buid... a fost ok si nu mai primim niciun mesaj dupa ea 
-primim mesaj dupa a doua comanda, cea de grep, deoarece cand am folosit comanda de test am specificat folderu build dupa care am pus numele fileului 
-la comanda grep nu am facut asta si deci vva cauta in folderu curent, adica la nivel cu folderu build, nu in acesta 
-deci daca nu folosim cd sa intram in folderu build, trebuie sa specficam folderu(pathu relativ) inainte de numele fileului car.txt
-deci va arata asa: grep "chassis" build/car.txt si ar trebui sa mearga ok 
-deci asa putem folosi gitlab sa creeam un simplu pipeline cu doua stages
-am folosit stages sa definim un build stage si un test stage si fiecare stage are prorpiul lui job
-vedem ca in build stage, avem build_car job si in test stage avem jobu test_car 
-acesta este view-ul pipeline ului adica executia se intampla de la stanga la dreapta 
-si daca vrem sa vedem job urile individuale, dam click pe jobs si vedem informatii despre fiecare job individual 

GitLab CI/CD arhitecture 

-executia unui pipeline este trigger-uita def fiecare data cand facem un change in repository
-arhitectura gitlab ci/cd contine un github server si un gitlab runner 
-gitlab server menegeriaza executia pipeline-ului si salveaza rezultatul 
-putem spune ca serveru stie ce trebuie facut dar nu face el singur 
-cand un job trebuie executat, serveru gaseste un gitlab runner potrivit sa faca job-ul 
-un working gitlab setup trebuie sa aibe macar un runner, dar de obicei sunt mai multe runnere sa ajute la distribuirea load-ului sau sa aiba niste runnere specializate pentru ceva job uri specifice 
-gitlab runner va primi un set de instructiuni de la server bazate pe toate comenzile specificate in script 

-in pipelineu nostru fiecare job individual este executat independent si daca inteleg cum functioneaza un job voi intelege de asemenea cum alt job functioneaza de asemenea 
-daca ne uitam pe logu de la jobu build_car, prima parte a acestuia, pana la comenzile care incep cu $, este toata munca pe care o face gitlab ca sa se pregateasca sa ruleze comenzile pe care le am definit 
-apoi avem executia efectiva a comenzilor pe care le am scris 
-incepem cu prima parte a log ului, inainte ziceam ca putem avea mai multi runneri si in cazul nostru, unul dintre acesti runneri care sunt disponibili au luat acest job si vedem in dreapta exact ce runner este 
-asta e cv foarte tehnic si face parte din infrastructura gitlab dar ar trebui sa stim ca este undeva un runner care a avut grija de executia acestui job 
-deci acolo in dreapta log-ului zice ca acest runner a inceput job ul si sunt niste informatii despre runner pt ca sa putem identifica in caz ca este ceva gresit cu acest run 
-a doua linie este Resolving secrets, momentan nu avem niciun secret, dar runneru poate sa dea fetch la secrete de care e nevoie sa ruleze acest job, asta poate include variables sau orice alta configuratie care este cumva secreta dar relevanta pt job 
-umr parte e pregatirea executorului, fiecare runner poate avea o cale diferita de a executa job uri
-gitlab foloseste docker machine ca un executor si acesta este un docker executor care ne ajuta sa rulam imagini docker 
-deci daca vrem sa folosim o imagine docker in configuratia noastra , avem nevoie de un docker executer 
-deci oricand e ceva gresit cu executia si nu suntem siguri de ce nu merge ceva si cine a executat job-ul, daca am specificat o imagine docker in configuratia noastra si ne asteptam ca un executor docker sa ia imaginea, ar trebui sa vedem asta in log
-daca nu vedem asa: Using Docker executor with image alpine...  , atunci avem tipul gresit de docker runner configurat sa ruleze acel job 
-urmatorul pas pe care gitlab runner il va face este sa dea pull la image, pe care o va lua dintr-un docker registry si o sa o aiba disponibila local 
-dupa asta va pregati environemntu, cand pornim o imagine docker avem un container docker pe care aceasta ruleaza 
-urmatoarea parte este luarea codului sursa de pe git repository, ii face clone la repository, ca sa aiba acces la toate files urile, tot source codu, tot ce e inauntru la repositoryu git 
-in exemplu nostru nu am folosit niciun file, dar am fi putut folosi niste file-uri care sunt disponibile aici 
-dupa acest pull, vedem ca se apuca sa execute step script, deci asta e partea unde noi am definit chestii 
-apoi reitereaza ce imagine docker foloseste, dar deja avem informatia asta mai sus in log si apoi merge prin comenzile pe care le am scris aici
-acu dupa ce ruleaza comenzile, pt ca am definit acest artifact, va publica niste informatii despre artifacts, cum zice aici: Uploading artifacts for successful job , insemnand ca nu s errori
-si dupa o sa ne zica exact ce a gasit in termeni de artifacts si le va da upload undeva ca si zip file 
-foarte tehnic, dar asta e daor o indicatie ca configuratia pe care am creeat-o in termeni de artifacts a fost luata de gitlab si gitlab stie ca trebuie sa stocheze artifacts urile 
-nu tre sa intelegem tot ce se intampla aici, dar cea mai importanta chestie e ca vedem Uploading artifacts... deci ca stocheaza undeva artifacts-urile 
-si vom vedea in dreapta logului de asemenea Job artifacts si avem posibilitatea si sa dam browse la aceste artifacts si vedem folderu nostru build si fileu car.txt si putem descarca fileu si sa ne uitam la el 
-la sfarsit, pt ca toate comenzile pe care le am avut au fost executate, artifacts urile sunt acuma uploadate suntem gata cu acest job 
-si cand suntem gata cu jobu, trebuie sa distrugem containeru docker 
-deci containeru docker care a fost creeat aici la inceput cu imaginea alpine la baza care a fost folosit in executia acestui job sa cloneze acest repo git sa ruleze comenzile pe care le vedem aici si sa uploadeze artifactsu si asa mai departe, la sfarsit este distrus 
-deci jobu care urmeaza care e test_car, va face la fel de la inceput, va folosi poate un alt runner, poate fi si acelasi runner dar poate fi si altu si va merge din nou prin acelasi proces de a da pull la o imagine docker, sa inceapa un docker container, sa cloneze repou..
-si e un lucru important care e diferit de data aceasta si anume: va downloada artifacts-urile pt build_car.
-deci noi stim ca jobu build_car a creeat niste artifacts si le va downloada jobu test_car
-deci aceste artifacts vor fi disponibile inainte sa incepem sa rulam comenzile noastre test si grep 
-asta e singura diferenta importanta dintre aceste doua job uri, dar in termeni de cum sunt executate job urile este efectiv acelasi lucru 

-pentru primul proiect numit test nu am specificat un docker image. in codu fisierului .gitlab-ci.yml avem doar numele job ului si o comanda echo de executat 
-deci intrebare este: unde s-a executat jobu asta, ce s-a intamplat cu el?
-ca sa vedem, mergem pe log-ul acestui build si aici vedem ca inca folosim un executor docker machine 
-deci inca facem ceva cu docker si vedem ca folosim o imagine numite ruby:3.1 
-acuma chiar daca nu specificam o imagine docker, pt ca asta e folosita by default de un gitlab runner(ruby:3.1) care are un docker executor, o sa foloseasca efectiv o imagine default
-aceasta imagine default este configurata pt fiecare runner. De obicei, by default, este o imagine ruby, dar poate fi orice altceva 
-nu ar trebui sa ne bazam niciodata pe o imagine random pe care o alege runner-ul, dar sa stim ca chiar daca nu specificam vreo imagine docker, va trebui sa folosim una 

-intorcandu-ne la primul proiect, stim ca fileu car.txt nu este parte din repository pt ca nu este commit-uita acolo si stim si ca acuma containerul docker a fost distrus 
-intrebarea este unde sunt folderu build si fileu car.txt stocate?
-le putem vedea in logu job-ului ca job artifact si in partea stanga la Job artifacts in care putem da browse, le putem vedea, putem chiar si downloada fileu car.txt 
-intrebarea este unde sunt file-urile si de ce inca le putem vedea?
-ideea principala este ca gitlab are grija de asta si este ceva care este abstractizat pt noi in sensul in care nu ar trebui sa ne pese unde gitlab stocheaza astea, pt ca e o chestie de implementare si nu ceva care ar trebui sa ne ingrijoreze 
-deci nu ii putem zice lu gitlab unde e fileu asta sau ca ii dam contu de dropbox si poate sa stocheze fileurile acolo, nu merge asa 
-deci administratoru gitlab configureaza cum sunt stocate aceste fisiere si asa mai departe 
-si daca avem nevoie de cv fisiere din aceste intr-un job diferit singura cale sa interactionam cu asta este sa specificam ca avem niste artifacts pe care le am generat si by default toate job urile care urmeaza vor lua acest artifact 

-deci am inteles ca tot timpu folosim docker si intrebarea este daca nu este prea mult sa folosim docker pt, sa zicem de ex o comanda simpla, tot trebuie sa mergem prin toti acesti pasi: sa dam pull la imagine, sa pornim container bazat pe ea, sa clonam un repo
-astfel ca pare ca repetam un nr de pasi din nou si din nou 
-in primu rand, vreau sa arat ca daca folosesc o imagine cu un footprint mic ca alpine, intreg procesul se intampla in cateva secunde(12 sec)
-deci am vazut ca executia comenzilor acestea se intampla in cateva secunde ceea ce nu e mult deloc si asta e destul de important, pt ca noi ne focusam in curs pe performanta
-deci in mod evident nu vrem sa asteptam toate job urile astea sa ruleze un minut, deci mereu punem multa energie si ne asiguram ca pipelineu nostru e performant 
-dar da, este un overhead daca facem asta, oricum, beneficiile sa avem acest build environment izolat intrece cu mult impactul performantei negative 
-pt ca vrem sa ne asiguram ca pipelineu nostru ruleaza exact la fel specificand acest environment docker si nu conteaza daca execut configuratia asta pe machineu meu sau dau altcuiva configuratia asta sa o ruleze intr-o alta infrastructura gitlab, atat timp cat gitlab runner stie cum sa execute o imagine docker
-deci configuratia asta este foarte usor portabila 
-si izolarea asta inseamna de asemenea ca putem avea mai mult job-uri care ruleaza in acelasi timp si aceste job uri nu se imapcteaza intre ele, ceea ce e super important 

.gitlab-ci.yml 

stages:
  - build
  - test

build_car:
  image: alpine
  stage: build
  script:
    - echo "Building the car"
    - mkdir build 
    - cd build
    - touch car.txt 
    - echo "chassis" > car.txt
    - cat car.txt
  artifacts:
    paths:
      - build/

test_car:
  image: alpine 
  stage: test
  script: 
    - test -f build/car.txt 
    - grep "chassis" build/car.txt

Linux shell 

-am folosit comenzi linux precum echo, mkdir, cd, cat, etc.. pe care le am pus in sectiunea script: a job ului 
-de obicei, scriem aceste comenzi printr-un CLI: console, terminal, shell. Un CLI este opusul unu GUI
-machine-urile cu care interactionam cand facem devops nu au de obicei UI, deci folosim aceste comenzi CLI din script: 
-interfata CLI pe care o au computerele e numita shell, care e efectiv outlayeru systemului si singurul lucru pe care il putem vedea din exterior
-deci trimitem comenzile acestea sistemului, si sistemul le va rula, asa putem interactiona cu el 
-cu gitlab, efectiv automatizam un set de comenzi pe care le executam intr-o anume ordine ca si comenzile din jobu build_car. Ordinea e foarte importanta 

Comments in a GitLab pipeline

-ca sa punem comentarii, folosim # si tot ce e dupa acesta va fi considerat ca si comment 
-yaml nu suporta block comment-uri pe mai multe linii 

Manually stopping a pipeline

-uneori job urile pot dura mai mult de 10 sec, ca ale naostre si pot dura chiar mai mult decat ne asteptam 
-punem dua comanda echo build car comanda - sleep 600 , comanda asta ii zice la job sa nu faca nimic pe 600 de secunde dam commit si daca ne uitam pe logu de la job vedem ca sta asa si nu face nimic la comanda sleep 
-deci, comanda sleep ocupa tot timpu si job ul nu va merge mai departe cu restu comenzilor pt ca mai intai, comanda asta trebuie sa se opreasca 
-normal ca asta e ceva simulat, dar pot fi anumite situatii in care o comanda efectiv se blocheaza sau nu am inteles exact ce ar trebui sa faca comanda si doar tine jobu ocupat 
-si nu este o idee buna sa asteptam la infinit, nu ar trebui sa dureze atata un build, o sa ne ia din minutele pe care le avem si e doar timp care e irosit 
-deci daca ne decidem ca jobu ruleaza de prea mult timp si vrem sa-l oprim, tot ce trb sa facem este sa dam click pe butonu rosu din dreapta sus a log-ului cu semn de interzis si se va da cancel la job 
-in cazu asta am dat abort manual la job, va trimite un semnal de intrerupere sa opreasca procesul si va opri comanda sleep 
-si in acest caz, vom vedea in loc sub comanda sleep, Terminated si dedesubt un warning in care ne zice script cancelled externally prin UI sau API si jobul o sa fie marcat ca si failed cu reason-ul cancelled 
-asta vom vedea si la pipelines ca a fost cancelled job ul build car si urmatorul job, test car a fost skipped pt ca nu se poate executa daca nu este build_car executat cu succes, putem da click si pe iconu pipelineu si sa vedem exact cele doua job uri unu cancelled si unu skipped 

YAML 

-pt identare yaml nu foloseste tab-uri ci doua spatii. adica chiar daca dam tab se va pune ca doua spatii sau asa tr trebui 
-daca nu scriem cod yaml valid, gitlab nu va putea sa ruleze pipelineu 
-de ex, in .gitlab-ci.yml, dupa stages avem : , daca stergem : nu o sa vedem erori, dam commit si o sa ne dea eroare la pipeline, pe bulina rosie cu failed 
-o sa ne zica ca si error tags: yaml invalid, error. Cand facem greseli in yaml este unpic mai greu de depistat sa intelegem exact ce s-a intamplat 
-punem inapoi : si acuma stergem spatiul de dupa dash-ul de la build si test: -build -test si dam commit 
-avem iarasi un yaml invalid, acuma primim si o informare, zice ca configulu stages-urilor ar trebui sa fie un array de strings sau un nested array de strings up to 10 levels deep 
-deci, ne dam seama ca este ceva legat de configurarea stage-urilor, astfel eroare poate fi unpic ambigua, unpic mai greu de inteles care e problema 

-creeam un nou file, numit person.yml in care vrem sa definim niste properties ale persoanei 
-in loc sa scriem ca in programare de obicei asa: first_name = Jamie, o sa scriem first_name: Jamie . Cu : in loc de = si o sa stergem spatiul de dinainte de : 
-deci avem pe stanga la : ce numim un key(first_name) si pe dreapta la : ce numim un value(Jamie) . Observam ca sunt colorate si diferit 
-putem avea si mai multe proprietati ca si, de ex,  age: 22  sau   is_married: false  
-sa zicem ca vrem sa listam ceva, de ex hobbies: , dupa care mergem pe o noua linie, bagam doua spatii, - , iar spatiu Netflix de ex. O sa arate asa:
-ca sa facem toate proproietatile astea first_name, age, is_married, hobbies sa apartina unei persoane, scriem deasupra la tot person: si selectam toate proprietatile de mai jos si le identam cu tab, cu doua spatii la dreapta, ca sa fie in interiorul lui person: deci ca sa ii apartina acestuia cumva 
-acuma toate prop vor apartine de person
-vrem sa adaugam si o lista de prieteni. Deci adaugam o proprietate numita friends: si in interiorul acesteia nu vrem sa punem doar niste nume, ci niste obiecte care au prorpietati la randu lor si ele 
-astfel, vom adauga sub fiernds: un dash - care are prorpeitatea first_name: Jane si age: 21 si inca o prop cu - cu numele Prya si age 23
-ce e important sa intelegem este ca astea cu - de sub friends: sunt si ele obiecte individuale cu propriile proprietati si fac parte dintr-o lista numita firends 
-deci daca ne intoarcem la configuratia noastra gitlab, vedem ca stages este o lista 
-build_car este un obiect care are proprietati ca si image, stage, script(aici vedem si o lista)
-artifacts este o proprietate care are o alta prorpietate care are o lista. articats este o prop care are paths care este o prop care are o lista cu un singur element -build/
-deci in yaml identarea e super importanta 
-sa scriem cv ca jobu nostru build_car cu image stage script identate, arata ca toate is proprietati ale build_car 
-daca stergem doua spatii de dinainte oricarei proprietati, ca de ex artifacts, o sa fie un obiect de sine statator si nu proprietate care apartine lui build_car 
-deci identarea cu 2 spatii e super importanta si doar un spatiu e important si : sunt relevante pt sintaxa 

person.yml 

person:
  first_name: Jamie 
  age: 22
  is_married: false 
  hobbies:
    - Netflix 
    - mountain biking 
  friends:
    - first_name: Jane
      age: 21 
    - first_name: Priya 
      age: 23

Effective testing in CI pipeline 

-cand facem un pipeline si punem mult efort ca sa build-uim ceva, sa ne asiguram ca avem teste adecvate este la fel de important 
-un pipeline poate sa ruleze fara sa raporteze vreo eroare si sa produca totusi un build defectuos
-trebuie sa prevenim sa se intample asta 
-o sa facem niste schimbari in jobul build_car: o sa adaugam o noua linie sub echo chassis in care scriem in car.txt si cuvantul engine: - echo "engine" > car.txt 
-si inca o linie sub engine in care scriem in file wheels: - echo "wheels" > car.txt 
-din moment ce am facut schimbari aici, o sa adaptam si testele pe care le rulam: - grep "engine" build/car.txt , - grep "wheels" build/car.txt
-daca ne uitam la pipeline, vedem ca jobu build_car a fost successful, dar e o problema cu test car job
-daca ne uitam pe log, vedem ca ultima comanda care a fost executata este - grep "chassis" build/car.txt
-deci stim ca fileu car.txt exista deoarece comanda de dinaintea asteaia de grep, si anume cea de test a for successful 
-dar se pare ca nu poate gasi cuv chassis si dupa comanda asta de grep, s a oprit executia 
-acuma urmatoru pas este sa vedem daca nu a fost o missconfiguration in pipeline ca un file path gresit sau ceva de genu
-dar nu ar trebui sa fie cazu, pt ca am dat copy paste la niste comenzi care mergeau inainte fara probleme 
-deci, daca nu ne putem da seama de nimic din pipeline log si configuratia arata ok, trebuie sa facem un test manual 
-pt ca scopul stage-ului de test era doar sa verificam daca un file exista si daca contine cele 3 cuvinte 
-si pt un motiv ceva nu merge ok. Deci, fileu ori nu contine cele 3 cuvinte, stim doar de chassis in punctu asta, sau este vreo problema aici 
-putem sa executam inca odata comanda cat car.txt in jobul test_car sau putem sa ne uitam in logu de la jobul build_car sa vedem ce se petrece acolo 
-in log, nu avem erori si vedem la comanda $ cat car.txt ca fileu contine doar cuv wheels 
-putem de asemenea sa mergem in dreapta log-ului la Job artifacts si sa dam browse sau download si sa ne uitam peste ea asa 
-deci ne putem da seama din log ca este o problema
-faptul ca job-ul test_car a dat fail este exact ce ne am dorit pentru ca fileu car.txt nu contine ce avem nevoie 
-doar pt ca jobul test_car a dat fail nu inseamna ca problema vine de la stage-ul de test si investigarea noastra arata ca e ceva gresit cu build stage-ul 
-daca ne uitam la comenzile din build script, sa vedem ca ultima comanda pe care am executat-o inainte de cat este aceasta unde punem wheels in car.txt 
-aici e problema: operatorul > va suprascrie continuturile file-ului. Deci, de fiecare data cand rulam comanda eci ... > car.txt , continutul fileului o sa fie suprascris 
-si nu vrem asa ceva, nu vrem sa inlocuim mereu cand executam comanda echo .. > continutul, ci vrem sa dam append informatia, adica sa o lipim, sa o adaugam la file 
-ca sa adaugam doar continut-uri intr-un file, folosim operatorul >> 
-a fost o greseala minora, dar avem teste si astfel am putut detecta problema. Dam commit la schimbari, punem >> la comenzi si vedem ca merge ok acuma 
-putem face acuma si un test manual, intram pe logu de la build si ne uitam la output-ul comenzii cat car.txt si vedem ca are 3 linii fiecare cu cuvantu care trebe 
-sa avem teste bune ne da mai multa incredere cand facem schimbari la pipeline 
-acum, daca stergem linia $ touch car.txt si dam commit vedem ca tot o sa treaca testele 
-deci din nou, sa avem teste foarte solide ne permite sa facem schimbari increzatori fara sa ne facem griji de output 
-deci high quality test sunt importante pt ca un pipeline poate sa ruleze fara probleme dar totusi sa produca output-uri nedorite 
-cand acesta este cazul, trebuie sa creeam teste mai bune 
-si in al doilea rand, daca un test da fail, sa inspectam log-urile cu atentie si cel mai important cu rabdare
-sa parcurgem log-ul pas cu pas cateva minute si sa intelegem ce se intampla si daca un test da fail sa ne dam seama daca este o problema cu testu sau testul ne da o alarma ca e o problema 
-in orice caz, ce avem de facut este sa replicam asta printr-un test manual si sa ne dam seama daca problema este cu testu, cu buildu sau cu altceva 

Why do jobs and pipelines fail(exit codes)

-inainte, am avut cateva situatii in care job-ul a dat fail, de ex, cand un file nu exista comanda grep nu gasea stringu pe care il cautam 
-avem exemplul cu testarea daca exista fileu 
-dar cum functioneaza asta defapt? si cum stie gitlab defapt ca fileu nu exista si trebuie sa dea fail la job 
-singurul lucru pe care il avem, daca ne uitam la logs este Error: Job failed: exit code 1
-asta e ca un cod secret unpic. Comanda ii zice lu gitlab exit code 1 si gitlab e gen ok roger failing the job 
-ce se intampla aici, putem intra in codu secret pe care gitlab si comenzile astea il folosesc?
-sigur, e super usor
-exit codes sunt o cale de a comunica daca executia programului a fost succesful sau nu 
-un exit code 0 va indica daca programul a fost executat cu succes. De obicei nu vedem hints-uri ale acestui exit code 0
  -asta e doar procedura normala, la ceea ce neasteptam si daca toate comenzile returneaza un exit code 0, gitlab va marca job-ul ca si successful 
-oricare alt exit code, care poate fi un numar de la 1 la 255 indica un failure 
-in cazu acela, comanda a returnat un exit code 1 si daca am avut alte comenzi aici fiind executate inainte ar insemna ca toate acele comenzi executate inainte au un exit code 0
-deci daca totu merge ok si comenzile fac ce ar trebui sa faca, printeaza ce mesaje ar trebui sa printeze, la sfarsit ii zice li gitlab exitcode 0 si gitlab este gen ok sa continuam cu urmatoarea comanda sau daca asta a fost ultima comanda va opri jobu si il va marca ca si successful 
-dar daca gitlab primeste un exit code care nu e 0(in cazu nostru e 1), va intrerupe imediat executia job-ului si nu va mai executa nicio alta comanda dupa asta 
-deci daca ne uitam la log-ul unui job care a dat fail, ultima comanda care a fost listata(in ex nostru este test -f build/car.txt) este aceea care a returnat exit codeu 1, nu va fi o comanda mult mai de deveremee
-asta nu inseamna ca radacina problemei nu poate fi o comanda de mai dinainte sau plasata intr-un job diferit 
-toate comenzile returneaza un exit code automat, nu trei sa facem noi nimic. Comanda doar stie ce sa faca 
-si daca pipelineu este unpic mai lung si unu din job-uri da fail, restu pipelineului nu va mai fi executat si tot pipelineu va fi marcat ca si failed 

-sa recapitulam, oricand github intalneste un exit code mai mare ca 0 issued de unul dintre aceste programe, executia job-ului se va opri 
-ca sa intelegem mai bine, o sa vedem cum putem simula un exit code 
-mergem la ideu din browser si ne uitam la jobu build_car ca si exemplu si dupa comanda de echo chassis dam comanda exit 1, dam comit si ne uitam la logs 
-vedem ca build_car va da fail pt ca a fost o problema in acest stage si de aceea, stage-ul urmator nu va mai fi executat ci doar skipped 
-ca sa intelegem ce s-a intamplat intram pe logu job ului build_car si vedem ERROR: Job failed: exit code 1 si vedem ca, comanda care a dat issue la acest exit code este exit 1 
-bineinteles ca asta e doar o simulare, dar important e sa intelegem ca restul comenzilor(eco engine wheels cat ..) nu mai sunt executate 
-deci mereu comanda care a dat issue la exit codeu mai mare ca 0 va opri executia build-ului 
-din nou, asta a fost doar simulat pt scopu de a demonstra, nu o sa tinem comanda exit 1 aici, o sa o stergem acuma
-trebuie sa intelegem conceptul acesta de cum functioneaza aceste exit codes, e un concept foarte important si vom face debugging la aceste pipeline-uri destul de mult 
-in plus, este foarte important sa avem rabdarea sa parcurgem comenzile executate sa intelegem care e output-ul logs-urilor si ne uitam dupa orce hints care ar putea cauza aceasta problema 

-fiecare stage poate avea unul sau mai multe job-uri care fac munca prorpiu-zisa


Continous Integration 

-vrem sa automatizam toti pasii manuali care sunt necesari pt a integra schimbarile ale mai multor developeri si sa creeam un pipeline care ca da build si va testa softu pe care il cream 
-adica, vom face continuous integration si vom face un CI pipeline de la 0, crescandu-i complexitatea pe parcurs 
-de obicei, nu e doar un om care lucreaza pe un proiect si cand facem continuous integration, integram schimbarile in cod cu codul pe care alti developeri l-au creeat 
-inseamna ca de fiecare data cand facem shimbari, codu este testat si integrat cu munca pe care altcineva a facut-o. Facem asta sa evitam probleme de integrare si sa ne asiguram ca softu nostru este folosibil oricand
-se numeste CI, pentru ca integram work in mod continuu cand apare 
-trebuie sa integram schimbarile in cod intruna, nu o data la mai mult timp pt ca asa poate fi prea tarziu si prea scump sa rezolvam problema
-cu cat asteptam mai mult, cu atat o sa fie mai mari sansele sa avem probleme de integrare 
-una dintre principalele tool-uri care da enable la CI este Git version control system care urmareste toate schimbarile 
-in sectiunea asta, vom folosi Git impreuna cu GitLab sa verificam schimbarile si sa le integram in proiectul nostru 
-in acest proces vom invata cum sa builduim un proiect folosind docker, cum sa rulam unit teste si sa configuram un linter, sa publicam test reports si sa le inspectam, sa configuram merge requests si sa invatam cateva trucuri sa optimizam viteza pipeline-ului 
-cand facem pipeline-uri mai avansate, o sa intalnim probleme cel mai probabil si e parte din procesu de invatare 
-daca avem o problema s aincercam si singuri sa o depistam, facand undo la mai multe schimbari pana la o versiune stabila si dupa sa facem schimbari putin cate putin si sa vedem la ce schimbare crapa exact 
-de obicei, cauzele problemelor o sa fie minore, greseli de sintaxa, ortografie, un cuvant scris gresit sau ceva 

Forking a Git repository 

-asta inseamna efectiv sa ne facem un repo al nostru dupa alt repo care e public 
-ca sa putem face un repo public, trei sa facem Group-ul nostru de repository-uri public din Groups -> Edit -> Public in loc de Private
-vom face fork la proiect de web cu react intram pe linku de la repo 
-dam clone pe desktop direct 
- $ git config --global core.sshCommand "ssh -i C:/Users/dapo273535/.ssh/id_rsa" ca sa ii zicem lu gitlab sa foloseasca acest ssh key cand facem git clone, dupa ce creeam ssh key-ul cu cmd: $ ssh-keygen -t rsa -b 4096 -C "davidpopescu85@gmail.com"  ca sa creeam keyu si dupa trei sai dam copy asa: $ cat ~/.ssh/id_rsa.pub si dupa intram pe gitlab la profile settings si cautam ssh keys acolo si ii dam paste si dam add 
-acuma dam $ npm install si dupa $ npm build run  si dupa $ npm install -g serve si dupa ca sa pornim $ serve -s build/

Using Docker as a buid environment

-facem .gitlab-ci.yml in rootu la project in care facem un job test_npm, folosim imaginea alpine si dam in script: doua comenzi nope --v si npm --v
-o sa dea fail pt ca imaginea alpine nu are node.js instalat asa ca vom folosi o imagine care are instalat node.js si anume image: node:22 si acuma va merge build-ul 
-in logu buildului vedem ca folosim un Docker executor cu iamginea node:22 si comanda noce --v va da v.22.14.0 , exact ceea ce ne trb pt proiectu nostru 
-ca sa alegem imaginea docker potrivita pt proiectu nostru, mergem pe dockerhub si in cazu nsotru, cautam node si dam pe primu rezultat node de la trusted content 
-imaginea asta e oficiala si e facuta de node.js direct 
-node:22 : acel 22 este versiunea imaginii de node.js pe care vrem sa o folosim si deci imaginea va folosi versiunea 22 de node.js care ne trebe pt proiectu nostru 
-dupa ce scriem la image: node:22 , gitlab runner va incerca sa dea pull la imagine de pe docker registry-ul default, care este docker hub by default 
-ne intoarcem la search bar unde avem Trusted content, unde gasim imagini oficiale mentinute de creatorii unui tool sau unui framework de limbaj de programare si asa mai departe ca imaginea node.js 
-dar putem avea si Comunity images la care contribuie alti developeri, dar nu sunt officially maintained 
-teoretic, putem sa ne facem un cont pe docker hub si sa publicam imaginile noastre acolo si sa le share-uim cu lumea
-o imagine neoficiala ar putea sa expuna un risc de securitate, deci ar trebui sa le evitam de obicei, doar daca suntem foarte siguri de originea imaginii, deci trb sa avem grija cu ele 
-pentru cele mai multe pipeline-uri ci/cd, vrem sa ramanem la imagini oficiale pt fiabiliutate si securitate 
-aceste iamgini sunt updatate regulat si au documentatie care explica cum sa le folosim 
-daca proiectul nostru foloseste alt limbaj sau framework decat node.js, avem doua variante: in documentatia framework-ului sau tool-ului folist este descrisa ce imagine ar trebui sa folosim 
-cele mai multe framework-uri mentioneaza explicit ce imagine merge cel mai bine si ar putea da si exemple pt pipeline-uri ci/cd 
-a doua optiune este sa cautam direct pe docker hub, de ex: python sau php, java si sa folosim imaginile oficiale 

Lightweight Docker images 

-de fiecare data cand un job ruleaza, imaginea docker din .gitlab-ci.yml trei sa fie downloadata. Cand vedem in log Pulling docker image inseamna defapt downloading docker image 
-asta inseamna ca daca imaginea este mare ca si size, pipelineu nostru va trebui sa stea mai mult timp sa o downloadeze si nu vrem asta daca nu trebuie neaparat sa folosim o imagine mai mare pt specificatiile proiectului nostru 
-daca este posibil sa folosim o imagine docker mai mica(small size, lightweight) ar trebui sa o facem 
-daca ne uitam la durata ultimului build o sa vedem ca este de 34 de secunde doar pt a executa doua comenzi de version care nu fac nimic 
-pentru pipeline-urile CI/CD putem folosi imagini lightweight pt ca sunt mai mici si mai rapid de donwloadat si contin doar ce avem nevoie 
-putem gasi aceste imagini mai light in documentatia imaginii pe care vrem sa o folosim 
-initial am folosit imaginea node:<version>, ceea ce e ok, dar avem si alte versiuni pe care le putem folosi si aceste versiuni sunt bazate pe alpine linux si inca unu care e numit slim 
-alpine linux este o distributie de linux super light weight care e perfecta pt ci/cd. Are scoase componentele ne necesare, oferind o imagine mica si eficienta 
-cealalta optiune, slim este de asemenea o alegere buna, de obicei aceste imagini sunt ceva mai mari decat alpine, dar tot e mai ok decat imaginea full size care nu are alpine sau slim in nume 
-mergem la tags, cautam 22 si dam scroll jos pana gasim 22-alpine si 22 si vedem ca cea alpine are doar 52.69 MB iar cea 22 are 386.52 MB, deci vedem ca este mult mai mica 
-copiem tag-ul celei alpine: node:22-alpine si il inlocuim in config fileu pipeline-ului. Singura diferenta este la tag, care are si -alpine dupa 22 
-o sa dam commit la schimbari, lasam pipelineu sa mearga si comparam timpu de executie al acestui job simplu
-vedem ca acuma build-ul a durat doar 14 secunde in loc de 34, adica mai putin de jumate din cat am avut initial 
-desi imaginile super light weight au timpi mici de downloadare, trebuie sa ne asiguram ca fucntioneaza cu pipeline-ul nostru 
-de ex, imaginea alpine folosita este perfecta pt aplicatii simple javascript, dar daca build-ul nostru are nevoie de niste librarii si tool-uri specifice pe care alpine nu le include, am putea avea limitari cu alpine 
-am putea fi nevoiti sa instalam tool-urile acestea mai tarziu si asta va incetini executia pipeline-ului si ar trebui sa avem o imagine de ansamblu ca sa intelegem exact de ce avem nevoie 
-dar, ideal, ar trebui sa testam mereu aceste imagini lighweight in environment-ul nostru CI/CD sa confirmam ca acestea intalnesc nevoile noastre 
-deci intr-un proiect real vom incerca imaginea alpine prima oara si daca ceva nu merge, putem sa folosim imaginea slim daca e disponibila si sa folosim imaginea full doar daca este absoluta nevoie 
-mai departe in curs, vom vedea cum sa construim imagini docker custom, unde luam imaginea alpine ca baza si adaugam la ea doar tool-urile de care avem neaparata nevoie in pipeline-ul nostru 

Building the project using GitLab

-o sa incepem prin a defini stage-urile pt pipelineu nostru. momentan o sa avem doar un stage si anume build: stages: - build , pe care il asignam la job-ul build_website: stage: build 
-putem lasa print-urile pt versiuni. Folosim versiunea 22 de node care nu este o versiune exacta, ci una majora, dar in caz ca buildu nostru nu mai merge la un momentdat, putem compara diferitele versiuni din log-uri si sa vedem daca de acolo vine problema 
-pt a continua, ne gandim la pasii pe care vrem sa ii facem: vrem sa builduim proiectu cu comanda: $ npm run build  , pe care o vom adauga la scripts sub npm --version 
-dar inainte sa putem rula build-ul trebe sa instalam toate dependintele proiectului cu comanda: $ npm install inainte de npm run build 
-tre sa facem asta pt ca rulam acest job intr-un container nou de fiecare data. Deci trei sa instalam dependintele proiectului de fiecare data cand vrem sa build-uim proiectu 
-intr-un server CI de obicei nu vrem sa folosim comanda npm install, si in locu asteia vrem sa folosim comanda $ npm ci , care e o comanda facuta specific pt un server CI 
-npm ci face cam acelasi lucru ca npm install, dar instaleaza dependintele folosind exact versiunile pe care le avem in package-lock.json fara sa faca schimbari si astfel versiunile exacte ale dependintelor sunt instalate si asta ne asigura ca avem un build replicabil
-pe langa asta, din moment ce foloseste log fileu direct, npm ci este de obicei mai rapida decat npm install, pt ca pastreaza niste featuri user-orientated ca si calcularea copacului de dependinte si altele 
-ideea e ca pt proiectu asta cu sizeu mic nu o sa faca o diferenta mare(folosirea comenzii npm ci in loc de npm install) deci putem folosi npm install daca chiar vrem 
-inainte sa rulam buildu, vrem sa listam toate file-urile din acest proiect inainte de executia comenzilor si dupa executia lor cu comanda $ ls -la , inainte de npm ci
-asta ne asigura ca o sa ne dea toate file urile ca o lista si de asemenea o sa ne dea si hidden file-ruile si rulam si dupa npm rum build exact aceeasi comanda
-dam commit la schimbari, lasam pipelineu sa mearga si o sa ne uitam la logs 
-vedem ca avem afisate de doua ori file urile proiectului cum ne asteptam dar a doua oara e si folderu node_modules care a fost facut ca urmare a comenzii npm ci ca 
-si la fel, observam  folderu build in a doua listare de file-uri care nu era prezent in prima 
-acuma putem sterge cele doua comenzi ls -la , le am adaugat doar sa vedem cum putem da troubleshoot la cateva chestii doar in caz ca procesu build-ului nu merge cum trebe si nu suntem siguri care file-uri de unde vin si ce face buildu, adaugarea comenzilor astea in pipelineu nostru poate sa ne ajute sa intelegem mai bine ce se petrece 

-DECI, cand dam commit la ceva schimbare in repo, asta face GitLab CI: face un container docker nou cu imaginea de baza specificata de noi, in care da checkout la ultimu commit(adica la ultima versiune a repo-ului nostru) si ruleaza comenzile din script specificate de noi 
-ruleaza acele comenzi, pt ca si noi am rulat acele comenzi dupa ce am dat clone la repo pt a build-ui si rula proiectu ca sa putem sa vedem ca merge siteu  

Assignment: Publishing build artifacts 

-stim ca folderu build este creeat cu succes(pt ca l am vazut cu ls) in root si tot ce trei sa facem este sa-l definim ca un artifact 
-trei sa definim folderu build ca si artifact asa ca adaugam pe acelasi nivel cu script:, artifacts: paths: -build/ , paths e o prop a lu artifacts deci trei sa fie sub el si identat cu 2 spatii mai la dreapta,  o sa arate asa:
-si sub paths, tot identat cu 2 spatii mai la dreapta, o sa avem lista 
-faptul ca punem un slash / dupa build, indica faptul ca nu este un file, ci este un folder 

  artifacts:
    paths:
      - build/

-dam commit si intram pe log sa vedem ce s-a intamplat 
-o sa vedem in dreapta log-ului Job artifacts si de asemenea si log-u s-a schimbat unpic si primim niste informatii aditionale in legatura cu artifact-ul si ne zice ca 7 artifacts au fost gasite si ca le da upload. Vedem si niste warning-uri dar e ok asa face gitlab
-daca dam pe browse, vedem folderu build ci niste file-uri in el si inca un folder 

Assignment: Adding a test stage 

-in loc sa dam $ ls -la dupa run build si sa verificam in log ca s-a creeat cu succes folderu build, vom face un testing stage cu un script care face asta pentru noi 
-deci creeam un nou job care testeaza acest artifact, care e in folderu build si in acest folderu vom vedea un file numit index.html si vrem sa verificam daca acest index.html este prezent si asta e un test pe care trei sa l scriem 
-la sf Assignment-ului, pipelineu trei sa arate asa: doua stage uri build si test, fiecare cu jobu lui build_website la build si test_artifact la test 

-deci, la stages: sus mai adaugam - test si dupa jobu de build_website adaugam un job de test_artifact cu imaginea alpine, pt ca acest job nu va avea nevoie de un node environment pt ca nu o sa vrem sa folosim comenzi ca npm, cu stageu test si la script punem comanda -  test -f build/index.html (-f testeaza un file oarecare). Path-ul file-ului poate fi obtinut usor daca dam inspect la artifacts la Browse si vedem ca avem index.html in folder build, deci ala va fi path-ul: build/index.html 
-!!! ATENTIE: by default, job-urile iau artifacts de la toate job-urile definite in stages-urile anterioare, aceste artifacts sunt downloadate in working directory-ul job-ului. Putem controla care artifacte sa fie downloadate cu prop. dependencies: in care specificam intr-o lista de la ca re job-uri sa downloadam artifacts 
-putem adauga si proprietatea dependencies in care restrictionam ce artifacts sa fie pasate unui job specific prin a defini o lista de job-uri de la care sa ia artifacts
-dam commit la schimbari si ne uitam la pipeline la jobu test_artifact si vedem ca singura comanda pe care am executat-o este cea de test -f build/index.html si pt ca acest file exista, jobu va fi pe success 
-daca ne uitam la logu jubului de testare, stim ca folderu build nu este parte din repository(la care se da checkout in fiecare job in fiecare imagine de linux), dar pentru ca am definit folderu build ca un artifact, acesta va fi pasat la jobu test_artifact 
-si vom vedea si o linie in log care zice Downloading artifacts, si va mai zice Downloading artifacts for build_website, deci artifacts-urile creeate de jobu build_website sunt downloadate aici, deci de asta avem acces la folderu build  
-daca in configuratia noastra, nu am fi definit artifacts: in jobul de build, intregul test ar fi dat fail, pt ca nu s-ar fi pasat acest folder de la un job la altu 
-deci asa am integrat un test foarte simplu in pipeline-ul nostru

Running unit tests 

-developingu de software nu este doar sa facem feauture-uri specifice, este crucial de asemenea sa ne asiguram ca viitoarele schimbari asupra codului nu strica neintentionat functionalitati existente 
-aici devine esential scrisul de teste. Testele sunt scrise la diferite nivele, care sunt adesea descrise de un model stiut ca si testing pyramid. Acest model ajuta developerii sa inteleaga echilibrul corect de teste care ar trebui scrise 
-la baza piramidei, vom gasi de obicei unit teste care sunt un tool fundamental in software development. Sunt facute sa verifice corectitudinea unei parti de cod izolata si mica. Asta poate fi o singura functie sau metoda 
-in context-ul framework-urilor frotend ca react, un unit test ar putea sa fie focusat pe o componenta specifica sa se asigure ca aceasta componenta se comporta cum ne asteptam in diferite conditii 
-sa zicem ca de ex, construim un calculator, in cazu acela un unit test ar putea sa verifice daca functia de adunare da return la rezultatul corect cand ii sunt date doua numere 
-intorcandu-ne la testing pyramid, putem vedea ca unit testele formeaza baza piramidei. Ele creeaza o baza wide pt ca de obicei avem multe unit teste. Sunt foarte rapid de executat si ne ajuta sa gasim probleme in mod explicit  
-micul proiect pe care il avem, are de asemenea unit teste 
-avem codul aplicatiei App.jsx unde am printat niste logo-uri si niste text, dar este si un test file echivalent, numit App.test.jsx in care avem cateva assert-uri 
-primu assert, adica primu describe este doar ca sa demonstreze cum functioneaza acest framework de testare. Deci, aici, ne asteptam ca daca adunam 1 cu 1 vom avea rezultatul 2, n are nicio trb cu aplicatia insasi, e doar un test aditional sa intelegem cum functioneaza aceste teste 
-apoi, in al dolea describe, avem componenta App in care verificam un text specific, in cazu asta verificam daca textu "Learn GitLab" este disponibil undeva pe ecran(pe pagina web)
-si incercam sa verificam si daca text-ul "GitLab logo" este prezent pe ecran(pe pagina web)
-deci acestea sunt testele pe care le avem si pt aplicatia asta basic sunt chiar ok 
-sa vedem cum se executa testu asta, pt asta folosim comanda urm in folderu proiectului: $ npm test  
-vedem ca e foarte rapida executia si vedem in consola un test result: in care vedem ca avem un test file care este passed deci ok si avem 3 teste in total care si ele au trecut foarte rapid 

-acum sa vedem cum putem sa facem acelasi lucru si in GitLab
-mai definim un stage numit -unit si dupa jobu test_artifact vom mai defini un job numit unit_tests 
-pt ca trei sa folosim comanda npm test, ne va trebui imaginea de node:22-alpine ca la jobu build_website si vom defini stage: unit 
-in script: vom cauta cateva comenzi , in primu rand ne va trebui $ npm test , dar nu va functiona doar cu comanda asta, deoarece testele astea sunt executate de un library numita Vi test 
-daca ne uitam in package.json, vedem ca "vitest" este o dependinta pt proiectu nostru, ceea ce inseamna ca daca nu rulam in pipeline $ npm install sau $ npm ci, dependinta asta nu va fi prezenta, deci testul nu o sa poata fi executat. De asta trebuie neaparat sa instalam si dependintele proiectului 
-putem incerca fara comanda asta de instalare sa vedem daca merge pipelineu, dar nu va merge garantat. Deci sa nu tinem niciodata nimic in pipeline daca nu stim daca avem nevoie sau nu de acel ceva. Il stergem, vedem daca mai merge pipelineu fara el si daca merge, ok
-in fine, dam commit la schimbari si ne uitam la pipeline, in care vedem ca avem 3 stage-uri, printre care si cel definit acuma numit unit cu jobul unit_tests in el 
-ne uitam in logu lui sa vedem ce se intampla si vedem ca la comanda npm test o sa avem cam acelasi rezultat pe care l am avut cand am executat comanda local
-vedem ca comanda noastra npm test face call la vitest si vedem un mic rezumat la ce s-a intamplat ca si cand am rulat comanda direct in terminalul nostru din proiect
-daca ceva ar fi dat fail, am fi vazut asta in reports-uri sau am fi primit o eroare care ar fi facut ca jobu sa dea fail si pipelineu sa dea fail de asemenea 
-deci, automatizarea acestui test este esentiala. Cand testele sunt automatizate, ele pot fi rulate in mod repetat fara interventii manuale
-deci, de fiecare data cand facem schimbari la repo, acest test va fi executat automat de asemenea, nu trei sa facem nimic, deci daca stricam ceva, testul o sa ne dea de stire si astfel salvam mult timp si efort 
-si in general, daca investim timp sa scriem teste bune, atunci salvam de asemenea timp cu testarea manuala si overall, avem mai multa incredere in softu pe care il facem 
-deci, testarea automata este o parte integrala a continuous integration, unde fiecare schimbare facuta la codebase este testata automat, asigurandu-ne ca daca este ceva gresit cu schimbarile pe care le facem, gasim eroarea aceea devreme in procesul de development 
-am putea zice, ca nu putem face continuous integration fara teste 

Running jobs in parallel 

-deocamdata, in pipeline-ul nostru, trebuie ca primul job de test(test_artifact) sa fie gata inainte sa fie rulat jobul unit_tests. Asta incetineste procesul degeaba si creste timpu de executie, are acu e peste 1 minut 
-sa dam merge la cele doua job-uri intr-unul singur ar fi o optiune, dar noi preferam sa le tinem separate. Aceasta separare ne asigura ca fiecare job are un scop clar si focusat, facand pipeline-ul mai usor de mentinut
-avand job-urile separate, o sa ne fie mai usor sa identificam probleme 
-daca un job foarte mare da fail, poate fi mai greu si mai consumator de timp sa gasim care e problema 
-putem sa ne acceleram executia pipeline-ului prin rularea acestor doua job-uri in paralel 
-o executie in paralel permite mai multor task-uri sa fie executate simultan 
-acuma o sa implementam acest approach:
-prima oara stergem stage-ul unit de la stages: si o sa asignam job-ul unit_tests in acelasi stage ca si test_artifact
-deci in cazul asta vom avea job-ul test_artifact si job-ul unit_tests asignate in acelasi stage, cel numit "test" si asta inseamna ca o sa avem doar doua stages 
-o sa dam commit la schimbari si o sa ne uitam la pipeline si vedem ca o sa avem cele doua job-uri de testare in acelasi stage si anume cel numit test, deci acuma aceste doua job-uri sunt executate in paralel 
-daca deschidem pipeline-ul cand job-urile sunt inca executate, o sa vedem ca cele doua job-uri test_artifact si unit_tests defapt ruleaza in paralel
-asta ne a salvat cateva sec din timpu de executie pt ca el este acuma de 50 de sec, fata de un minut nu mare mult, dar rularea job-urilor in paralel face o economie mare de timp 
-in meniul din stanga, la build la pipelines vedem o lista cu toate pipeline-urile precendente(versiunile anterioare commituite) si daca apasam pe status, o sa ne duca la pagina unde vedem build-urile si job-urile acestora cu bifele verzi si etc. Putem da si pin la Pipelines din meniu Build 

Default GitLab pipeline stages 

-putem sa stergem partea de stages: de la inceputu file-ului de configurare si pipelineu o sa mearga ca si inainte 
-vedem in pagina cu stages si jobs ca arata exact ca inainte cele doua stage uri cu job-urile lor 
-cum e posobil asa ceva? by default, github a definit deja niste stage-uri: build, test and deploy 
-de asta, cand asignam job-uri la stage-urile build si test, pipelineu functioneaza absolut la fel pt ca configurarea pipeline-ului by default contine deja asta 
-deci trebe sa ne imaginam ca daca nu scriem nimic la stages(nici macar stages:), vom avea by default asta:

  stages:
    - .pre 
    - build:
    - test:
    - deploy:
    - .post 

-in plus, sunt doua stages aditionale care sunt definite
-primul este - .pre , care este inainte de - build si va fi si executat inainte de - build 
-deci, daca este ceva ce trebuie sa se intample cumva inainte de build 
-si este, de asemenea, un - .post stage care e de asemenea predefinit si are loc dupa toate celelalte stage-uri 
-deci putem asigna job-uri la oricare dintre aceste stage-uri fara sa trebuiasca sa definim acest proprety numit stages: . Deci daca astea sunt toate stage-urile de care avem nevoie, nu trebuie sa scriem aceasta configuratie de mai sus pt ca ea exista by default in spate si putem folosi ce ofera GitLab
-e bine totusi sa avem stage-urile definite in configu pipeline-ului ca sa inteleaga usor cine se mai uita peste acest config de unde vine ordinea respectiva de stage-uri 
-deci cand vedem un pipeline care nu are stage-urile definite, stim ca GitLab le-a definit deja oricum 

Publishing a JUnit test report 

-de obicei, nu avem doar 2,3 teste care ruleaza, am putea avea sute si daca ceva da fail, nu o sa fie foarte usor sa mergem prin console output si sa ne dam seama exact ce a dat fail si ce s-a intamplat 
-partea buna e ca cele mai multe tool-uri de testare dau publish la report-uri. Report-ul pe care il vedem in logu pipeline-ului e numit report CLI pt ca raporteaza direct la CLI  
-dar, deseori sunt si alte report-uri, aceste teste pe care le rulam aici sunt configurate sa genereze si un report JUnit de asemenea 
-in file vite.config.js este descrisa toate configuratia pentru teste 
-vedem ca avem acest reporters: ['verbose', 'junit', 'html'] care sunt prezentati aici si este un report junit care a fost configurat 
-in general, un report JUnit este un file generat de framework-ul de testare JUnit in proiectu java, deseori intr-un format XML, care pt oameni este foarte urat de privit dar merge bine pt calculatoare 
-asest report JUnit da informatii despre rezultatele test case-urilor care include un status pass/fail, timpi de executie, mesaje de eroare, statistici sumare, etc . Deci e ok de navigat prin acest report 
-aceste rapoarte sunt esentiale pentru workflow-urile de continuous integration pt ca permite echipelor sa evalueze automat calitatea codului, sa identifice regresii si sa se asigure ca noile schimbari de cod nu fac probleme in timpul software development-ului 
-proiectul nostru nu foloseste java sau JUnit testing framework, dar poate totusi genera rapoarte in acest format JUnit care este atat de raspandit, incat toate sistemele CI/CD stiu cum sa lucreze cu el 
-si de asemenea, GitLab stie cum sa lucreze cu acest aproape standard format JUnit 
-acest format JUnit o sa fie disponibil, cum zice si linia de config, in folderu reports din root-ul proiectului si se va numit junit.xml 
-in aceasta lectie vom publica acest raport JUnit care deja exista aici 
-ne intoarcem la configu pipeline-ului si la jobul unit_tests vom defini ca si artifact acest raport JUnit. Vom folosi aceeasi structura de artifacts ca si mai devreme, dar va fi unpic diferita 
-deci sub "artifacts" (la nivel cu script:) vom avea o propietate identata numita "reports:" si sub "reports:", vom avea o propietate identata numita "junit:" 
-folosirea acestei structuri specifice, il ajuta pe GitLab sa inteleaga ca la ce da provide aici este un JUnit report si GitLab va stii cum sa interactioneze cu GitLab 
-luam pathu de la report din vite.config.js: ./reports/junit.xml si il punem la junit: 
-in puls, vrem sa publicam acest report fara sa conteze daca jobu a fost sau nu successful 
-cu alte cuvinte, daca jobu da fail, vrem ca totusi sa avem acces la acest report. Si pt asta, vom mai adauga o conditie aici, chiar sub artifacts: identata when: always
-deci acest raport va fi mereu published indiferent de ce se intampla(da sau nu fail jobu)
-diferenta fata de ce am facut inainte la build_website in artifacts: este ca nu avem proprietatea paths: ci doar definim aici in reports: 
-deci chiar daca si astea este un artifact(cel din unit_tests), este unul mai diferit, unul mai special cu care GitLab stie sa lucreze 
-dam commit la schimbari si ne uitam la pipeline sa vedem cum arata 
-dupa ce dam click pe bulina verde de langa commit de deasupra la repo din pagina de home a proiectului sa zicem o sa vedem ca avem 3 tab-uri, Pipeline cel care se deschide by default, Jobs, al doilea si Tests al treilea 
-intram pe tab-ul de Tests, unde vedem ca avem un 3 nou in dreptu la Tests 
-si vedem aici jobu unit_tests, pt ca testele vin din jobu unit_test si dam click pe job name si vedem ca vin dintr-un file anume src/App.test.jsx , avem si numele testelor, putem da si pe View details daca sunt detalii relevante care au fost adaugate aici
-si este mai usor sa navigam prin teste de aceea le dam publish asa 
-deci e o integrare mai buna intre reporter si GitLab 
-putem sa mergem si in unit tests de la pipeline si intram pe log, nu o sa vedem la Job artifacts acest file(junit.xml) pt ca in configuratia noastra nu am specificat un path 
-deci daca vrem sa avem oportunitatea sa inspectam manual artifacts-urile pe care le publish-am, putem sa facem si o configuratie similara cu cea din jobu build_website cum am facut pt build 
-deci am putea teoretic sa dam publish la tot folderu reports daca am fi vrut in aditie la reports-urile de configuratie pe care le avem aici, dar strict vorbind asta nu e necesar si asta este tot ce avem nevoie pt a publica acest JUnit report 

Testing the tests(ensure that the tests fail)

-trebe sa ne asiguram ca testele mai dau si fail, ca de aia sunt teste. Daca nu dau fail niciodata ar putea fi ceva gresit cu ele 
-mergem in vite.config.js si schimbam build directory-ul. Acuma el este setat ca fiind 'build' in build: { outDir: 'build'} si o sa l schimbam in build-tmp 
-acuma build directory-ul nostru o sa fie in alta locatia deci ne asteptam ca testu nostru(test -f build/index.html) sa dea fail, pt ca build directory nu mai este la path-ul respectiv(build/)
-in plus, artifact-ul din build_website va incerca sa dea publish la ceva ce nu exista in acel path, deci o sa fie interesant de vazut ce se intampla 
-in plus, mergem si in App.jsx si stergem logo-ul GitLab din cod hrefu, sa vedem daca este un test trigger-uit de asta
-defapt testul pe care vrem sa l trigger-uim este acesta din App.test.jsx unde zice shows the GitLab logo, deci ne asteptam ca testu acesta sa dea fail pt ca am comentat hrefu cu logo din App.jsx
-deci dam commit la schimbari si ne uitam la pipeline sa vedem cum da fail 
-mergem la pipeline si vedem ca build_website a fost successful si test_artifact a dat fail deja si unit_tests o sa dea fail si el 
-ne uitam la build sa vedem ce s a intamplat aici si ce s a intamplat cu artifact-ul 
-si vedem ca acuma am creeat tot in build-tmp si in termeni de uploadarea a artifact-ului, avem o eroare care zice: No files to upload, dar asta nu previne job-ul din a fi successful 
-deci daca ne asteptam ca daca nu sunt artifacts-uri de gasit, GitLab o sa crape, raspunsu e nu. Jobu o sa fie pe succes chiar daca nu sunt artifacts in path dupa cum am specificat 
-pe logu de la test_artifact si vedem ca singura comanda pe care o avem cea de test -f build/index.html a dat fail pt ca nu gaseste acest file la pathu asta si da alarma ca nu gaseste fileu pe care se astepta sa l gaseasca la pathu specificat 
-daca mergem pe jobu unit_tests vedem ca e mai mare si la un mom zice ca nu poate gasi gitlab logo 
-daca mergem la tabu de Tests, si dam pe unit_tests, vedem ca avem un test picat si aici ne arata acelasi lucru, ca in App.test.jsx, testu App > shows the GitLab logo a picat 
-e unpic mai usor sa vedem ce s a intamplat si ne da si informatia asta si daca dam pe View details, o sa ne dea logu job-ului unde vedem asta: Unable to find an element with the alt text: GitLab logo si o sa ne dea informatii tehnice cu ce e pe pagina, ce s a intamplat si asa 
-deci din perspectiva asta, sa avem JUnit test reporteru configuat calumea face navigarea prin teste care au picat mult mai ok 
-deci, piopelineu nostru a trecut testu de testare a testului, ceea ce e bine, acuma dam revert la schimbari
-putem face asta direct din meniul din stanga la Code -> Commits ceea ce ne va da o lista cu toate commits-urile, intram pe ultimul si daca mergem in dreapta sus la dropdownu Options si selectam Revert 
-asta va da Revert in branch-ul main, nu vrem sa pornim un nou request de merge, deci debifam optiunea aia si dam click pe Revert 
-acesa este la randul lui un commit de asemenea care o sa triggeruiasca pipelineu sa fie executat iar si vedem ca o sa treaca acuma ca si inainte si codu la fel o sa dea revert in browser ide si in vs code daca dam reload window

Configuring Merge Requests 

-ca sa creeam merge requests in gitlab trebuie sa configuram cateva lucruri 
-in meniu din stanga mergem la Settings -> Merge requests 
-Merge method impacteaza cum este creeat git commit history cand folosim un merge request 
-o optiune ok de folosit este Fast-forward merge option, care previne creearea de merge commits si mentine history-ul mult mai curat 
-in plus, putem da enable la sqashing commits direct in GitLab
-sqashing commits e folositor cand dam push la mai multe changes pe un branch in loc sa dam merge la toate schimbarile individuale in branchu main, ele sunt combinate intr-un singur commit  
-deci selectam Encourage 
-la sectiunea Merge checks in termeni de setari in primu rand vrem sa ne asiguram ca pipelienu da succed before merging any changes 
-deci asta inseamna ca merge requestu no poate fi merged daca pipelineu da fail, ceea ce are sens 
-mai avem aici o setare: All threads must be resolved , pe care o explicam:
-ca parte a procesului de code review, alti developeri ar putea creea discussion threads, deci ar fi ok sa dam enable si la optiunea asta sa ne asiguram ca toate obiectiile sunt documentate in conversation threads care au fost rezolvate si inchise 
-asta ne asigura ca nu e niciun comment care a fost ignorat si requestu de merge este merged oricum 
-ultima setare pe care vrem sa o mai schibam aici este Target project. Din moment ce lucram pe un fork, trebuie sa schimbam setarea din Upstream project(proiectu original) la This project(proiectu nostru)
-Upstream project e proiectu de unde am dat fork si vrem, de fapt, sa creeam un merge request doar pe This project(proiectu nostru)
-acuma ca am configurat toate aceste setari, dam Save changes 
-acuma mergem tot la Settings -> Repository si dam pe Protected branches
-aceasta parte din configurare ne permite sa protejam branchu main de commit-uri directe si sa fortam developerii sa creeze merge requests
-deci o sa schimbam setarea Allowed to push and merge din Maintainers in No one 
-deci nimeni nu va fi lasat sa dea push si merge pe acest branch, adica nu vom putea sa mai facem schimbari directe pe acest branch 
-asta e tot ca sa putem face merge requests 

Making changes through a Merge Request

-acuma ca am facut configuratiile pt merge requests sa vedem si cum facem primul nostru astfel de request
-facem o schimbare in fileu README.md(documentatia proiectului). md vine de la markdown care e un format folosit de obicei pt scrierea documentatiei in acest fel de proiect 
-o sa mai adaugam cateva informatii despre cum sa fie build-uit acest proiect: adaugam o linie cu ## Building the project si intre dastea ``` ... ``` o sa punem cele doua comenzi npm install si npm run build pt a buildui appu 
-mergem si dam commit si o sa primim o eroare ca nu avem voie da push pe acest branch 
-deci acuma nu mai putem face schimbari cum faceam inainte, dar ni se da optiunea(in web ide) sa facem alt branch si sa dam commit. Daca suntem totusi pe vs code putem da pe cele 3 puncte de la source control si la Branch -> Create branch. Daca suntem pe web ne cere direct numele noului branch ope care sa dam commit 
-cand lucam la un nou feauture, creeam mereu un branch nou fata din main, pt ca vrem ca mereu updatati la zi cu alte schimbari care au fost deja integrate
-la denumirea branch-ului putem avea cv probleme. De obicei, organizatiile au un naming convention ca si a pune un prefix ca si branch name sau o structura specifica 
-de ex, un prefix ar putea fi feauture si numele feature-ului e improve-docs, deci am putea avea: feature/improve-docs. De asemenea, putem evita spatii sau oricare alte caractere in numele branch-ului ca sa facem lucrurile mai usoare.
-deci o sa punem numele asta: feature/improve-docs si dam Publish Branch cred, dupa care putem da commit la schimbarile din readme.md pe acest branch nou 
-daca vrem sa schimbam branchu, dam click in josul ide-ului pe numele branch-ului actual(feature/improve-docs), care are langa un icon de Git gen, si ne pune sa alegem in sus-ul ide-ului dintre cele doua branch-uri sau putem creea inca un branch daca vrem 
-acuma o sa mergem pe browser pe GitLab pe proiect si vedem ca sus o sa ne apara pe fundal verde un propmt pt a creea un merge request 
-daca mergem la Pipelines, vedem ca avem un pipeline care a fost deja executat cumva de la schimbarea facuta pe noul branch(feature/improve-docs) 
-daca ne uitam unpic pe history, vedem ca toate celelate pipeline-uri au fost executate against the main branch 
-acuma ultima execute de pipeline a fost executata pe noul branch si putem intra pe el si sa vedem daca executia a fost succssful(a fost), daca dam pe Passed, si putem vedea si schimbarile din commit daca dam click pe commit message 
-ca sa integram schimbarile, tre sa ne intoarcem pe main pageu proiectului, unde ne aparea promptu de Create merge request sau putem merge direct la Merge requests in meniul din stanga, unde putem da New merge request, dar aproape mereu o sa primim acest promt verde cu Create merge request pe care il regasim si aici in pagina dedicata MErge requests, care o sa ne faca viata mult mai usoara 
-asa ca dam pe Create merge request pe prompt. E important sa punem un titlu clar. De obicei, o sa fie multe merge request-uri care sunt deschise si care asteapta sa fie merged si cineva care se uita pe aceste request-uri trei sa inteleaga foarte rapid despre ce este acel merge request 
-deci pe langa un titlu clar si descriptiv, vrem sa includem si o descriere in care explicam pe scurt schimbarile 
-asta ajuta review-erii sa inteleaga scopul si importanta acestui merge request. Putem sa punem screenshots sau orice alta informatie care e relevanta sa ajute pe oricine altcineva sa inteleaga care este treaba cu acest merge request si de ce aceste schimbari trebuie sa fie merged 
-deci, la Title putem pune "Improve documentation" si la Description putem pune "Improved documentation by explaining how to build the project." 
-pentru acest merge request, e posibil de asemenea sa dam provide la un template pe care fiecare merge request il va avea
-mereu cand deschidem un merge request o sa fie doar prefilled cu un template 
-putem de asemenea sa adaugam checkbox-uri daca vrem, ca de ex o lista cu toate astea: - [ ] It works on my computer - [ ] I've did a manual test - [ ] I've executed all tests - [ ] I didn't just copy/paste this code from ChatGPT 
-in plus, daca dam scroll mai jos, putem creea si Labels, daca e un proiect mai mare si poate vrem sa folosim un label pt diferite categorii: poate avem un label pt Bug fixes, poate avem un label pt Documentation... Deci posibilitatile sunt nelimitate in termeni de labels 
-putem alege si Asignee si Reviewer 
-dupa, mai la final, avem Merge options. Deci cand acest merge request a fost merged, branch-ul sursa(feature/improve-docs) o sa fie sters, pt ca mai mereu, dupa ce se face merge-ul, nu vom mai avea nevoie de branch-ul respectiv, deci e ca o forma de a face clean-up la chestii
-si pe langa asta, mai avem o setare care se refera la squahsing the commits, deci o sa primim un prompt despre asta 
-acuma dam pe Create merge request 
-dupa ce creeam merge requestu, daca vedem ceva gresit cu titlu sau cu descrierea, putem da click pe Edit in stanga sus 
-cam asta e workflow-ul tipic, putem bifa checklist-urile sa ne asiguram ca am verificat cateva chestii inainte sa facem acest Merge request 
-in puls, aici mai vedem si pipelineu. Si vedem ca acest pipeline asociat cu acest branch(feature/improve-docs) care e asociat cu acest Merge request, a fost successful, deci vedem ca totu e ok 
-pe langa asta, avem aici si cele 3 unit teste trecute din App.test.jsx si ca totu este gata pt Merge 

Code review and merging changes 

-urmatorul pas important pt un merge request este procesul de review, adica code review-ul 
-implica unul sau mai multi team memebers care dau review la schimbari si dau feedback dupa 
-review-urile de cod sunt importante pt ca ajuta la gasirea greselilor si ne asigura ca codu este clean si are good practices si permite membrilor echipei sa invete unul de la altul care este probabil cel mai important aspect
-daca suntem nesiguri unde sa localizam un merge request, trebe sa ne uitam in meniu din stanga la Merge requests 1. Acel nr 1 indica cate request-uri deschie avem 
-deci, ca developeri, ce facem de obicei, din cand in cand, ne uitam la Merge requests si daca observam ca este ceva acolo in lista de Open merged requests, ar trebui sa ne uitam si sa vedem ce se intampla 
-cand facem un review, citim titlu si descrierea si dupa mergem la tabu de Changes pt ca vrem sa vedem ce s-a schimbat si in cazu asta, GitLab ne ofera toate file-urile care au fost schimbate si in cazu asta ni le da cu verde intr-un diff 
-deci diferenta, in acest caz, dintre main branch si branchu pe care l-am creeat aici si vedem ca sunt cateva linii care au fost adaugate 
-ca si aprte a procesului de review, ceilalti pot lasa comentarii sau sa inceapa discussion threads direct pe linii specifice de cod 
-aici la merge review, la changes, daca dam cu mouseu peste nr liniilor vedem ca putem sa adaugam un comment
-in acest caz, avem doua optiuni: avem optiunea de a incepe in review si mai avem optiunea de a adauga un comment acum pe care o sa o alegem 
-comentariul a fost adaugat si o sa vedem ca este un thread nerezolvat in dreapta sus
-daca ne intoarcem pe overview-ul request-ului, vom avea Merge blocked si un semn rosu fix sub Test summary si o sa mai scrie ca sunt niste discutii nerezolvate 
-deci trebe ca mai intai sa rezolvam aceste discutii. putem merge pe Go to first unresolved thread, si ne duce la schimbarea codului si la commentu nostru 
-putem intra si la Changes sa le vedem, unde am dat si comment defapt. Putem da si reply la acest discussion sau putem da Resolve thread, in cazu in care am lamurit situatia prin alte cai de comunicare 
-cealalta optiune de a lasa commnet-uri este prin a da start la un review 
-diferenta este ca atunci dam un comm pe un line si alegem sa dam Start a review in loc de Add comment now, comm-ul nu este defapt published
-pt review-uri mai lungi, uneori am putea avea o opinie aditionala despre ceva, dar poate dam miss la niste aspecte importante si daca scriem primii comm-urile si doar atunci la sfarsit dam click pe Finish review, si astfel publicam acest commit, doar atunci vor fi public accesibile 
-sa zicem cainitial am crezut ca ceva nu e ok, dar mai incolo ne am uitat pe cod si ne am dat seama ca defapt e ok. Daca dam publish la comm imd, cineva ar putea deja sa inceapa sa raspunda la el pt ca primesc o notificare, deci poate sa dea avoid la additional work 
-deci astea sunt cele doua approch-uri pe care le putem avea 
-daca dam Start review, dupa ce scriem comm-ul, putem da pe sagetuza de la Finish review o sa vedem ca avem cateva optiuni si aici, una este sa dam Request changes in care cerem schimbari ca nu e ok ceva. Mai avem Comment si Approve pe care o sa o si alegem si dam Submit review dupa 
-sa zicem ca am vazut comm-ul acela ca trei sa adaugam si teste, mergem in vs code si mai adaugam o sectiune in readme in care explicam cum sa rulam teste 
-adaugam indicatii ca tre sa rulam npm test dupa npm ci sau asa si dam commit si push pe branchu asta secundar feature/improve-docs 
-ne intoarcem pe merge request si vedem ca iar ruleaza pipelineu pt ca am dat push la schimbari noi, pe care le putem vedea si la tabu Changes si putem da Resolve la discutia pe care o aveam acolo la This is a comment  
-acest merge request include acuma 2 commit uri si sunt 2 pipeline-uri care au fost executate 
-avem si aprtea de Approval la care putem da Revoke daca nu mai suntem multumiti cu el si vedem acolo ca Approvalu e optional si daca dam lcik pe semnu de intrebare o sa ne duca la o pagina cu mai multe detalii despre asta. Pe free plan acest feature e foarte basisc deci approval-urile nu sont mandatory 
-mai sunt echipe care de obicei folosesc feature-ul Thumbs up sau down si au o intelegere de ex daca merge requestu are thumbs down, inca sunt discutii care trei sa se intample, deci merge requestu nu tre sa aiba thumbs down ca toate echipa sa fie ok cu schimbarile din merge request 
-dar noi o sa zicem ca pipelineu a trecut, toti sunt fericiti, toti si au dat approvalu si apoi daca totu este gata, putem merge la partea unde zice Ready to merge! 
-asta este cea mai importanta parte din tot Merge reqestu, vrem sa ne asiguram ca totu merge ok 
-aici la Ready to merge o sa fie sters source branchu(asta nou pe care l am creeat pt commit-urile pe docs) si o sa dam sqash la commits pt ca am facut 2 schimbari 
-in plus, vrem si sa Editam commit messageu sa ne asiguram ca schimbarile carora le dam push aici sunt corecte 
-devi avem Improve Documentation, dar putem folosi si alte mesaje de commit din dropdownu din dreapta sus fata de comm 
-putem acuma da insfarsit Merge si acuma asta a fost merged, nu mai este un open request, deci daca mergem la Merge requests, vedem ca la tabu Open avem 0 si avem la Merged 1 
-si daca ne uitam la Pipelines, vom vedea ca pipelineu este running pentru branchu main 
-deci rerulam pipelineu pe main branch doar ca sa ne asiguram ca totu inca merge cum trebe pe main branch 
-deci este important sa rulam pipelineul din nou, chiar daca a fost executat pe branch, doar ca sa ne asiguram ca stagiile de build si test merg si nu sunt probleme de integrare 
-rar se poate intampla ca pipelineu sa dea fail pe main branch, dar depinzand de configuratie se poate intampla deci vrem sa ne asiguram ca branchu main inca merge cum trebe 
-deci nu este un pas redundant, este un pas critic sa ne asiguram ca totu functioneaza corect. Nimic nu e mai important in CI/cD decat integritatea main pipeline-ului pt ca asta reflecta calitatea proiectului 
-deci cam asta e procesu de a creea un branch, un merge request si sa avem schimbarile integrate in main branch printr-un merge request 
-pt ca am sters branchu pe care l am folosit sa lucram, deci branchu feauture/improve-docs nu mai exista 
-deci tre sa schimbam branchu la source control in ide sa evitam probleme 

Configuring a code linter 

-cand mai multi devi colaboreaza pe un proiect, e important ca toti sa scrie cod intr-un stil similar ca sa fie codu mai usor de inteles si de mentinut nu doar de catre autorii originali, ci pt oricine ar putea lucra pe proiect in viitor 
-ca sa facem asa, de obicei, folosim un tool numit linter care e un program care verifica codu pt lint, adica pt erori mici sau probleme de stilizare care pot face codu mai putin curat sau mai greu de menegiuit 
-deci rolul tool-ului este de a face clean up la code si de a depistsa micile chestiute care nu sunt chiar ok 
-in software development, un linter nu repara automat orice pt noi, doar ne raporteaza problemele gasite 
-proiectu asta are deja un linter configurat numit eslint care e comun pt proiectele de javascript 
-sa poata genera un report din ESLint pe care GitLab sa il poata intelege, proiectu nostru foloseste o depdeninta npm aditionala, care e un formatter facut pt GitLab
-deci e asta deja configurat in proiect
-acuma o sa facem un branch nou numit feature/add-lint 
-documentatia pt dependinta npm ESLint Formatter for GitLab contine deja ce putem folosi https://www.npmjs.com/package/eslint-formatter-gitlab
-numele job-ului nu prea conteaza dar trei sa punem imaginea de node 22 alpine in loc de node 20 si in loc de a doua comanda din script vom folosi $ npm run lint 
-aceasta comanda $ npm run lint este aceeasi cu comanda care e definita aici in package.json 
-deci mereu cand rulam orice comanda cu npm run, de ex build, defapt rulam comanda care este definita in package.json la scripts, de ex "build": "vite build", in cazu nostru va fi $ npm run lint, deci va fi defapt "lint": "eslint --format gitlab ."
-deci deja e configrata intr-un mod sa folosim GitLab ca si reporter 
-in gitlab-ci la eslint: avem si sectiunea de artifacts: si de data asta folosim un codequality report, deci e ceva care se va integra automat cu GitLab 
-dam commit si ne uitam in GitLab la Merge requests si dam Create merge request pe promptu verde care ne apare 
-pastram titlu cum este si toat ecelelate default-uri si dam Create la sfarsit 
-si pt ca nu am asignat niciun stage: la acest job o sa fie parte din test stage si vedem pe bulina din dreptul pipelineului din merge request ca o sa apara ca un job in test stage practic 
-de obicei, dupa ce pipelineu a fost executat, toata interfata user-ului pt merge request ar trebui sa se updateze automat, in sensu ca o sa fie ready to merge in loc de blocker cu rosu si o sa avem cele doua stage-uri bifate cu verde in dreptu lu Pipeline 
-dam refresh pana ne apare deasupra la Test summary Code Quality hasn't changed, asta e partea care e cea mai importanta
-vrem sa ne asiguram ca totu a fost publicat cum trebe, intram in dreptu la Pipeline pe a doua bulina verde corespondenta Stage-ului de Test si dam pe jobu eslint
-ne va duce pe logu job-ului si daca ne uitam vedem ca se executa cele doua comenzi si dupa vedem ca se Uploadeaza si artifacts-ul specificat de noi gl-codequality.json
-deci acesta exita si a fost gasit apoi va fi uploadat 
-acuma ne vedem nimic pt ca nu sunt erori, deci urm pas ar fi sa introducem o eroare mica in codu nostru ca sa gaseasca ceva linteru si sa ne raporteze apoi problema noua 
-mergem la src in App.test.jsx si declaram o variablia let foo; in primu describe in it pe linia 7 inainte de expect 1+1 si dam commit 
-in merge request vedem ca iar se schimba interfata grafica, mergeu va fi blocked si pieplineu se executa iara 
-si vedem ca jobu eslint o sa dea fail si daca intram pe log-ul lui si vedem ca ne da o eroare ca avem o variabila nefolosita declarata 
-informatia asta e vizibila si pe Merge request la Code quality scans founf 1 new finding dam pe sageata dropdown si vedem ca aceeasi eroare ca in log: Major -foo is defined but never used 
-si sub acest mesaj de eroare Major avem si un path cu locatia erorii(path-ul si numele fileului plus linia la care se afla eroarea): gl-codequality.json
-daca dam pe el o sa ne arate exact fileu App.test.jsx si linia de cod 7 highlighted: let foo;
-si de asta Mereg requestu e blocked cu bulina rosie pt ca jobu a dat fail si nu putem da merge pana nu reparam problema cu linteru 
-acuma am vazut cum se configureaza linteru(job-ul eslnit) si cum il putem integra intr-un Merge request, deci putem da Close merge request asa cum e pt ca nu vrem sa complicam pipelineu inutil 
-acuma, am dar Revert la ultimu commit si ca sa fie totu ok, intram si pe vs code si dam la Source Control la alea 3 puncte dam la Pull -> Pull(rebase)

How to structure a pipeline?

-cum am structurat noi pipelineu, e doar un exemplu, nu e vreo regula scrisa, dar sunt cateva principii pe care sa le luam in considerare
-in geenral, timpu de executie al pipeline-ului este un key concern, acuma pipelineu e executat in 51 sec 
-cum ordonam stage-urile si job-urile joaca un rol important in cat de rapid este executat pipelineu 
-diferite limbaje de programare si tehnologii ar putea avea nevoie de o ordine diferita 
-avem doua principii sau guideline-uri pe care ar trebui sa le consideram in acest punct 
-in primu rand, job dependencies care sunt unpic ne-negociabile si trebuie sa intelegem depdentintele dintre job-uri 
-in acest caz, avem build stage si avem si test stage 
-ne asumam ca tot ce este in test stage are o dependinta in build stage, dar defapt singuru job care are o dependinta este test_artifact(din cauza artifact-ului care este testat -folderu build produs in jobu build_website in stageu de build)
-celelate doua job-uri eslint si unit_tests pot fi executate chiar si inainte de test stage 
-e posibil sa le punem si intr-un pre stage sau doar eslint in pre stage si sa le executam pe ele primele 
-cum se reflecta asta in timpu total de executie al pipeline-ului este alta treaba 
-dar ideea principala aici cu build_website si test_artifact este ca aceste job-uri trei sa fie in stage-uri separate  
-nu putem sa testam daca exista artifactu inainte ca acesta sa fie creeat 
-suna logic, dar in practica multi oameni pot fi confuzati ca pica anumite teste dar nu realizeaza ca defapt, ca pentru ca un anume test sa dea succeed(test_artifact), build_website trei sa fie executat primu 
-deci este esential sa stim aceste dependinte, relatii dintre job-uri 

-alt guideline pe care ar trebui sa il consideram este failing fast 
-cum ziceam mai devreme, viteza este o consideratie majora. Nu vrem sa asteptam sa ruleze pipelineu 10 minute doar ca sa avem un linter la sfarsit care da fail 
-si daca asta se intampla des, ar trebui sa executam astfel de job-uri mult mai devreme in pipeline 
-in general, vrem sa ne asiguram ca cele mai comune motive pt care un pipeline ar putea da fail, sunt detectate devreme
-de ex, rularea job-ului eslint care dureaza doar 30 de sec, este o folosire mai buna a timp-ului nostru comparat cu punerea eslint-ului intr-un stage overall, unde poate alte job-uri dureaza cateva min sa se execute 
-tot trebuie sa asteptam pt toate acele job-uri sa fie gata si asta e doar un waste de resource 
-deci, in general trebuie sa avem grija cu job-uri care ruleaza in paralel 
-de obicei, vrem sa punem sa ruleze in paralel job-uri care au un timo de executie similar 
-daca de ex, un job tine doar 15 secunde si altu 5 minute, ar trebui sa ne gandim de doua ori daca chiar vrem sa le punem in acelasi stage 

Implementing CD with GitLab 

-o sa facem un deployment manual pe Netify, descarcam zipu build.zip si ii dam extract la folderu build 
-luam acel folder build si manual il uploadam pe Netify dupa ce ne facem cont cu GitLab de ex 
-si dupa upload o sa inceapta imd un deployment si by default o sa ne genereze automat un domain name 
-putem sa schimbam numele site-ului la Site configuration in meniul din stanga si putem sterge tot ce e acolo si sa punem numele learn-gitlab-demo si dam save 
-dupa asta, putem verifica aplicatia pe linku de sus din acest meniu site configuration si vedem ca merge 

Installing CLI tools 

-acuma trei sa vedem cum il facem pe GitLab sa deschida Netify, sa se logheze si apoi sa mearga pe acest site Netify, sa selecteze siteu nostru de la Sites, apoi sa mearga la Deploys si sa ia folderu build si sa ii dea upload
-nu trebuie sa o facem asa, tool-urile de automatizare ca GitLab nu deschid aplicatii, browsere si nu apasa pe butoane sau selecteaza path-uri
-nu asa merg lucrurile in lumea automatizarilor. Trebuie sa lucram mereu cu un tool CLI sa putem replica orice pasi manuali pe care ii facem 
-acuma din fericire, Netlify are un tool CLI numit Netlifi CLI, pe care il vom folosi sa interactionam cu Netlify ca un serviciu si sa creeam un deployment 
-acest CLI ii va permite lui GitLab sa interactioneze cu Netlifi si de ex, sa se logheze sa uploadeze file-uri si sa faca multe alte lucruri fara sa iasa din terminal, fara sa trebuiasca sa deschida un browser 
-este tot bazat pe linia de comanda, acuma ca sa folosim Netlifi CLI si GitLAb, trebuie sa il instalam prima oara cu comanda: 

$ npm install netlify-cli -g 

-fiind npm primu cuvant din comanda, vom folosi un package manager sa-l instalam si mai are nevoie de cel putin node.js 18.14.0 sau mai nouo 
-creeam un nou branch si in acest branch, vom creea un nou job. Numele branch-ului o sa fie: feature/netlify 
-deschidem configuratia si mai facem un job numit netlify deocamdata cu aceeasi imagine ca la build_website, node:22-alpine 
-folosim prestage-ul, deci vom avea stage: .pre , pt ca la acest pas in timp nu depindem de build, deci doar vrem sa instalam asta ca un tool si vrem sa ne asiguram ca merge 
-daca nu merge, vrem sa fim informati din timp in pipeline, ca sa nu trebuiasca sa asteptam dupa toti pasii sa se execute 
-la script, nu avem nevoie de npm ci pt ca nu interactionam cu proiectul propriu-zis, deci nu avem nevoie de npm ci 
-din documentatia Netlifi CLI copiem comanda de instalare a CLI-ului $ npm install netlify-cli -g 
-asta va instala Netlifi CLI, si -g de la final se asigura ca este instalata ca o dependinta globala, putem avea -g si dupa install dar nu cont unde e 
-acum sa verificam ca Netlify a fost instalat corect, adaugam in script si comanda: - netlify --version 
-dam commit la schimbari si ne uitam la pipeline. Avantajul ca am pus acest job in .pre stage este ca se executa primu si ne putem si uita pe log-ul lui inainte ca restu pipeline-ului sa se termine 
-ne uitam la rezultatul comenzii netlify --version si vedem ca este versiunea 19. Deci daca nu primim o eroare si primim ceva dupa comanda asta, inseamna ca instalarea a fost successful si asta e cel mai important 
-ne uitam la cat a a durat acest job si vedem ca a durat 46 de secunde si stim ca in general, doar pornirea imaginii docker pe care am mai folosit-o, dureaza cam 15 sec 
-si daca ne uitam atent la outputu comenzii de instalare a netlify-cli vedem ca scrie ca a durat 24 sec. Deci instalarea unui pachet npm in executia pipeline-ului ne costa 24 de sec, care e ceva 
-nu ne vom face nimic despre asta acuma, netlify este aici si o sa incepem sa l folosim pt deployment, care e scopu lectiei 

Storing project configuration in environment variables 

-urm pas sa pregatim GitLab sa da deploy la aplicatia noastra, este sa punem niste configuratii in pipeline 
-deci trei sa i zicem lu netlify CLI ce site vrem sa i dam deploy si asta se face prin a configura un environment variable 
-un environment variable este un sistem de sistem de operare
-in GitLab, environment variables sunt folosite sa stocheze si sa menegiuiasca configuration values care pot varia intre diferite environment-uri 
-de obicei, incercam sa stergem orice configuration settings din cod si din comenzi si sa folosim environment variables pt ca ne ofera mai multa felxibilitate 
-suna complicat, dar e destul de usor 
!!!-cel mai important lucru pe care trei sa ni-l amintim din asta este ca deseori folosim environment variables sa configuram tool-uri CLI 
-acesta este un concept cheie in devops 
-cand vrem sa folosim netlify CLI command, trebuie sa ii dam doua environment variables 
-una din ele se numeste NETLIFY_AUTH_TOKEN si cealalta se numeste NETLIFY_SITE_ID 
-ideea este ca Netlifi CLI se va uita automat dupa aceste environment variables cand da deploy la proiect 
-deci e important ca aceste environment variables sunt definite in pipelineu nostru GitLab si sa foloseasca aceleasi nume de mai sus, altfel nu vor fi gasite 
-vom invata cum sa definim un environment variable din GitLab configuration file 
-dar sa vedem mai intai care este value-ul pe care vrem sa il folosim 
-mergem inapoi pe Netlify, vrem sa ne asiguram ca avem siteu corect selectat 
-deci, oriunde am fi pe pagina, trebuie doar sa dam pe siteu nostru learn-gitlab-demo si sa mergem la Site configuration si aici ne intereseaza la Site information variabila Site ID 
-asta e infirmatia pe care vrem sa o punem in GitLab Site ID: e880dc5c-b07c-4ca0-8387-b740e27e9bff
-asa identificam acest site efectiv 
-ca prim pas, ce vrem sa facem este sa dam store la acest Site ID in configuratia pipeline-ului GitLab
-mergem in vs code si o sa definim in jobu netlify un environment variable 
-in GitLab sunt doua locuri unde putem defini variabile: putem defini variables intr-un job si putem defini de asemenea variabile in pipeline, asta se numeste top-level variable configuration 
-unde variabilele definite pt tot pipelineu sunt valide in tot pipelineu(top-level variable configuration)
-dar variabilele definite doar in job, cum vom face imd, vor fi scoped doar pt jobu respectiv, adica doar acolo le vom putea folosi/apela. Deci nu le vom mai putea folosi nicaieri, in alt job de ex. 
-sub stage, punem variables: si trei sa specificam netlify site id, deci e cel mai bine sa deschidem documentatia https://cli.netlify.com/commands/deploy/
-si de aici copiem NETLIFY_SITE_ID , trebe sa fie neaparat asa cum e pe docs, altfel netlify nu o sa poata citi aceasta informatie 
-sub variables, identat cu doua spatii mai la dreapta, o sa punem asa: NETLIFY_SITE_ID: 'e880dc5c-b07c-4ca0-8387-b740e27e9bff' pe acesta il luam din site configuration 
-acuma mergem la script: , unde vrem sa punem un mesaj gen Deploying to site id , pt ca asa putem sti ca acest env var este chiar definit si sa-i putem vedea in logs valoarea ei 
-sub script identnat la dr cu 2 sp punem: - echo "Deploying to site id $NETLIFY_SITE_ID" , folosind $ inainte de numele env var-ului, facem apel la valoarea acestei variabile 
-dam commit si stim ca nu o sa mearga, dar cautam mesaju de eroare 
-dar vedem ca jobu netlify a fost successful si a trecut, ne uitam pe logs si vedem ca avem acces la acest env var
-adica, daca ne uitam la comanda noastra de echo, vedem ca ne afiseaza site id-u pe care l am pus in variables: 
-asta inseamna ca am definit variabila cum trebe si este accesibila in script: . Asta e cel mai important 
-mai sunt doua moduri prin care putem accesa env varu asta site id 
-putem sa ii dam direct asa: - echo $NETLIFY_SITE_ID sau asa: - echo "Deploying to site id ${NETLIFY_SITE_ID}"
-si o varianta care nu o sa mearga niciodata este sa folosim '' in loc de "" , pt ca va trata tot ce e intre '' ca un stream, deci variabila noastra $NETLIFY_SITE_ID nu va fi inlocuita 

Managing secrets 

-chiar daca am instalat netlifi cli, chiar daca am configurat acest site id, nu inseamna ca gitlab e autorizat sa dea deploy la aplicatie 
-pt ca nu am dat credentialele, adica nu am dat numele si parola noastre, daca un deoployment ar fi posibil fara credentiale, oricine ne ar putea lua contu si sa dea deploy la alceva pe siteu nostru 
-tool-urile CLI ca Netlifi, de obicei nu folosesc o combinatie de username si password pt authentication, in locu lor folosesc cv numit tokens  
-termenu token in contextu de authentication e similar cu un token pe care l am folosi intr-un arcade 
-cum un arcade tocken ne garanteaza acces sa jucam un joc, un authentication token ne permite accesu sa performam actiuni specifice 
-ne putem gandi la un token ca un fel de parola temporara, ceva care da provide la acces la cont, dar nu e ceva pe care il putem folosi sa ne dam login pe siteu propriu-zis  
-decei ce o sa facem acuma, este sa generam un token si sa il stocam secure in gitlab 
-acest token ii va permite lu GitLab sa se autentifice cu Netlify si sa foloseasca Netlify CLI sa dea deploy la aplicatie 
-mergem pe netlify.com si in coltu din stanga jos, intram pe User settings si din meniu care apare aici, gasim OAuth 
-sectiunea care ne intereseaza este Personal access tokens si dam pe New access token, in descrierea lui zice ca poate fi folosit in shell scritps si pt API access 
-ideal ar fi sa dam o descriere tokenului, de ex, GitLab si lasam expirarea tokenului default la 30 zile si dam Generate
-asta e diferenta majora in comparatie cu o parola, ca putem sa setam tokenu sa expire si parola nu 
-asta ne va genera si afisa tokenu pe ecran 
-acuma lasam pagina asta asa cum e si mergem pe GitLab, pt ca trei sa gasim o cale securizata unde putem stoca acest token 
-mergem pe pagina cu proiectu nostru si la Settings, selectam CI/CD si dam pe Variables si aici putem defini variabile 
-avem doua seciuni, una e Group variables, deci e posibil in GitLab sa definim variabile la un nivel de grup si mai multe proiecte sa mosteneasca acele variabile
-si partea de care suntem interesati este Project Variables si o sa dam pe butonu Add variable din dreapta 
-suntem intrebati mai intai de Visibility si pt ca este un secret, nu vrem ca el sa fie vizibil in logu job-ului. Deci daca lasam pe Visible, va fi vizibil in job logs si oricine are acces la log-uri va putea sa vada secretu asta si nu vrem sa facem asta chiar daca e proiectu nostru personal, nu e un good practice sa tinem secrete in modu Visible 
-urm optiune e Masked, care se va asigura ca variabila asta nu o sa fie expusa in log-urile job-ului, ceea ce e un lucru bun, dar tot va fi vizibil aici in termeni de variabile. Deci daca cineva are acces la partea asta de "GitLab, o sa poata sa vada variabilele, deci o sa i vada value-ul 
-urm optiune e Masked and hidden, ceea ce inseamna ca odata ce punem variabila aici, nimeni nu o sa aiba acces la ea, deci nu o putem vedea aici, nu o putem edita ceea ce e super important 
-mai jos sunt doua flag-uri pe care o sa le dezactivam
-Protect variable: o variabila poate fi definita ca si protected ceea ce inseamna ca o sa fie disponibila doar pe anumite branch-uri care sunt protejate. In cazu nostru branchu main este protected 
-daca lasam flagu asta activat si definim aici o variabila, acea variabila nu o sa fie disponibila intr-un merge request. 
-acea variabila nu o sa fie disponibila cand creeam oricare alt branch si pt ca noi acuma facem developmentu dintr-un branch, o sa debifam aceasta optiune de Protect variable
-mai e si optiunea de Expand variable reference, e posibil sa avem o variabila in variabila deci o sa ii dam disable de asemenea si lu asta pt ca nu vrem nicio interferenta
-cea mai interesanta parte este aici la Key si Value 
-la Key, nu avem multa flexibilitate pt ca in docs la netlify trei sa salvam acest token cu numele asta: NETLIFY_AUTH_TOKEN , altfel netlift CLI nu o sa o poata gasi, ne asiguram ca nu sunt spatii pe la incept sau la sfarsit, fara new lines fara nimic 
-apoi, la Value luam cu copy paste tokenu pe care l am creeat pe siteu Netlifi si dam Add variable 
-variabila a fost adaugata si o sa i vedem numele si ca este MAasked si Hidden si chiar daca dam pe Edit nu o sa putem sa vedem valoarea 
-ne si zice jos ca valoarea e maskata si ascunsa permanent. Deci aeasta valoarea a fost securely stored by GitLab si oricine ar vrea sa o fure din aceasta interfata, nu va putea sa ii dea reveal si asta e o protectie de securitate 
-mergea si daca puneam aceasta variabila in gitlab-ci ca si site id, dar sunt f multe motive de ce este o idee proasta:
  -in termeni de security, sa punem credentiale direct in cod risca exposure mai ales daca oameni neautorizati acceseaza code baseu. Un sotre secured ca si cel oferit de GitLab, protejeaza aceasta informatie sensibila. Credentiale sensitive sunt leaked in fiecare zi pe repo-uri publice si chiar daca repo-ul este private, tot nu am vrea sa share-uim anumite credentiale cu oricine. Nu oricine care lucreaza pe proiect trebe sa aiba acces la secretu asta 
  -cand dam store la credentiale separat, cadn trei sa facem update-uri la un token sau la o parola, putem face schimbarile prin user interface fara sa trebuiasca sa facem schimbari la cod direct 
  -in cazu acesta cu variabila NETLIFY_SITE_ID , nu l am adaugat in cod pt ca e o idee buna, doar sa vedem si o alta cale de a adauga variabile intr-o configuratie 
  -la fel de bine, putem defini aceasta variabila in aceeasi interfata pe care am folosit-o sa definim variabila Token (Settings -> CI/CD -> Variables) si tot o sa fie disponibila. ASta ar ajuta cu mentenabilitatea, o vom simplifica overall 
  -in plus, avem support pt mai multe environment-uri: Cand dam add la o variabila avem sus Environments
  -deocamdata nu avem niciun environemnt si by default este selectat All(default) * 
  -dar putem avea mai multe sisteme IT, mai multe environment-uri si putem defini variabile care sunt valide doar pt un anume sistem 
  -asta ajuta mult si face acest intreg management de informatie, de variabile, de credentiale, mult mult mai usor 
  -putem avea variabile pt diferite invironment-uri ca de ex development, testing, production fara sa facem schimbari in cod, deci ne putem pastra configuratia de pipeline intacta si trebuie doar sa schimbam aceste environment variables aici si se va schimba modu in care aceste sisteme merg 
  -intr-un context enterprise, companiile sunt obligate sa foloseasca un sistem securizat pt credentiale din motive de securitate da si pt compliance
  -si destul de des acest fel de secure credential stores ofera capabilitati de tracking facand uso sa monitorizam cine poate sa acceseze datele si asa mai departe 
-o sa incercam sa dam leak la value cu comanda - echo $NETLIFY_AUTH_TOKEN , in script: si vedem ce se intampla 
-dam commit si ne uitam pe log si vedem ca apare cu [MASKED] outputu de la comanda adica nu este revealed de GitLab, asta inseamna sa fie masked 
-spre desebire de site id care nu e protejat sau mascat si e vizibil direct in print 
-deci o expunere accidentala in logs a acestui token este astfel mult mai dificila 

Deploying to production

-acuma vom folosi Netlifi CLI din GitLab sa dam deploy la proiect la environmentu de productie 
-prima oara sa testam setup-upu cu netlify status command doar ca sa confirmam ca am configurat toate aceste environment variables cum trebe
-mai adaugam o comanda sub cea cu version, de status, dam commit la schimbari si ne uitam la logs 
-totu merge ok, pt ca putem vedea useru curent si niste informatii despre site. Rularea comenzii de status e doar pt info si nu are legatura cu deploymentu prorpiu zis 
-dar se asigura ca credentialele si informatiile pe care le am dat sunt luate cum trebuie de Netlify ca in urmatoru pas cand incercam sa dam deploy, stim deja ca suntem pe drumul cel bun 
-vrem sa vedem Site id, si daca vedem si informatia pt useri inseamna ca deja am fost deja logati 
-ne intoarcem la configurarea pipeline-ului pt ca inca mai avem de facut cateva chestii 
-avem o dependinta la build jobs deci nu mai putem folosi acest .pre stage deci trei sa ne mutam codu job-ului in deploy stage 
-deci modificam din .pre in deploy si punem sus la stages: - deploy dupa test si stergem - .pre 
-comanda pe care o vom folosi pt deployment-uri este numita - netlifi deploy 
-si mai trei sa specificam si folderu de build 
-deci jobu de build_website o sa puna un website in folderu build ca un artifact(index.html) de care avem nevoie aici in jobu de deploy, netlifi
-si de aceea, trei sa i spunem lu netlify ca vrem defapt sa dam deploy la acest folder, deci de asta o sa il specificam
- - netlifi deploy dir=build/   ,putem sa ii punem si un spatiu in loc de semnu = 
-pe langa asta mai adaugam si un flag --prod inainte de --dir care indica faptul ca vrem sa creeam un production environment 
-deci o sa zicem ca acesta este siteu nostru principal, unde clientii si userii nostrii o sa acceseze siteu, si de asta il punem in production environement 
-dam commit si ne uitam la logs, vedem ca avem 3 stage uri build, test si deploy cu jobu netlify care a dat deploy la fileurile proiectului nostru 
-ultima comanda executata este cea de deploy si avem niste informatii tehnice peste care ne putem uita, dar cea mai importanta chestie e ca zice jos Job succeded 
-si deasupra la asta zice Deploy is live! deci deploymentu a fost succesful, avem si URL-u de la site daca vrem sa ne uitam peste el: https://learn-gitlab-demo.netlify.app
-vedem ca merge. deci asta e siteu nostru, merge pe netis infrastructure si am reusit sa automatizam toti pasii cu un pipeline simplu de la GitLab, deci ura! 

Smoke tests 

-trei sa ne asiguram ca o sa mearga si in viitor, de ex daca facem schimbari si rulam iar pipelineu?
-trei sa mergem la sfarsit inapoi sa dam pe website sa il deschidem intr-un browser si sa ne asiguram ca merge cum trebe 
-asta nu prea suna a automatizare 
-avem in pipeline teste prin care verificam ca avem artifactul corect si rulam niste unit teste dar asta nu ne zice totu despre site, nu stim daca aplicatia chiar merge dupa deployment si asta e o mare intrebare 
-in lectia asta o sa vedem cum sa facem ce este referit uneori ca si smoke test 
-si pt asta vom folosi o utilitate Linux foarte populara numita curl sa serveru web chiar serveste file-urile corect si ca aplicatia pe care o vedem acuma pe ecran(siteu cu 3 logo-uri) chiar este accesibila pt oricine altcineva 

-mergem si modificam unpic jobu netlify, deci fix dupa deployment vrem sa ne asiguram ca aplicatia merge corespunzator 
-bagam comanda curl(care ne returneaza htmlu cumva daca e ok siteu) dupa cea de deploy sa verificam siteu si il dam ca si parametru intre '' 
-apoi folosim caracteru pipe | ca sa trimitem rezultatu cu contentu site-ului comeznii grep(care da search in text) si ii dam ca parametru 'GitLab'
-deci daca primim inapoi ceva unde apare cuvantu GitLab suntem ok pt ca stim ca avem cuvantu GitLab afisat pe site undeva, deci trei sa fie si in html, deci ar trebui sa mearga fara nicio problema 
- curl 'https://learn-gitlab-demo.netlify.app/' | grep 'GitLab'
-dam commit la schimbari sa ruleze pipelineu, dar o sa dea fail pt ca comanda curl nu e instalata cu eroarea: curl: not found 
-deci curl nu face parte din aceastea imagine apline pe care o folosim, deci trei sa o instalam ca si parte din executie 
-aceasta este o utiliate linux, nu un node package, deci nu vom folosi npm install ca nu va merge 
-vom folosi comanda apk(alpine package managers) 
-deci folosim package manageru distributiei de linux alpine sa instalam curl si comanda pt instalare este numita add, deci vom baga inainte de curl comanda:
- apk add curl   , care va instala curl si o va face disponibila pt urmatoarea comanda pe care o avem
-dam commit la schimbari si vedem ca o sa mearga 
-ne uitam pe logu de la jobu netlify si vedem ca se instaleaza comanda curl si vedem logu de la instalare 
-si apoi mergem la partea in care executam efectiv comanda de curl si vedem cum comanda grep cauta in outputu comenzii curl si gaseste scris GitLab pe linia asta din index.html <title>Learn GitLab CI/CD</title>
-deci ce avem aici este un test foarte foarte basic caruia ii spunem deseori smoke test, care vine din testarea circuiteleor electronice sa vedem daca iese fum nu i bine 
-aceste smoke test se revere la teste initiale sa ne asiguram ca cele mai basic si critice functionalitati ale sistemului merg 
-scopu acestor smoke tests este sa elimine nevoia de a deschide manual un browser si de a verifica siteu 
-este foarte basic, daca pagina nu e accesibila, daca cuvantu GitLab nu e disponibil pe aceasta pagina, inseamna ca ceva a mers gresit cu deploymentu si trei sa ne uitam sa vedem ce e 
-nu ne asiguram ca siteu arata frumos, nu face nimic fancy, de asta zicem ca e un test foarte basic, dar totusi e mai ok decat niciun test 
-daca comanda curl da fail, trebe sa facem chestii manual sa identificam cauza problemei, daca e o configurare aiurea cu comanda, de ex nu a fost instalata ok utilitatea curl sau este vreo problema cu configurarea job-ului ca a dat fail partea asta, poate am sters cu totu cuvantu GitLab dupa pagina 
-deci sunt multe motive pt care comanda poate merge si poate sa dea fail
-deci e important sa intelegem care e root cause-ul, este o configuratie cu comanda sau este o problema cu deploymentu? 
-adica, daca incercam sa intram pe site intr-un browser si dam refresh nu se incarca nimic si nu merge nimic, asta nu are nimic de aface cu comanda curl, inseamna ca aplicatia efectiv nu merge 
-deci daca ceva da fail in pipeline, trei sa intelegem care e problema si daca e vreo indicatie ca ar putea fi o problema cu siteu, atunci trebe sa ne deschidem browseru, sa bagam linku sa dam enter si sa vedem daca siteu se incarca pe machineu nostru 
-suna basic dar multi se blocheaza la comanda asta si nu inteleg ce face exact: efectiv deschide siteu, descarca codu sursa al siteului adica htmlu
-daca dam view source pe site, o sa ne dea htmlu generat, deci asta e ce vede curl si pt ca in titlu o sa gaseasca comanda grep GitLab, e deajuns sa zica cv gen: da e ok siteu, se incarca cum trebe, il pot accesa, pot gasi gitlab si sunt ok cu asta 
-asta e tot ce face aceasta comanda si daca intelegem ce face, o sa avem o experienta ok cu ea, daca nu e nasol 
-dar in cazu asta, executia pipelienului e successful, siteu merge ok in browser, deci asta ne finalizeaza procesu nostru de deployment si acuma avem un pipeline unde dam build, test si deploy si dupa deploy rulam un test foarte simplu sa ne asiguram ca deploymentu a fost successful 

Conditional job execution with rules:

-facem un merge request cu branchu feature/netlify din main pageu proiectului, ne apare cu verde un pop up, si il denumim Deploy to Netlify si lasam defaulturile si dam Create merge request 
-acuma ne putem pune inrebarea: de ce ne am batut capu atata ca sa ne alegem cu un pipeline care ne lasa sa dam deploy in productie dintr-un branch sau dintr-un merge request 
-adica are sens sa dam deploy in production inainte ca merge requestu sa fie reviewed si approved si merged in branchu main de development? 
-raspunsu e NU, clar NU. N-are niciun sens sa dam deploy in productie dintr-un branch sau dintr-un merge request process
-in lectia asta o sa reparam asta, specificand cand jobu de deployment ar trebui sa fie executat 
-practic, vrem sa configuram GitLab astfel incat sa nu dam deploy la schimbari facute din orice branch si in loc vrem sa dam deploy doar la schimbari care au fost merged in branchu main
-si pt pipelineu nostru pe care il avem aici, cand il rulam dintr-un branch, vrem sa stergem stageu deploy
-adica pipelineu sa execute doar stage-urile build si test 
-si cand rulam exact acest pipeline pe branchu main, atunci sa avem toate cele 3 stageuri(si cel de deploy adica) 
-dar pentru merge request si pt branchu insusi, nu vrem sa vedem stageu deploy aici pt ca nu dam deploy in productie(unde sunt afisate stage-urile si job-urile pipelineului: Pipelines -> bula verde)
-sa mergem sa schimbam configuratia si o sa folosim o cale speciala de a include sau exclude job-uri, folosind rules 
-sa zicem ca in jobu netlify, sub stages: deploy(dar nu prea conteaza unde definim rules-urile), scriem rules: 
-o sa descriem rules ca o lista(cu mai multe proprietati, desi o sa avem doar una in cazu asta)  
-si regula este ca un if statement, deci trei sa comparam ceva si aici e partea unde lucrurile pot sa fie mai tricky si trei sa intelegem unpic conceptu de variabile predefinite 

https://docs.gitlab.com/ci/variables/predefined_variables/

-aici o sa fasim multe variabile care sunt deja predefinite de GitLab, adica ele sunt disponibile in timpul executiei 
-una dintre ele este: CI_COMMIT_REF_NAME(	The branch or tag name for which project is built.)	, pe care o vrem sa o folosim, pt ca aceasta variabila tine numele branch-ului cand pipelineu e executat 
-daca vrem sa vedem cum arata efectiv variabila, ii dam un echo in sectiunea script: a job-ului 
-mai e o susta sa dam comanda in script: -env , care va printa toate environment variables care sunt disponibile
-le vom vedea pe toate in log-uri si le putem sa vedem exact ce valoare are fiecare environment variable 
-deci, am zis inaite ca vrem sa executam acest job de deploy(netlify) doar daca suntem pe branchu main, deci conditia o sa arate asa:
- if $CI_COMMIT_REF_NAME == "main"
-mai tarziu, ne am putea decide ca branchu main nu este principalul nostru branch de development si vrem sa il schimbam sa fie altu, deci sa avem ceva hardcodat in cod nu e prea ok ('main')
-in loc sa facem asa, putem folosi alta variabila $CI_DEFAULT_BRANCH care ne va zice care este numele branch-ului default, in acest caz, aceasta variabila va avea numele 'main' , pe care l am hardcodat in build 
-dar in loc sa scriem efectiv 'main' in job, putem folosi aceasta variabila 
-putem sa punem tot ce e dupa if: intre '' , nu ca ar fi necesar pt ce avem acuma, dar daca scriem ceva mai complex, sa punem totu intre '' este in general, o idee buna 
-deci o sa arate asa: - if: '$CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH'
-sa dam commit la schimbari si sa vedem daca pipelineu care ruleaza pe branch, tot o sa includa acest job netlify sau nu 
-nu tre sa satam mult sa vedem cum va arata pipelineu 
-indata ce dam push la schimbari, pipelineu este creeat 
-intram pe merge requestu nostru Deplo to netlify si vedem ca se executa pipelineu, dam pe bulinuta albastra cu Running 
-si vedem aici ca avem doar doua stage-uri, build si test stage care sunt executate aici(pt ca suntem pe un branch de deployment si nu pe cel main)
-vrem sa testam sa vedem daca pe branchu main va rula stageu asta de deploy, asa ca o sa dam Merge la request (si butonu de Set auto-merge e ok daca nu vrem sa asteptam dupa Merge, ii dam auto merge si cand se termina de executat pipelineu ii va da merge automat)
-si vedem ca dupa Merge, avem alt pipeline care a fost creeat(pe branchu main, fiindca am dat merge la branchu feature/netlify pe branchu main) si daca dam pe el, vedem ca aici exista si stageu de deploy cu jobu netlify 

Scripts: before_script and after_script

-sa ne origanizam mai bine scriptu din pipeline, putem folosi before script si after script 
-in GitLab CI/CD, before script este useful pt pregatirea environemnt-ului inainte sa ruleze jobu main 
-si after_script e folositor pt clean-up sau task-uri aditionale dupa ce se termina jobu 
-mergem sa creeam un branch nou: refactoring/before-script
-incepem cu before script, si il punem chiar inainte de script: , arata asa: before_script: , la nivel cu script si variables 
-de obicei, folosim before script sa separam instalarea de tool-uri aditionale de scriptu prorpiu zis 
-in cazu de fata, instalam doua tool-uri aditionale: curl si netlify cli 
-deci in loc sa le avem in script: , le putem muta in before_script: 
-acuma instalam prima oara tool-ruile de care avem nevoie inside the job si apoi rulam comenzile care efectiv apartin job-ului 
-in timpul executiei proopriu zise, before_script si script sunt merged, deci nu e nicio diferenta oricum 
-este doar despre menegiuirea mai buna a script block-ului: sa facem clar ce trebuie sa fie instalat si care sunt comenzile efective care trebuie sa fie executate 
-pe langa asta, before_script poate fi adaugat de asemenea ca un nivel global sub keyword-ul default 
-deci sus de tot, inainte de stages: , putem scrie default: , si sub default(identat cu 2 spatii la dreapta), putem avea un before_script: , in care putem da print la un mesaj: - echo "This is executed in all jobs":

default:
  before_script:
    - echo "This is executed inall jobs"

-si asta o sa fie merged cu orice altceva si va fi adaugat la toate job-urile, deci e ceva bine de stiu, dar in cazu nostru nu avem nevoie de asa ceva 
-deci acuma avem before_script, script si putem avea de asemenea si after_script, care e executat dupa ce main scriptu e gata 
-si orice comanda specificata after_script, este executata intr-un nou shell 
-deci executia before_script-ului si a script-ului sunt separate de ce vine dupa in after_script, sunt doua chestii diferite 
-si asta e ceva cu care in general vrem sa fim atenti cand il folosim, ca sa intelegem diferenta 
-after_script poate fi folositor pt clean-up sau oricare alte task-uri aditionale pe care am vrea sa le rulam dupa ce se termina jobu 
-pt acest pipeline, nu avem un exemplu bun de after_script, deci o sa l lasam asa cum este 
-acuma o sa dam commit sa rulam pipelineu si dam si merge la schimbari dupa ce facem merge request si ii dam Merge 

Deploying to the staging environemnt 

-acuma ne extindem pipelineu si introducem un staging environment, care este non production si, de obicei, non public environment care e foarte asemanator cu production environemntu propriu zis 
-adica, ne vom incerca deploymentu pe sistemu de staging inainte sa dam deploy in productie 
-daca da fail, environmentu de productie nu e afectat si avem suficient timp sa dam troubleshoot la problema 
-si daca merge, e o sansa mare ca deploymentu de pe productie sa fie ok de asemenea 
-deocamdata avem cele 3 stage-uri(build, test, deploy), dar acuma o sa avem doua deployment-uri, deci o idee buna ar fi sa separam in doua stage-uri de deployment 
-pe cel pe care il avem acuma sa il denumim deploy_prod si sa mai bagam inca un stage pe care il numim deploy_staging(inainte de cel cu prod)
-adica sus la stages: sa avem cele doua stage-uri de mai sus in loc de doar unul numit deploy 
-jobu nostru netlify da deploy in productie, asa ca sa il redenumim netlify_prod si ii schimbam si la stage: sa fie deploy_prod (adica asta este jobu care da deploy in prod deci trebuie sa fie in stageu de production)
-dam copy paste la tot jobu netlify_prod sii ii dam paste deasupra actualului si il redenumim in netlify_staging si la stage: ii punem deploy_staging 
-la rules: este ok, deoarece vrem sa rulam asta doar pe branchu main, pastram si variables: , pastram la fel si before_script
-facem schimbari doar in script la comanda - netlify deploy si trei sa schimbam si urlu din script 
-din comanda de deploy stergem flafu --prod ca nu mai dam deploy in productie si in locul lui o sa punem un alias numit staging astfel: --alias staging 
-acest alias va adauga la inceputu numelui siteului ce parametru ii dam(in cazu nostru staging) si de aceea folosim comanda curl cu staging-- dupa https://
-asta e tot setupu ca sa creeam un staging environemnt 
-trebuie sa schimbam url-ul ca sa nu rulam comanda curl pe siteu de production 
-deci chiar dupa https:// o sa bagam staging-- dupa care vom avea restu adresei asa:     - curl 'https://staging--learn-gitlab-demo.netlify.app/' | grep 'GitLab' 
-o sa verificam in logs sa ne asiguram ca avem linku buna
-observam ca avem variabila NETLIFY_SITE_ID definita de doua ori, in ambele stage-uri de deployment, deci o sa le stergem de acolo(blocku varaibles: cu tot cu variabila) ca sa nu avem duplicate si o sa punem sus inainte de stages aceasta proprietate  
-acum, aceasta variabila va fi disponibila pt toate job-urile, incluzand netlify_staging si netlify_prod 
-ca sa dam commit la schimbari, trebuie sa creeam un branch separat, dam commit, deschidem un merge request, dam merge la toate schimbarile si o sa ne uitam cum arata pipelineu 
*(ca sa creeam un branch nou, tre sa ne mutam pe main branch mai intai altfel nu ne lasa, cand dam sa ne mutam, ne intreaba daca sa dam stash la schimbarile actuale ca sa nu le pierdem cand facem schimbarea la main branch, o sa zicem ca da si dupa ce trecem la main branch, dam create branch from si alegem main si dupa la cele 3 puncte de la source control din vs code mergem la Stash -> si dam Apply stash si alegem stashu nostru creeat anterior, caruia putem sa i dam si un nume sa ne fie mai usor)
-acuma dam commit pe noul branch numit netlify_staging si dam merge la request ca sa se execute tot pipelineu cu cele doua stage uri de deploy 
-deci acuma avem si deploy_staging si vedem ca acesta se executa primul, pana sa se execute deploy_prod, deci daca ceva se intampla in deploy_staging, daca jobu da fail, pipelienu se opreste aici si production environemntu este neafectat
-intram pe logy de la deploy_staging si dupa comanda de deploy, vedem ca flagu prod: este false, ceea ce inseamna ca acesta nu este un production deployment, adica production system nu este afectat de ce facem noi aici
-si in plus, vedem ca ne printeaza si Website draft URL si vedem ca este acelasi url ca si cel din comanda curl de mai jos care e successful
-deci am configurat jobul cum trebe si totu pare sa mearga ok 
-environmentu de productie este deployed si el 

Manual approval step before deploying to production 

-acuma avem un continuous deployment pipeline, asta inseamna ca fiecare schimbare pe care o facem printr-un merge request, care trece apoi branch pipeline si main pipeline ajunge in production environment 
-deci asta numim continuous deployment, fiecare change este deployed
-daca facem 10 schimbari azi si fiecare trece pipelineu, vom face 10 schimbari la deployment environement intr-o zi 
-uneori, am putea vrea sa facem un manual check final inainte sa dam deploy in productie 
-cu alte cuvinte, am vrea sa oprim pipelineu dupa ce am dat deploy la staging si sa verificam totusi cateva lucruri in staging environment inainte sa mergem efectiv in production 
-doar sa ne asiguram ca nu dam deploy la nimic la care nu vrem sa dam deploy 

-facem un branch nou: feature/protect-production si inainte de asta, schimbam branchu curent pe main si dam pull reabase, dupa dam publish la branch 
-la jobu netlify_prod, adaugam o conditie sub stage: deploy_prod care arata asa: when: manual 
-dam commit la schimbari, dam merge la merge request si apoi de uitam la main pipeline 
-deci dupa ce am dat deploy to staging vom vedea ca deploy_prod este pus pe pauza deocamdata 
-arata unpic altfel ca si pana acuma(are o rotita in bulina de stare) si langa numele job-ului(netlify_prod) avem un buton de Play peste care daca dam hover scrie Run 
-deci ca sa pornim deploymentu in productie, trebuie sa dam click pe butonu de play, altfel pipelineu o sa tot astepte dupa noi 
-daca dam click pe numele jobului(netlify_prod) si vedem niste explicatii despre job, zice ca acest job are nevoie de o actiune manuala, acest job nu porneste automat si trebe pornit manual 
-acuma putem sa dam pe butonu de play de mai devreme sau direct in pagina asta pe Run job si doar atunci acest job(parte din pipeline) va fi pornit 
-cand avem acest pas manual, avem defapt un continuous delivery pipeline care are nevoie mereu de interventia noastra manuala inainte sa faca un deployment in productie 

Creating review environments 

-cand lucram la un merge request, poate fi greu sa ne dam seama cum se vor comporta schimbarile cand vor fi deployed 
-code reviewers si stakeholders trebuie sa se bazeze pe citirea codului sau pe rularea locala a acestuia ceea ce nu ar putea replica complet environementu de productie 
-asta poate duce la bug-uri nedetectate, asteptari nealiniate, surprize de ultim minut in timpul deploymentului 
-acuma, ca sa vedem schimbarile, prima oara trei sa le dam merge si abea atunci ne putem uita la staging environment 
-si pana cand dam inspect la lucruri pe staging environment si ne dam seama ca este ceva gresit, acele schimbari sunt deja deployed pe environementu de productie, deci e deja unpic tarziu 
-review environements rezolva aceasta problema creeand automat un environment temporar pt fiecare merge request 
-aceste environement-uri permit echipelor sa testeze si sa valideze schimbari intr-un setting realist inainte sa se dea merge 
-dand un preview live al schimbarilor, environment-urile de review cresc increderea in procesul de merge request 
-si creeand aceste environement-uri temporare cu netlify este chiar usor:

-facem un branch nou: feature/review-environments
-definim un nou stage sus: deploy_review 
-apoi copiem jobu netlify_staging , ii dam paste deasupra lui, schimbam stageu la deploy_review si ii schimbam si numele in netlifi_review
-stergem si rules cu ifu pt ca vrem sa rulam jobu asta pe branch ca si parte din merge request(cand se executa pipelineu dupa commit) 
-before_script il lasam asa cum e si majoritatea script: cu o diferenta importanta: stergem --alias staging 
-asta va instrui netlify sa creeze acest environment pt noi pt ca nu specificam un alias si nu avem nici flagu --prod , deci nu dam deploy in productie 
-in acest moment trei sa stergem comanda de curl pt ca nu stim linku environment-ului, este generata random de netlify si il stim doar dupa ce executam jobu 
-dam commit, deschidem un merge request si ne uitam la pipeline si vedem ca exista, pe langa build si test si stageu deploy_review cu jobu netlify_review 
-ne uitam pe log si vedem ca executia deploymentului a fost successful si vedem linku de la site la Website draft URL: https://67cf1415537d2f44718e63cb--learn-gitlab-demo.netlify.app/ , dam pe el si vedem ca merge 
-partea asta a fost generata random de netlify 67cf1415537d2f44718e63cb si de fiecare data cand dam deploy, primim o adresa diferita si asta ne lasa sa vedem schimbarile 
-acuma putem sa mergem pe acest branch(feature/review-environements) si sa facem o schimbare(titplu aplciatiei sau mai bine, textu ala de jos Dive into the world...) in src/App.jsx
-dam deploy la schimbari si apoi comparam cu versiunea care e disponibila pe staging environement(https://staging--learn-gitlab-demo.netlify.app/) si mai comparam si cu versiunea care e disponibila pe production environment(https://learn-gitlab-demo.netlify.app/)
-o sa vedem ca schimbarea pe care am facut-o aici, in acest merge request, in acest branch particular(feature/review-environements) o sa fie disponibila pe acest review environment, ca sa ne putem decide mai tarziu ca poate nu vrem acasta schimbare  

-DECI acest review environment este ca sa putem da deploy la un job similar cu celelalte doua de deployment(staging si prod care se executa doar cand facem mergeu pe branchu main) ca sa putem vedea cum arata schimbarile inainte sa dam merge pe branchu main 

-am vazut schimbarea pe linku generat pe pipelineu commit-ului, care va fi pe acelasi merge request si nu ne convine asa ca dam undo la schimbare si dam commit iar si dam merge la merge request sa continuam cursu 


Merge request pipeline vs Branch pipeline 

-dupa ce am adaugat deploy_review si am dat merge la acel branch in branchu main, pipelineu pt mainu branch va fi pornit si vom vedea ca deploy_review este de si el parte din acest branch(sau pipeline creca a vrut asta sa zica ca arata pe pipeline treaba)
-acuma chestia e ca nu prea are sens sa avem deploy_review executat pe branchu main pentru ca pentru scopul lui, avem deja deploy_staging aici si deploy_review este pentru a fi folosit doar pe Merge request dar nu si in main branch 
-asa ca adaptam configuratia noastra si facem ca deploy_review sa nu mai fie executat si pe main branch, doar pe branch-urile secundare 
-pt staging si production, avem acest rule cu ifu care interzice acestor doua job-uri sa ruleze pe oricare alt branch decat pe cel main 
-ca sa avem efectul opus(pt deploy_review, adica acesta sa nu fie executat pe branch main si in rest pe celelalte branchuri sa fie executat), trebuie sa negam conditia din if('$CI_COMMIT_REF_NAME != $CI_DEFAULT_BRANCH')
-acuma, schimbam branchu pe main si dam pull rebase ca sa putem creea un nou branch fara conflicte cu numele bugfix/review-only-on-mr pentru merge request 
-copiem rule: cu tot cu if din staging si il mutam la netlify_review sub stage: - if: '$CI_COMMIT_REF_NAME != $CI_DEFAULT_BRANCH' si in loc de == ii dam != ca sa insemne gen, cand branchu curent nu este branchu default(main) vom executa asta 
-dam commit la schimbari, creeam un merge request si vedem ca avem doua pipeline-uri care ruleaza in acelasi timp
-deci pentru schimbarea pe care am facut-o, avem doua pipeline uri care ruleaza simultan
-pentru primu pipeline din lista(de sus in jos) avem un label numit merge request si e foarte interesant ca acest pipeline are doar un stage si anume deploy_review
-si acest stage cu jobu netlify_review nu poate rula doar el pt ca nu are acces la build files deci nu va functiona 
-si mai avem inca un pipeline care a fost inceput, care ruleaza pt branchu nou(bugfix/review-only-on-mr) cand am dat commitul si are toate cele 3 stage uri care ar trebui sa ruleze pe pipeline 
-adica are build, test si deploy_review ceea ce este ce am configurat noi 
-acest comportament sa intampla cand incercam sa excludem un job din pipelineu branch-ului main 
-in cazu asta, incercam sa excludem jobul deploy_review, dar nu cand incercam sa excludem alte job-uri sa ruleze pe branch, de asta nu aveam problema asta inainte 
-deci GitLAb va creea un pipeline de feicare data cand dam push la schimbari pe un branch 
-de ex, am dat push la schimbari(am dat commit & push) pe branchu bugfix/review-only-on-mr si GitLab a creeat un pipeline si asta e normal, la asta ne asteptam 
-dar mai e si merge requestu creeat si nu vedem niciun branch asociat cu el 
-chestia e ca acesta este un merge request pipeline 
-deci sunt doua feluri de pipeline-uri: poate fi un merge request pipeline si poate fi si un branch pipeline, pe astea le-am avut tot timpu pana acuma 
-intreabarea e de ce acest merge request pipeline a aparut dontr-o data?
-ei bine, merge request pipeline este creat pt ca fiecare job cu rules: nu are o configuratie care exclude jobu din merge request pipeline 
-de asta vedem doar deploy_review adaugat in acest branch 
-merge request pipeline e creeat pt ca jobu trei sa fie executat 
-acuma normal ca nu vrem asta, dar cand incepem sa adaugam rules: la un job care este apoi parte a unui merge request pipeline, suprascriem o configuratie care spunea jobului sa nu fie parte din pipeline si daca niciun job nu este parte din pipeline, atunci pipelineu nu exista 
-deci de asta se intampla asa: ca am adaugat conditia asta in netlifi_review si astfel am suprascris alte conditii care ne asigura ca acest merge request pipeline nu este creeat 
-cu alte cuvinte, configurarea pt rules a suprascris niste default-uri care ar preveni merge requestu sa fie creeat initial 
-deci am cam inteles de ce se intampla asa si ca sunt doua tipuri de pipeline-uri si ca acest merge request pipeline este ceva care a aparut acuma 
-deci cum putem scapa de aceste pipeline-uri dublate in GitLab, pt ca nu avem nevoie de ambele
-avem un pipeline functional si avem nevoie de pipelineu care are toate stage-urile(tot cel functional) 
-putem sa obtinem controlu iarasi asupra pipeline-ului nostru, adaugam rules la fiecare job 
-deci putem merge pe config si sa ne decidem de ex cand vrem sa rulam unit_tests, si zicem ca pt main branch si pt celelalte branch-uri 
-deci am putea avea rules configurate in toate job-urile, dar nu este ideal pt ca va adauga mult boiler plate configuration in pipeline si astfel o sa supra complicam lucrurile si vrem sa mentinem lucrurile simple 
-si ca sa mentinem lucrurile usoare, o sa definim un workflow 
-esential, prin workflow vrem sa dam disable la branch pipeline, doar daca acesta este branchu main
-deci vom pastra main branchu, dar cand GitLab incearca sa adauge un branch pipeline, il vom opri si vom avea un merge request pipeline si acel merge request va avea toate job-urile de care avem nevoie 
-suna mai complicat decat este, dar sa mergem sus de tot in config file, deasupra la variables: si screm workflow: si ca si prorpietate a acestuia vom avea rules 
-acuma trei sa definim regulile, prima regula este in legatura cu source-ul pipeline-ului 
-deci pipeline source este un environment variable si in acest caz, prin pipeline source ne putem da seama daca asta este un merge request event, cu alte cuv, daca am creeat un nou merge request 
-si daca am creeat un nou merge request, atunci vrem sa rulam pipelineu 
-si pt asta o sa folosim un - if: '$CI_PIPELINE_SOURCE == "merge_request_event"' . Trebuie sa fim foarte atenti cum scriem conditia din if altfel nu va merge si va fi ciudat de troubleshoot 
-deci, noi acuma verificam cum a fost tirgger-uit pipelineu si vom da enable la toate job-urile pentru Merge request, doar daca nu sunt excluse de alte conditii 
-deci, cu aceasta prima conditie, vom repara pipelineu nostru care are doar un singur stage
-dar ne mai trebe o configuratie aditionala doar ca sa includem branchu main, sau care e branchu default si e o conditie foarte similara cu ce am avut inainte 
-deci mai punem un if in care verificam daca branchu in care am facut un commit(e in variabila $CI_COMMIT_BRANCH), vom verifica daca aceasta valoare este branchu nostru default($CI_DEFAULT_BRANCH), in cazu nostru main 
-deci daca branchu curent este branchu main, asta e conditia pe care o avem
-deci, CI_COMMIT_BRANCH va avea branchu curent 
-de ex, am dat merge la un merge request, deci commit_branch este acuma main, daca main este egal cu default branch care este main, atunci vom avea un branch pipeline care ruleaza doar pt main branch 
-asta e configu pe care il avem acuma ca sa rezolvam problema pe care am vazut o inainte:
- if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
-in termeni simpli, cu aceasta configuratie, am dat switch de la branch pipelines, exceptamnd branchu main, la merge request pipelines 
-si cu acest setup, chiar daca dam push la un branch, nu va fi creeat/executat niciun pipeline 
-deci trebe sa dam push la schimbarile noastre din branch si apoi putem creea un merge request ca sa incepem pipelineu de merge request 
-deci main request pipeline nu va incepe decat daca creeam un merge request 
-dar daca avem oricum un merge request, acel pipeline o sa fie regenerat, deci in acest caz deja avem un merge request, deci atunci cand dam commit la aceste schimbari si le dam push, un pipeline de merge request o sa fie triggeruit  
-acuma o sa vedem un pipeline care este tirgger-uit, vedem ca este un merge request pipeline, nu are nicio referinta la niciun branch, dar vedem la stages ca avem 3 stages: build, test si deploy_review si asta este ce am vrut 
-deci in loc sa avem un branch pipeline cand dam push la un commit, acuma vom avea un merge request pipeline, dar care contine toate cele 3 job-uri 
-normal ca putem sa negam aceste noi reguli din workflow si sa dam disable la aceste merge request pipelines si sa avem doar branch pipelines 
-dupa ce s a terminat pipelineu de merge request mergem si dam merge la el in main branch 
-deoarece nu ne pasa doar de merge request, dar ne pasa si de main branch sa ne asiguram ca acesta merge corespunzator 
-acuma vedem ca pipelineu pt mainu branch a fost trigger-uit si dam pe bulina lui si vedem ca avem built, test, deploy_staging si deploy_prod, deci nu mai avem si deploy_review intre test si deploy_staging, este exact ce ne doream 
-ne uitam si la Pipelines, sa nu mai fie si altele care ruleaza in acelasi timp si vedem ca asa este 
-deci cu aceasta configuratie, am reusit sa rezolvam doua lucruri deodata 

Parsing CLI response data 

-urm pas este sa stergem partea de manual work pe care o mai avem:
-asta este partea in care intram in jobu netlify_review din stageu deploy_review, ne dam seama care u URL-ul(e la Website draft URL:) si sa intram pe el sa ne asiguram ca deploy-ul pentru review environement a fost succesful 
-si ideal ar fi sa inlocuim acest pas cu un curl command, dar problema e ca urlu este generat random, deci nu-l putem sti de dinainte 
-de ex, in job-urile precedente, era destul de usor sa punem linku(urlu) comanda de curl, pt ca il stiam de dinainte, dar pt netlify_review, nu stim asta 
-deci, acuma o sa extragem acest link din logu comenzii $ netlify deploy --dir build si apoi sa-l folosim un curl command ca sa rulam acest simplu smoke test 
-acuma problema e ca logurile acestei comenzi care apar aici ca un result al comenzii aceleia sunt doar niste log-uri si noua ne va fi foarte greu sa accesam inforamtia de aici pt ca nu este un format structurat 
-dar, din fericire, il putem ruga pe netlify sa ne dea provide la acest output al comenzii de deploy intr-un format structurat numit json(un format de text simplu care da store si share la data intre aplicatii, este human si machine readable)
-ca sa facem asta, ne intoarcem in ide, (dam pull la main daca nu am dat dupa merge request) si creeam un nou branch cu numele: feature/extract-dynamic-url 
-acuma o sa mutam jobu netlifi_review in .pre stage , pt ca vrem sa executam acest job prima oara sa nu asteptam sa ruleze tot pipelineu ca sa putem face ceva, deci in loc de deploy_review o sa avem .pre la stage:
-si o sa creeam un file foarte simplu in before_script, sub apk add curl: creeam mai intai un folder numit build: $ mkdir build 
-si apoi, in folderu build, cu comanda echo o sa punem cuvantu "Test" intr-un file numit index.html: $ echo "Test" > build/index.html 
-efectiv ii dam lu netlify sa dea deploy la ceva 
-in comanda netlify deploy o sa i pasam un flag: --json , si acuma nerlify o sa ne dea acest raspuns intr-un format json 
-acuma dam commit la changes, facem un merge request si ne uitam la logs 
-acuma daca ne uitam la pipeline, vedem ca jobu netlify_review se executa inainte de build in .pre stage 
-intram pe logu job-ului si vedem ca comanda netlify deploy o sa ne dea un output total diferit fata de ce aveam inainte intr-un format json 
-noi incercam sa extragem din acest json prorpietatea "deploy_url" 
-dar inainte sa incepem procesarea, avem nevoie de o modalitate sa luam aceasta informatie(jsonu) si o sa split-uim procesu asta in mai multi pasi
-de retinut e ca putem face totu dintr-o singura comanda, dar daca nu suntem asa tari pe linux merge si approuchu asta step by step, chiar daca nu e cel mai tare approach
-acuma o sa redirectam output-ul care vine din comanda netlify deploy in fileu deploy-result.json asa: 
$ - netlify deploy --dir build --json > deploy-result.json 
-iar dupa asta o sa folosim comanda cat sa printam contentu fileului deploy-result.json sa ne asiguram ca avem json aici 
-dam iar commit la schimbari si ne uitam la log si vedem ca comanda de deploy nu mai da oputput la nimic si doar redirecteaza tot in acest file deploy_result.json 
-si dupa comanda cat ne va afisa continutu jsonului, dar mai sunt cativa pasi pe care trei sa i facem:
-cel mai important pas este parsarea json-ului, adica sa gasim o cale sa dam extract la aceasta proprietate numita "deploy_url" si sa facem ceva cu ea 
-avem nevoie de un tool sa parsam jsonu asta si sa extragem informatia aia si un tool foarte popular care ne poate ajuta se numeste jq 
-acuma vom folosi jq sa accesam aceasta proprietate 
-prima oara il instalam. Avem in before_script pakage manageru apk pe care il putem folosi sa instalam si comanda asta 
-deci in comanda de instalare pt curl, putem adauga jq si dupa curl sa fie si acesta instalat:
$- apk add curl jq
-apoi, dupa comanda cat o sa ii dam call lui jq si ii zicem ca avem un file pt el 
-dar avem nevoie sa luam o anume propietate si pt asta vom scrie in comanda, dupa jq asa: -r '.deploy_url'
$ - jq -r '.deploy_url' deploy-result.json 

-deci, ce ne asteptam sa vedem dupa ce ii dam call lui jq si ii cerem sa ne dea proprietatea deploy_url din fileu pe care i-l am dat(deploy-result.json), este sa vedem efectiv urlu 
-deci iar dam commit la schimbari si ne uitam pe job o sa vedem ca, ca si rezultat al comenzii jq avem acest link 
-deci cu ajutoru jq am reusit sa parsam jsonu si sa avem acces la link 
-acuma putem pune acest link intr-un environment variable 
-o sa definim o variabila, in script, sub comanda jq, numita REVIEW_URL, caruia am putea sa i atribuim urlu propriu zis, dar nu l avem la indemana sa il putem asigna asa
-si pt asta, vom folosi un linux construcut, care e numit command substitution, care are sintaxa: $() , ne permite sa executam o comanda si sa i folosim outputu ca si valoare pt variabila  
-asa ca vom lua comanda jq(cut) si o punem intre parantezele de dupa =$
- REVIEW_URL=$(jq -r '.deploy_url' deploy-result.json)
-deci asta o va executa si stim ca ne va da urlu pt ca tocmai am testat comanda asta deasupra si va pune valoarea(outputu comenzii) in variabila pe care noi o definim(REVIEW_URL) 
-deci acuma avem acest review url variable pe care o putem folosi 
-o sa o folosim intr-o comanda de curl pe care o punem sub definirea variabilei in script: 
- curl $REVIEW_URL | grep 'GitLab' 
-asta o sa caute gitlab si pt ca nu am scris GitLab in echo test in before script o sa dea fail da facem dupa sa fie bine, dam commit si vedem daca merge 
-intram pe log si vedem ca da fail si avem comanda curl care ia in mod dinamic review url de unde l am extras ca si parte din acest json  
-ne astepam sa dea fail 
-daca suntem nesiguri de continutul variabilei respective, daca a fost parsata corect, putem folosi comanda: - echo $REVIEW_URL sa o putem vedea, inainte de curl 
-dar inainte, o sa puntem jobu acesta(netlify_review) inapoi in pipeline in stageu deploy_review (deci o sa avem asa: stage: deploy_review) si stergem si comenzile temporare de mkdir si echo din before script carora oricum nu le am inteles sensu da ma rog 
-mai putem si sa stergem comanda de cat din script: si in locu ei putem sa folosim comanda tee in comanda netlify deploy astfel:
-inlocuim operatoru > cu cel de pipe | ca sa combinam doua comenzi 
-comanda tee va redirectiona output-ul comenzii netlify deploy in fileu deploy-result.json si ii va da si print acestui output, deci face doua chestii deodata 
    - netlify deploy --dir build --json | tee deploy-result.json
-avem un config destul de solid: i am cerut lu netlify sa ne dea outputu in format json si luam acest raspuns si il bagam intr-un file ca sa il putem procesa dupa cu jq  
-cand definim variabila REVIEW_URL, folosim un construct din linux(command substitution) si rezultatul executiei comenzii este pus in variabila si apoi folosim aceasta variabila in comanda curl 
-mergem pas cu pas ca sa intelegem perfect ce se intampla 
-dam commit si ne uitam pe log si vedem ca executia a fost successful chiar si cand este parte din intreg pipelineu si vedem comanda tee in actiune, care va scrie in fileu deploy_result.json si va da si print in consola la ce scrie acolo 
-asa ca totu fiind ok, mergem sa dam Merge la acest Merge request  

Defining dynamic environments 

-daca un pm vrea sa se uite pe un nou feature pe care l am creeat?
-nu ar fi ok sa le zicem sa deschida un job din pipeline si sa se uite pe logs, dar in GitLab avem in workaround 
-putem folosi environments care sunt o cale de a linkui gitlab la infrastructura noastra, adica ii putem zice lu gitlab ca acest url(deploy_url de mai devreme) este review environmentu nostru si sa i dam efectiv linku 
-e simplu de facut si o sa avem mai multe informatii despre acest environment prin user interface-ul gitlab 
-mergem in vs code, schimbam pe main, dam pull si creeam un nou branch si ii dam publish: feature/dynamic-environments 
-in jobu netlify_review, trebuie sa audam niste configurari:
-adaugam environment: sub rules care trebuie sa aiba doua proprietati
-una numita name: si inca una numita url: 
-pt numele environmentului ne trei ceva dinamic, punem de obicei prefixu preview(pt ca e preview environement)
-dar si pt ca putem avea mai multe merge request-uri deschise in acelasi timp, e o idee buna sa adaugam si o parte dinamica in nume 
-ne uitam la predefined environment variables si gasim una interesanta pe care o putem folosi: CI_COMMIT_REF_SLUG care este url safe version a variabilei CI_COMMIT_REF_NAME care e numele branch-ului 
-atunci cand creeam un branch, vom accesa numele branch-ului intr-un environment variable si acea environment variable o sa fie URL friendly, adica o versiune scurtata care nu contine spatii sau alte chestii, deci e in general URL safe si asta e o idee buna pt naming(sa fie folosit intr-un nume) 
-deci copiem numele variabilei acesteia URL safe, si il punem dupa preview cu un dolar$ sa-l facem variabile refrence 
  - name: preview/$CI_COMMIT_REF_SLUG
-si acuma avem un nume dinamic de environment, deci asta ne ajuta sa identificam environementu 
-pentru propietatea url: vrem sa folosim variabila pe care am creeat-o anterior $REVIEW_URL , pt ca deja am extras-o din outputu de la comanda deploy si ne trebe pt environement ca pe acel link o sa fie environementu
-chestia e ca nu va merge automat(toata treaba asta cu environement:) deci mai avem cativa pasi de facut, care sunt destul de importanti, altfel variabila noastra url: $REVIEW_URL nu o sa fie populata cu nicio valoare 
-ca sa facem asta sa mearga, vom folosi alt concept important in GitLab si asta e in legatura cu passarea de informatii folosind .env report 
-.env report  este un report special unde putem baga intr-un file niste environment variables 
-dupa ce am printat urlu cu echo in script si stim ca exista si dupa ce am executat comanda curl si stim ca deploymentu a fost successful,
-dupa comanda curl, putem sa creeam un file, numit deploy.env si acesta va store-ui environment variables 
-deci cu comanda echo vom pune niste content pe care il vom redirecta in deploy.env 
-vom face asta creeand o variabila REVIEW_URL si ii vom asigna valoarea variabilei noastre existenta deja $REVIEW_URL
-va fi asignata exact aceeasi valoare doar ca treb sa creeam acest file intr-un mod structurat 
-efecitv fileu va contine textu: REVIEW_URL=<valoarea variabilei noastre, adica linku de review> - si in loc de $REVIEW_URL va fi valoarea acestei variabile 
-daca suntem curiosi cum arata acest file sau nu suntem siguri despre cum a fost creeata, putem folosi comanda cat ca sa printam continuturile file-ului, nu e necesar dar ne ajuta sa intelegem mai bine ce facem pe aicia 
-mai avem un lucru de facut, la acelasi nivel cu script: sub el vom defini artifacts: o forma de report(chiar daca nu e un report intra in acea categorie)
-deci sub artifacts:, identat vom scrie reports: si sub acesta identat vom scrie dotenv: deploy.env 
-dotenv se revera la un tip special de file, care poate avea in ea environment variables, deci de aceea trebuie sa ii dam numele file-ului creeat anterior 
-deci schimbarile facute sunt ca sa configuram environmentu si ca sa putem avea un URL dinamic, trebuie sa i-l pasam din fileu deploy.env pe care il creeam, deci efectiv citim variabila pe care o avem in job si o bagam in acest file ca sa o avem disponibila si in environment 
-pe scurt, noi creeam un review environment pe baza URL-ului de review generat random in acest job, deci trebuie sa facem acest file in care vom avea REVIEW_URL=https://67d16e194892910749a46c1c--learn-gitlab-demo.netlify.app si pe care il pasam mai departe pentru proprietatea de url din environment care are nevoie de variabila $REVIEW_URL care se regaseste in fileu asta 
-dam commit la schimbari, creeam un merge request si dupa ce executia acestui job a fost successful o sa vedem ceva foarte interesant 
-ne uitam la pipeline si vedem ca merge ok si dam refresh la merge request si vedem ca sub Merge request pipeline apare Deployed to preview/feature-dynamic-environments
-si cel mai important ce vor sa vada stakeholderii, nu vor sa citeasca logurile, ci sa aiba butonu asta de View app, sa dea click pe el si sa vada aplciatia 
-deci asta s-a linkuit automat prin configuratia pe care o avem in job si e un big win pt fiecare care da review la un merge request ca sa poa sa vada cum arata appu si sa testeze diferite chestii, putem sa ne uitam si pe changes sa vedem ce s-a intamplat 
-deci face procesu de review si sa se vada ce s-a schimbat mult mai smooth decat sa mergem prin log-uri si sa luam un url ciudat de acolo, in fine dam Merge la merge request si pull la branchu main pe ide 

Defining static environments 

-acuma o sa facem environments pentru netlify_staging si netlify_prod pt ca si acestea sunt environment-uri si vrem sa le integram cu GitLab 
-sunt doua approach-uri pt definirea environment-urilor pt aceste fel de static environment-uri care nu se schimba
-unul este sa mergem pe configu yaml al pipeline-ului si celalalt aproach este prin UI 
-o sa le facem pe amandoua, de asta configurarea pt job o sa fie diferita 
-nu pt ca chiar au nevoie de alta configurare, dar pt ca am vrut sa vedem doua approach-uri diferite sa stim ca exista 
-creeam un branch nou, feature/static-environments si ii dam publish si o sa dam copy la configuratia pe care o avem pt netlify_review si ii dam paste in netlify_staging sub rules: 
-numele il dam ca si staging pt ca nu e nimic ce trebe sa avem dinamic aici 
-e un environment care o sa fie mereu numit staging si putem sa ii dam aici si urlu direct pt ca e static si el din comanda curl intre ''
-in loc sa avem duplicarea asta aici, cu link-urile, in momentu cand folosim acest environment, putem folosi si un environment variable care este apoi disponobila prin GitLab
-in lista de predefined variables, avem CI_ENVIRONMENT_NAME si CI_ENVIRONMENT_URL
-si vedem ca acest environment variable este available daca am setat proprietatea environment:url
-mergem si folosim acest variable ca sa nu avem duplicate in pipelineu nostru 
-deci stergem linku din comanda curl si bagam in locu lui $CI_ENVIRONMENT_URL si folosim acest environment variable 
-pt motive de troubleshoot nu e o idee rea sa printam aceasta variabila cu comanda echo inainte sa o folosim in curl de exemplu, deci dam echo $CI_ENVIRONMENT_URL inainte de curl 
-deci daca nu suntem siguri ca e ok sau nu suntem siguri ca e stata variabila asta sa ne asiguram ca toate variabilele pe care le folosim sunt definite corespunzator, acuma nu facem asta 
-asta e primu mod de a configura static environmentu, mai e o cale alternativa pentru care va trebui sa lasam sa ruleze pipelineu si va da fail pt ca un environment nu e definit, dar o sa l definim manual mai tarziu 
-deci in netlify_prod: o sa scriem sub rules: , environement: production si nu o sa definim un URL, vom defini un URL prin interfata UI 
-schimbam si comanda curl ca si la netlify_staging pt ca nu mai avem nevoie de valoarea hardcodata pt acest link, deci punem $CI_ENVIRONMENT_URL in loc de linku learn-gitlab-demo...
-dam commit la changes si facem merge rquest si daca nu s erori dam merge si ne uitam pe merge request la main pipeline
-vedem ca sub Merged by avem Pipeline si sub Pipeline avem Deployed to staging 1 minute ago cu butonu View app si daca dam pe el ne duce pe siteu de staging, deci stie despre staging environment si exact asta voiam in termeni de integrare 
-mergem in meniu pe stanga jos la Operate si dam pe Environments si aici o sa vedem o lista cu toate environment-urile pe care le avem  
-vom vedea aici staging ca si environment, si putem da pe Open si ne trimite pe siteu staging--learngitlab.. 
-putem sa vedem si cate deployment-uri am avut pe staging environment, care e versiunea curenta, deci e multa integrare care se intampla acum intre GitLab si ce e defapt pe un evironment specific pentru ca noi acuma am facut conexiunea dintre infrastructura noastra si pipeline-urile noastre, deci acuma GitLab are informatia asta si ne-o da intr-un mod mult mai placut 
-production nu este link-uit cum trebe 
-si daca ne uitam la Stopped(eram pe Active) o sa vedem preview, asta e avantaju folosirii acestui prefix(preview din nameu de la netlify_review) pt ca putem grupa multe alte environment-uri care ruleaza sub un label sau folder specific 
-dam pe el si vedem doua previous merge request-uri la Stopped, fiecare avand un environment pe care putem intra 
-ele apar ca si Stopped pt ca am inchis Merge requestu, dar netlify nu ne lasa sa stergem aceste environment-uri, dar noi le vom considera ca si inchise, oprite, nu ne mai pasa prea mult de ele acuma, deci de asta apar aici sub stop 
-deci cum putem repara acest production environment, care vedem ca este failed jobu lui: putem sa dam click pe el si avem posibilitatea sa dam Edit environment 
-cum statusu jobului este pe failed, este un trigger si a dat fail pt ca scriptu nostru are o problema 
-dam pe Edit environment in dreapta sus si vedem ca aici putem sa dam informatii aditionale daca vrem, dar avem si posibilitatea sa ii dam URL-ul de la production environment si fix asta o sa facem 
-deci la External URL ii dam linku de la production environment(cel care era la netlify_prod in curl, deci cel pe care il genereaza jobu netlify_prod) si anume: https://learn-gitlab-demo.netlify.app si dam Save 
-acuma ne putem intoarce la pipeline si sa re pornim acel job specific care a dat fail, ne putem uita iar pe el si sa ne uitam de ce a picat, dar stim ca motivu pt failure este comada curl pt ca nu a putut sa dea resolve la acest environment variable, pt ca nu il avea de nicaieri, dar acuma cum i l-am dat in Edit environment la external url il are 
-deci speram acuma ca avel environment variable este properly defined, deci tot ce tre sa facem e sa dam click pe butonu albastru din dreapta sus cu doua sageti numit Retry si va da start din nou doar la acest job 
-executia job-ului acuma a fost de succes, adica acest environment variable($CI_ENVIRONMENT_URL) a fost revealed 
-ne putem uita iar la Operate -> Environments si vedem ca acuma si production environment are linku Open care ne permite sa deschidem linku https://learn-gitlab-demo.netlify.app/ deci nu trei sa tinem urma tuturor link-urilor 
-putem vede in production cand a fost facut ultimu deployment successful si interfata de aici o sa tina urma tuturor deployment urilor doar pt ca am pus configuratiile astea aditionale in termeni de specificare a environment-urilor la job-uri (environemnt: ...) 
-o sa specificam environment: doar in job-urile care fac deploy pe acel environment specific si nu in alte job-uri care fac teste sau build sau altcv... 
-mai e un aspect important despre care ar trei sa stim: cum environment variables definite de noi lucreaza cu environment-urile pe care le avem aici? 
-mergem la Settings si la Variables vedem ca avem variabila pe care am definit-o noi cand am inceput deployment-urile 
-acuma daca dam pe Add variable, vom vedea ca fieldu Environments este acuma populat cu environment-urile pe care le avem
-avem environment-urile preview pe care le am creeat in trecut si mai avem dupa production environment si staging environment  
-deci teoretic, acuma e posibil sa avem de asemenea credentiale diferite pt diferite environment-uri. Sa zicem ca production environment foloseste un token diferit fata de staging environment, ceea ce pt multe proiecte este cazu neaparat
-in acea situatie, putem defini acelasi nume de variabila si apoi sa selectam environmentu corect si apoi acea variabila o sa fie disponibila doar in acel environment care este o cale foarte foarte folositoare de a refolosi duplication, sa nu avem keys(nume de variabile) definite care au de asemenea prefixu sau sufixu environment-ului, deci asta face configuratia overall mult mult mai placuta 
-deci acest link cu folosirea environment-urilor in configuratia job-urilor poate fi o chestia foarte puternica 

Project simulation using merge requests 

-o sa facem un "project simulation" si o sa lucram la niste mici feature-uri si bug fixuri, planu e sa creeam doua merge requests, fiecare cu un alt aspect al aplicatiei 
-o sa facem un nou paragraf de text pt care vom creea un nou branch: feature/add-text 
-mergem in src in App.jsx(mainu aplicatiei sa zicem) si sub paragrafu Dive into the world of continuous integration ... adaugam un nou paragraf cu <p> Note to self: I am really learning a lot about GitLab </p>
-si dam commit la schimbare pe branch si creeam un Merge request si se porneste pipelineu 
-sa zicem ca intre timp, vrem sa lucram pe altceva cat timp colegii dau review la schimbarea pe care am facut-o aici 
-acuma o sa dam switch pe main branch din vs code si in cazu asta o sa ne asumam ca vrem sa stergem niste imagini din aplicatia noastra, nu ne place cum arata appu nostru si trei sa stergem doua imagini pe care le avem
-mai facem un branch(bugfix/remove-images) pt ca fiecare feature sau bugfix sau orice schimbare pe care o facem ar trebui sa fie in branchu ei separat
-nu o sa vedem schimbarea facuta anterior pt ca e un branch separat si sa zicem ca in cazu asta avem un bug la aplicatie si vrem sa vedem GitLab dar nu ne prea pasa de celelalte logo-uri care apar aici, deci din App.jsx stergem primele doua logo-uri <a>...</a> din primu <div> si dam commit la schimbari si deschidem un Merge request 
-deci acuma o sa avem doua Merge request-uri pornite si de obicei o sa avem multe merge request-uri deschise in paralel ceea ce poate fi uneori challanging 
-primu merge request a terminat de rulat pipelineu si ne-a dat Review environment pe care o sa l folosim sa vedem schimbarea sa vedem daca arata ok inainte sa dam merge la schimbare si daca dam pe butonu View app o sa vedem schimbarea efectuata la aplicatie, deci acesta este previewu nostru
-daca vrem sa verificam ca schimbarea asta nu s-a mai propagat nicaieri altundeva, mergem la Operate -> Environments si deschidem production environmentu si vedem ca aici nu avem schimbarea asta 
-vedem ca schimbarea e doar pe review environment si pe cel de production nu 
-ne uitam si pe a doua schimbare pe care am facut-o, alt merge request dam refresh si putem intra pe environment cu View app de sub Merge request pipeline si vedem ca avem doar logo-ul GitLab si asta e fain, usor de facut review, ne putem uite si la tabu Changes din merge request 
-si o sa dam Merge la request ceea ce va incepe pipelineu main si va porni toate deployment-urile pe care le avem, deci schimbarea asta a fost merged 
-ce se intampla cu celalalt merge request pe care il avem - add new paragraph? ce se intampla cu paragrafu asta pe care incercam sa l adaugam aici? 
-intram pe reqest, asta e partea interesanta, o sa ne zica Merge request blocked. De ce e blocked? Acu doua min ne am uitat la el si totu arata ok 
-daca ne uitam unpic si citim, o sa vedem ce se intampla si zice ca Merge requestu trebuie rebased pt ca un merge fast-forward nu e posibil. E o descriere unpic tehnica, dar ce trei sa observam este:
-la Merge details, avem - The source branch is 1 commit behind the target branch 
-source branchu este cel pe care l-am creeat pt requestu asta, ne uitam sus la titlu merge request-ului si vedem ca avem feature/add-text  
-target branch este main branchu pe care incercam sa dam merge la schimbarile noastre 
-merge requestu anterior, cel in care am sters logo-urile a fost deja merged, deci schimbarile alea sunt acolo, dar stergerea logo-ului nu este parte din aplicatia noastra aici(daca intram pe View app din merge request pipeline vedem ca nu avem logo-urile sterse) 
-deci trei sa ne integram schimbarile, asta este pretty much parte din partea de CI. Vrem sa integram schimbarile cu alt developer care a sters logo-urile si trebuie sa integram schimbarile noastre in codu nostru(pe branchu nostru actual din requestu de add paragraphs) pt ca am fost unpic intarziati cu merge-urirea schimbarilor astora(de add paraghraph) 
-acuma trei sa ne dam update la branch cu toate schimbarile care s-au intamplat, uneori am putea avea ceva conflicte, dar in cazu asta e putin probabil sa avem, pt ca am schimbat parti diferite ale aplicatiei 
-o sa dam click pe Rebase la Merge blocked, care e un feature foarte convinient pe care ni-l ofera GitLab pt ca nu trei sa mergem inapoi pe cod, nu trei sa merge-uim local schimbarile si sa le dam push din nou, doar dam click pe rebase si pt 95% din cazuri, schimbarile sunt facute in parti diferite ale aplicatiei, cu cat e mai mare aplicatia, cu atat sunt mai mici sansele sa fie un conflict intre aceste merge requestu-uri 
-acuma in branchu nostru, am dat pull de asemenea la stergerea logo-urilor si acum re executam pipelineu, vrem sa ne asiguram ca tot pipelineu merge cum trebe, dam iar review la aplicatie si abea apoi vom da merge, dupa cateva min merge request pipeline a fost successful  
-putem merge si in vs code, schimbam pe branchu add-text si dam pull rebase(cred ca se intampla acelasi lucru ca si daca dam rebase din gitlab) si vedem ca logo-urile au disparut, dar schimbarea noastra cu paragrafu a ramas si pipelineu a fost executat cu succes, environemntu de review a fost creeat si nu mai are cele doua logouri si are textu adaugat deci e perfect, este up to date 
-deci vedem pe acest review env ca schimbarea cu logou vine din celalalt merge request care e acuma parte din main branch si apoi avem schimbarea pe care am facut-o noi cu paragrafu de text adaugat 
-deci acuma schimbarile noastre sunt integrate, gitlab ne zice ca suntem Ready to merge! si asta vom face si prin asta vom da trigger la main pipeline si intre timp putem merge la operate environments si sa vedem exact ce s-a intamplat in termeni de deployment to production si vedem ca a fost finalizat deploymentu cu success, dupa ce ii dam run manual si la ultimu job de deploy to prod 
-daca ne uitam pe production environment vedem ca celelalte doua logo-uri au disparut deci deploymentu a fost de succes acolo si daca ne uitam la deployment history 
-dam pe environmentu production si pe deployment history vedem toate deploymnet-urile din trecut pe care le avem 
-deci asta e o cale foarte realista la cum ne asteptam sa fie merge request-urile folosite intr-un proiect real cu multe merge request-uri care au loc simultan, trei sa facem multe Rebase-uri, pipeline-urile trebuiesc trigger-uite de mai multe ori inainte sa fie facut un merge request 
-deci de asta e super important ca un pipeline sa fie cat se poate de rapid, pt ca daca avem un pipeline incet o sa avem mult timp irosit asteptam sa se termine pipeline-urile ca sa le putem da merge si asa mai departe, deci complica unpic lucrurile 

End-to-end tests with Playwright(E2E tests)

-urm pas ar fi sa inlocuim pasu manual de a deschide siteu si de a verifica daca aplicatia merge corect cu un test automat  
-in aceasta lectie, ne vom uita cum sa rulam teste end-to-end intr-un framework foarte popular numit Playwright 
-testele end-to-end sunt un tip de testare software care verifica daca intreaga aplicatie merge cum trebe de la inceput la sfarsit
-ele simuleaza cum un user real ar interactiona cu softu sa ne asiguram ca toate componentele merg impreuna corespunzator
-in piramida de testare, testele end-to-end sunt chiar in varf, pt ca de obicei sunt foarte complexe si scumpe de executat
-scumpe, adica de obicei cer mult efort pt a fi creeate, pt mentenanta si de asemenea, executia tinde sa fie scumpa in termeni de resurse si de accea vrem sa avem doar cateva 
-oricum ne trebuie neaparat, daca vrem sa nu mai facem noi testarea asta manuala 
-testele end-to-end verifica workflow-uri cheie ca si login-ul, plasarea unei comenzi sau submit-uirea unui form pe toata aplicatia frontend, backend, databases, api-uri externe si orice mai poate fi 
-de asta sunt numite end-to-end, de la user interface pana la un sistem uitat undeva 
-proiectu pe care-l avem noi e relatic mic ca si size, dar are un test end-to-end in folderu e2e, care e relativ simplu, verifica doar daca pagina are un titlu, daca GitLab apare in body si verifica de asemenea daca o versiune apare care e hardcodata deocamdata 
-e un test super basic, oricum acest e2e test deschide un browser, baga urlu aplicatiei si apoi ruleaza acest test pe care l-am mentionat aici
-acuma, cum stie testu care url sa l deschida? dupa cum vedem, nu e niciun url hardcodat in test, e doar un / pe linia 5 
-pt asta trei sa ne uitam la alt file, care e un config file pt acest framework: playwright.config.cjs si in acest file vedem ca e configurat urlu cu un environment variable pe linia 31 APP_BASE_URL
-deci iar, avem un environment variable pe care o putem seta din afara, influentand cum ruleaza o parte din software
-si daca acest env var nu e setata, este un fallback la localhost. Asta e doar pt local development environemnt daca cineva incearca sa execute acest test local 
-dar acum, incercam sa rulam acest test din GitLab, deci trebe sa setam acest environment variable APP_BASE_URL 
-acum vom incerca sa rulam acest e2e test pe aplicatia noastra 
-acuma, cat timp ar avea sens sa rulam teste e2e pt mai multe environmente ca stagins si production, le vom implementa pentru review environment 
-oricum in pasu initial, inca vom folosi production environment doar ca sa avem un environment acolo 
-vrem un nou job in pipeline pe care sa il denimi e2e: si prima data il vom asigna stage-ului .pre pt ca stageu asta este executat primu in pipeline si sa nu asteptam prea mult 
-playwright project deja are un docker image pe care ar trebui sa-l folosim si contine deja multe browsers si e mult mai ok decat imaginea noastra nodejs, car enu va functiona daca o vom folosi 
-copiem numele de aici https://playwright.dev/docs/docker, de ex acuma e docker pull mcr.microsoft.com/playwright:v1.49.1-noble si trei sa folosim exact tagu asta, chiar daca sunt versiuni mai noi, asa e configurat testu sau ceva sa mearga fix cu acest tag 
-numele imaginii este playwright si dupa : avem tagu acesteia, deci numele v1.49.1-noble este o distributie linux numita ubuntu
-partea interesanta este prima: mcr.microsoft.com , care este necesara oricand incercam sa folosim un docker container registry, care nu este registry-ul default numit Docker Hub 
-deci de asta trebe sa specificam tot pathu si asta este un container registry pentru microsoft si de asta adresa trei sa arate asa 
-sa continuam prin a defini variabila de care avem nevoie, deci in variables: , definim variabila APP_BASE_URL: 'https://learn-gitlab-demo.netlify.app/'  ii dam linku de la production environment 
-deci o sa rulam testu pe production environment pt ca este deja acolo si a fost deployed si il putem folosi cu usurinta 
-in script: instalam dependintele npm de care avem nevoie pt proiect pt ca playwright este un project dependencies si avem nevoie sa avem depdenintele astea instalate 
-deci avem comanda - npm ci si vom mai avea si - npm run e2e , rulam comanda asta pt ca este in package.json pe linia 10 
-deci defapt cand rulam comanda npm run e2e, comanda care va fi executata este cea de pe linia 10 din package.json, unde mai vedem ca playwright este un dev dependency deci de asta are sens sa rulam comanda 
-dar oricand suntem nesiguri daca avem neaparata nevoie de o comanda, e cel mai bine sa o stergem, rulam pipelineu si vedem daca inca merge 
-acuma avem totu in place pt un mic test, creeam un branch nou(feature/run-e2e-test), dam push la aceste schimbari, facem un merge request, si ne uitam la executie, vedem ca a fost succesful, vedem comanda run e2e executata si vedem ca au fost 3 teste executate si toate au trecut
-deci din perspectiva asta, acest setup initial este suficient sa confirmam ca avem totu in place si ca am configurat jobu corect

Passing data between jobs with environment variables 

-acuma vedem cum pasam environment variables de la un job la altul intr-un pipeline GitLab 
-acest approach e esential pt a avea o comunicare mai buna intre job-uri si sa reducem configuratii duplicate 
-in testu nostru e2e am hardcodat urlu, dar trebuie sa il luam din netlify_review($REVIEW_URL) pe care l am obtinut din raspunsul comenzii netlify deploy(pt ca e generat random) si pe care trei sa l injectam in jobu e2e 
-deci trebe sa scapam de valoare hardcodata din e2e 
-sa ne uitam la stage-uri ca sa ne asiguram ca job-urile ruleaza intr-o anumita ordine 
-deci dupa stageu deploy_review o sa adaugam un stage numit post_deploy_review 
-si aceste teste e2e o sa fie executate dupa ce suntem gata cu deploy_review, deci de asta vom adauga jobu e2e in stageu post_deploy_review care se executa dupa deploy_review
-in jobu e2e schimbam la stage: din .pre in post_deploy_review
-deci, ca sa ajungem la variabila $REVIEW_URL din netlifi_review, e usor, pt ca deja a fost pescuita din outputu comenzii de deploy si bagata in fileu depoly.env ca si environment variable numita $REVIEW_URL 
-acest file deploy.env a fost publicat ca si artifact, deci noi deja avem acces la REVIEW_URL in jobu e2e 
-sunt cateva lucruri pe care le putem incerca:
-putem folosi $REVIEW_URL direct in variables: APP_BASE_URL: $REVIEW_URL . Deci putem zice ca APP_BASE_URL este REVIEW_URL care vine din jobu anterior 
-si cand suntem nesiguri de variabile, putem rula comanda - env in script sa avem toate environment variables printate pe ecran sau direct cu comanda - echo $REVIEW_URL , cu care printam env vars specifice care ne intereseaza 
-deci daca suntem nesiguri ca REVIEW_URL este disponibil in jobu e2e, putem incerca sa-l printam efectiv 
-putem sa incercam sa prinam su $APP_BASE_URL tot cu echo, astea le punem primele script-uri 
-acuma ne putem intreba de ce nu definim alt environment in jobu e2e si sa i zicem ca gen si el face parte din environmentu preview/$CI_COMMIT_REF_SLUG ca sa poata avea acces la REVIEW_URL automat
-nu facem asta pt ca daca definim inca o data un environment cu acelasi nume, i-am sugera lu GitLab ca defapt dam deploy din acest e2e job si noi defapt nu dam deploy de aici, deci de asta nu are absolut niciun sens sa definim acest environment keyword in jobu e2e 
-dam commit si ne uitam la pipelineu din merge requestu ongoing sa vedem daca totu merge cum trebe 
-deci acuma daca ne uitam la pipeline vedem ca avem un stage aditional la sfarsit cu jobu e2e ca parte din post_deploy_review si vedem ca executia sa a fost de succes si pt scopuri de troubleshoot vedem printate REVIEW_URL si APP_BASE_URL care vin din jobu precedent netlify_review 
-deci linku asta e pasat din jobu netlify_review la jobu e2e printr-un environment variable 
-acesta e un concept foarte IMPORTANT si de aceea o sa rezumam cum merge asta
-deci totu merge pt ca fileu deploy.env(poate fi denumit altfel) este definit ca si un report sub aritfact si e de tipul .env si asta face variabilele care sunt in acest file disponibile in jobu urmator, asta se intampla automat in GitLab 
-daca nu aveam configuratia asta, asta nu ar fi mers si ca sa creeam acest file, am folosit comanda echo in care am specificat numele variabilei REVIEW_URL si fara spatii am pus = si am referentiat o variabila pe care am definit-o in executia jobului, poate fi si altceva, dar de obicei o sa fie ceva dinamic 
-si astfel functioneaza prin acest .env file, GitLab il injecteaza in jobu urmator si noi doar redenumim variabila aici APP_BASE_URL: $REVIEW_URL ca sa ne putem configura testing frameworku si ca sa rulam testu asa si deci asa putem pasa variabile de la un job la altul 
-putem sterge comenzile de troubleshooting din e2e script, cele cu echo pt ca nu avem nevoie de ele 

Assignment: Publish e2e Junit report 

-trei sa publicam ca si artifact junit reportu generat de testu e2e 
-asa ca vom cauta in playwright.config.cjs unde este pus acest raport junit generat 
-vedem ca avem reproter: care o sa face un junit ca si output file in folderu reports/playwright-junit.xml , deci fix acest path trei sa il punem la artifacts in jobu e2e 
-facem ceva asemanator ca la jobu unit_tests 
-solutie: sunt doua modalitati de a ne da seama unde a fost generat acest raport una grea si una usoara 
-deci cautam un report dar n avem idee unde este generat acel report, dar stim ca comanda npm run e2e trebuie sa genereze reportu 
-stiind asta, tot ce trei sa facem este sa listam file-urile inainte si dupa ce comanda este executata, folosind comanda - ls -la 
-dupa executie ne uitam pe log si vedem exact ce fisiere aditionale sau foldere au fost creeate daca comparam cele doua liste 
-dupa ce facem asta o sa observam ca singura diferenta in acest caz este ca folderu reports apare si putem continua sa dam cd in folder si sa listam reports-urile din folder 
-dar daca suntem mai destepti, putem sa publicam direct raports urile direct ca si un artifact , deci folosim when: always sa ne asiguram ca reportu asta e mereu publicat si specificam pathu reports/ si asta se va asigura ca avem acces la acele file-uri si apoi mergem si cautam prin aceste file-uri si vedem direct unde este raportu junit care a fost generat de playwright, deci vom gasi efectiv numele fileului de care avem nevoie 
-deci vom avea asa:

script:
  - npm ci
  - ls -la 
  - npm run e2e 
  - ls -la 
artifacts: 
  when: always 
  paths:
    - reports/ 

-mai e si modalitatea usoara in care stim ca playwright are acest config file numit playwright.config.cjs 
-putem sa ne uitam la acest file aflat in rootu proiectului si gasim configuratia pt reporter si vedem aici la reporter: 'junit' care are un output file specific 
-deci totu e configurat undeva doar ca trei uneori sa sapam prin configuration si sa ne dam seama unde sunt chestiile 
-cumva e parte a job-ului ca trb sa lucram cu tool-uri diferite si framework-uri diferite si nu suntem experti in ele probabil dar observam niste pattern-uri sau intelegem roughly cum ar trebui sa functioneze lucrurile 
-deci mereu sunt niste configurations pe undeva si in acest caz, aici se ascundea configuratia junit 
-asa ca sa dam publish la acest junit report din acest path (putem pastra comenzile de ls si paths: - reports/)
-asa ca dam commit la schimbarile pe care le am facut si noi: 
  artifacts:
    when: always
    reports: 
      junit: reports/playwright-junit.xml
-si ne uitam in merge request sa vedem daca acest report a fost publicat properly
-dupa executia cu succes a pipelineului vedem la Test summary in request ii dam expand si vedem unit testele pe care le am configuart anterior dar vedem si e2e test acuma si putem da pe full report si vedem testu e2e dam pe el si putem sapa prin fiecare test individual si sa intelegem ce a facut exact testu ala 
-asa ar trebui sa arate report jnunit pt acest playwright test 
-mai trebe sa facem un lucru pt e2e test, ca sa ne asiguram ca pipelineu main nu o sa dea fail, este sa excludem acest test din main pipeline, pt ca deocamdata nu sunt execution conditions care vor fi executate pt merge request pipeline, deci va fi executat de asemenea pe main pipeline si nu vrem sa avem jobu e2e acolo   
-de aceea trebe sa compiem toata sectiunea de rules: pe care o avem la netlify_review si ii dam paste in e2e job sub stage
-astfel ne asiguram ca testele e2e nu ruleaza din greseala in pipelineu main 

Publishing a HTML report 

-in configuratia playwright avem si un html report care e generat intr-un anume folder, unde il avem pe cel junit 
-in lectia asta, vrem sa adresam aspectu de a publica rapoarte html din GitLab si sa explicam pe scrut de ce e unpic mai complicat in comparatie cu alte tipuri de raport-uri 
-cea mai usoara calea sa publicam reportu este prin configuratia artifacts: si tot ce trei sa facem este sa punem paths: si putem sa definim folderu care a fost specificat in config complet sau putem publica tot folderu reports si apoi vom avea acces la toate sub folderele 
-deci asta e approachu pe care il vom lua in acest caz, doar ca sa simplificam lucrurile, deci vom da commit la schimbari si ne uitam la pipeline 
-bagam paths: - reports/ sub when: always  
-executia pipelineului a fost successful si ca sa accesam reportu HTML, tre sa mergem in pipeline, in stageu post_deploy_review la jobu e2e  
-si vom avea Job artifacts in dreapta log-ului si acolo avem butonu Browse si vedem folderu reports care contine si folderu care ne intereseaza: playwright-html , in care avem index.html pe care putem da click si care ne va deschide un link pe care putem da click  
-sunt cativa pasi pe care trei sa i facem, dar acesta e reportu care a fost creeat de playwright 
-si ne putem uita la el si sa vedem mai multe chestii aditionale pe care un report normal nu le va oferi
-tre sa dam cateva click-uri ca sa accesam acest report si nu e integrare cu gitlab ui, dar daca ceva da fail si raportu html e foarte detaliat si ne ajuta sa dam troubleshoot la problema, merita 
-acest report playwright merge fara probleme, dar report-uri din alte framework-uri care sunt mai complexe ar putea suferi de la niste erori si am putea primi un whitepage sau o pagina care nu e formatata corespunzator si daca dam click dreapta si inspectam console output vom vedea in consola niste erori, ceva legat de CSRF
-acestea sunt niste protectii de securitate, dar icnercand sa dam publish la niste rapoarte HTML mai avansate prin acest approach poate conduce la rapoarte stricate si nefolosibile 
-nu e niciun quickfix pt asta, dar in termeni de a publica raporate HTML este o cale mai buna sa facem asta, care e facuta prin GitLab Pages     

Setting a build version 

-prin pipelineu nostru avem mai multe environment-uri: diferite environment-uri de review, staging environment, production environment
-destul de des, daca facem schimbari care nu sunt usor vizibile ca schimbarea titlului principal sau ceva de genu 
-cand ne uitam pe diferitele environment-uri nu suntem chiar siguri ce versiune de aplicatie este acolo
-desigur, o parte din informatia asta e deja disponibila in GitLab, dar uneori ar fi frumos sa vedem ceva in aplicatia prorpiu zisa 
-in cazu asta, vedem ca jos avem Aplication version: 1 , care e hardcoadata sa fie 1 
-de obicei e important sa identificam versiunea curenta a build-ului pe un environment anume si de asemenea, sa confirmam ca versiunea corecta a fost deployed pe acel environment 
-deci nu doar ca sa credem ce ne zice GitLab, dar sa avem o cale de a verifica cine a dat deploy la aceasta versiune si deschidem environmentu si vedem acea versiune exacta 
-asta o sa facem in lectia asta, e relativ usor 
-deschidem vs code si creeam un nou branch: feature/app-version, dupa ce dam merge la requestu anterior si dam pull pe branchu main 
-vom face schimbari in codu sursa ca sa dam replace la Aplication version: 1 ce vedem noi pe pagina noastra 
-intram in App.jsx si pe linia 32, in loc de 1 punem: {import.meta.env.VITE_APP_VERSION} care e un envirionment variable
-ideea folosirii aici a unei environment ariable este ca vrem sa dam provide la acest env var in timpu de build si cand aplicatia este built, acel env var o sa fie inserat aici si o sa fie parte din aplicatie propriu-zisa. O sa fie versiunea hardcodata deci nu o sa mai fie o variabila, e ceva care o sa fie replaced in timpu build-ului 
-de aceea, copiem numele VITE_APP_VERSION si mergem in pipeline si in variables: sus de tot, ce putem face, este sa definim o noua variabila: VITE_APP_VERSION: 
-cum putem face lucrurile dinamice? ca reminder, avem lista asta cu predefined variables oferite de GitLab si mereu e o idee buna sa ne uitam pe lista si sa vedem daca putem folosi ceva de aici 
-si vedem variabila CI_COMMIT_SHORT_SHA care este o versiune scurta a id-ului de commit 
-asta e mereu unica si nu o sa avem niciun conflict, nu e un numar, e o serie de numere si litere si nu e incremental(efectiv idu unui commit de ex a8d07a09) si o sa vedem imd cum arata si deci daca este o alegere buna pt situatia noastra 
-mergem inapoi in vs code si la variables: o sa avem asa: variables: VITE_APP_VERSION: CI_COMMIT_SHORT_SHA
-si aceasta variabila o sa fie disponibila si pt state-ul build  
-o sa avem nevoie de acest application version doar in jobu build_website 
-dar cand suntem nesiguri de ceva ca poate fi folosit si altundeva in proiect, mergem la search pe stanga pe lupa de sub file explorer si vedem ca pot fi si alte use case-uri ale acesteia 
-si unul dintre use case uri este aici(dam click pe ce ne gaseste inafara de ce am scris noi) in e2e in app.spec.cjs si vedem ca acest env var este folosit intr-un test e2e, care este important pt ca verifica daca acea versiune a fost cu adevarat deployed 
-deci ne asiguram ca avem exact acest string care apare aici de asemenea si de asta are sens sa avem VITE_APP_VERSION ca si global variable pt ca asa avem acces si un build job(build_website) dar si cand rulam testele e2e mai tarziu in pipeline 
-dam commit la schimbari, facem merge request, rulam pipelineu si vedem exact ce se intampla
-dupa executia pipeline-ului, vedem pe merge request ca apare butonu View app pt environmentu de review si cand dam pe el, vedem application versionu pe pagina: Application version: 1b025a65
-daca dam copy la acel id si ne intoarcem pe pagina cu requestu sau la Commits(daca dam pe history din main pageu proiectului ne duce pe lista de commit-uri), si dam ctrl f si bagam acolo idu vedem ca este exact acelasi 
-deci, ne este usor sa identificam care este ultimul commit care este deployed intr-un environnment specific si un beneficiu adaugat este ca testele e2e verifica si ele asta
-deci chiar daca avem un environment, poate din ceva motiv, environmentu nu a fost updatat, dar apoi, testu e2e va verifica daca acest id vine de pe site si asta se intampla doar daca deploymentu a fost successful 

A critical analysis of the pipeline 

-sa facem un pipeline necesita mult efort si de obicei suntem multumiti cand tot merge cum trebe 
-oricum, e un practice bun sa punem pauza uneori si sa reflectam la ce am facut
-sigur, pipeluneu ar putea merge properly, dar usor de inteles si mentinut? daca revizitam acest pipeline peste o luna o sa intelegem atunci ce se intampla? avem increderea care ne trebuie sa facem schimbari? sa ne luam un minut sa reflectam la ce am facut pana acuma 
-o sa incepem cu timpu de executie al pipeline-ului curent de la ultimu merge request sa zicem care este cam de 3 minutes 2 seconds, care nu este mult, dar pt proiectu asta simply, asta putea fi facut mult mai rapid, poate in jumate din timpu asta 
-sa incercam sa intelegem unpic unde este timpu nostru folosit si unul din job-urile care ar avea nevoie de ceva timp este deploymentu netlify_review: 1 minute 8 seconds
-acest job ar putea fi executat in sub 30 de secunde, deci unde e problema? problema este ca instalam niste software aditional in timpul executiei job-ului de ex netlify-cli, curl, jq , dar pe acestea nu le putem sterge doar sa salvam timp pt ca avem nevoie de ele pt executie 
-instalatu de dependinde la runtime este foarte scump si in cazu asta, dubleaza timpu de executie
-o solutie pt asta ar fi sa folosim o imagine docker custom pe care o putem folosi da vedem mai incolo in curs
-dar, ca un good practive, sa ne uitam mereu la job-urile noastre si sa incercam sa vedem cat de rapide sunt si unde este timpu ala investit din punct de vedere al executiei si daca e ceva ce putem face sa facem acel job si pipelineu overall mai rapide 
-cand un pipeline ia mult timp, ne consta timp si cand asteptam sa ruleze pipelineu, in merge request, in branchu main si in general ne impacteaza, e ca o linie de productie inceata intr-o fabrica 
-intorcandu-ne la overview-ul pipeline-ului, vedem ca rulam testele e2e pe review environment, dar daca schimbam pe main branch, vedem ca aici nu sunt teste e2e executate pe environmentele de staging sau production 
-si in general, am vrea sa avem teste e2e si aici in special pe staging, dar ar trebui sa le consideram si pe production pt ca branchu main e foarte important si vrem sa ne asiguram ca aplicatia merge corespunzator
-in cazu asta, nu am vrut sa avem mult cod duplicat in pipeline, dar teoretic, am putea copia configuratia pt jobu e2e si destul de usor am putea creea stage-uri aditionale si sa rulam acesti pasi de asiemenea si dupa staging si production, dar asta ar duce la mult cod duplicat si vom repeta mula logica degeaba 
-pt astfel de situatii, are sens sa creeam template-uri refolosibile pt acest tip de job-uri si sa dam doar provide la env vars in configuratii care se schimba de la un environment la altul 
-in general, incercam sa evitam pe cat posibil sa ne repetam in configuratia pipeline-ului, pe langa asta mai sunt niste situatii unde am harcodat informatii in pipeline si nu e prea ok, avem de ex NETLIFY_SITE_ID, pe care am putea sa il tinem intr-o variabila ca si cum am facut cu NETLIFY_AUTH_TOKEN, deci nu e nevoie sa avem variabila asta aici, e mult mai ok fara si asta ne permite sa ne mutam pe un environment diferit si sa nu facem schimbari in cod 
-am putea face toate schimbarile din GitLab UI, sa updatam tokene, SITE_ID-uri si configuratia pipeline-ului sa ramana aceeasi 
-deci din perspectiva asta, sa avem NETLIFY_SITE_ID hardcodat aici nu e o idee buna. Deci putem merge la Settings -> CI/CD si la Variables sa adaugam aceasta variabila ca sa nu o mai avem hardcodata in configu pipeline-ului
-acelasi lucru se intampla si in jobu netlify_staging, urlu pt environment e si el hardcodat aici, dar am putea sa facem cum am facut si pt production environment si sa folosim GitLab ca sa dam store la informatia despre acest environment 
-deci iar alta configuratie care e parte din pipeline si nu ar trebui sa fie 
-am adaugat asta in pipeline ca sa avem un exemplu si ceva sa reflectam pe el sa intelegem pe viitor cum sa facem un pipleine mai bun 
-un pipeline nu merge mereu perfect, am putea avea probleme, unele chestii ar putea da fail, deci de asta e important sa stim ce se petrece si sa ne asiguram ca avem destula informatie sa dam troubleshoot la problema 
-de ex, in unele locuri am folosit comenzi echo sau cat sa inspectam continuturile unui file sau ale unei variabile. Acuma ne am putea gandi daca are rost sa avem comenzile astea aici care sunt pt scopuri de trobule shoot in pipelineu nostru, daca ne ajuta sau e doar informatie aditionala de care nu avem nevoie in situatiile de zi cu zi 
-dar putem sa simulam anumite fail-uri, de ex sa mergem pe gitlab ui si dam rename la tokenu pt netlify ca tokenu sa nu mai fie available ca deploymentu sa nu mai mearga, vom avea destule informatii din log-uri sa intelegem ce s-a intamplat? asta are nev de unpic de experimentare 
-pe langa asta, daca avem cv comenzi de troubleshoot in codu nostru(echo, cat), probabil nu e o idee proasta sa adaugam un comment in care zicem ca e doar pt scopuri de troubleshoot, ne asiguram ca avem in logs diverse informatii in caz ca ceva da fail, va fi mult mai usor sa dam inspect la ceva, si asta ar putea fi o idee buna 
-in general, daca suntem nesiguri de ceva din pipeline, si nu stim daca aceasta configurare este inca nevoie de ea, mai e nevoie de aceasta comanda? cea mai buna cale sa invatam este sa stergem comanda sau configuratia respectiva si sa rulam pipelineu sa vedem ce se intampla 
-trebe sa ne asumam ce este in pipeline si cea mai buna cale de a invata este sa experimentam sa intelegem lucruri pe cont propriu, sa investim timpu, si cand stim exact ce face o configurare in pipeline sau in configu jobului, vom sti exact daca acea configurare este necesara si vom sti exact ce face si stim exact ce se intampla daca nu o avem 
-sa nu ne fie frica sa experimentam, asta e una dintre caracteristicile cheie ale unui devops de succes 
-in plus pe langa builduirea de imagine docker custom, netlify poate fi adaugat si ca si project dependency si daca ne uitam la documentatia package-ului, scrie asta si aici 
-zice calr ca atunci cand folosim netlify cli intr-un environment ci e recomandat sa fie instalat local ca un development dependency in loc sa fie globally cum o facem acum 
-deci acest approach de adaugare a netlify cli ca si un project dependency poate duce de asemenea la timpi mai mici de build 
-deci in before_script in joburile netlifi_review, netlify_staging si netlify_prod in loc de comanda: - npm install -g netlify-cli , putem avea comanda: - npm install --save-dev netlify-cli 
-dar asta merge doar daca proiectu insine este doar un proiect de nodeJs, daca o tehnologie diferita este folosita, atunci acest approach de instalare de npm locala, nu va merge pe web 

Continuous Deployment to AWS 

Amazon S3(object storage) 

-prima oara o sa lucram cu S3(simple storage service) la care ne putem gandi ca si Dropbox dar mult mai bine potrivit pt devops, care chiar a folosit S3 in spate in trecut pt storage de files 
-din moment ce website-ul nostru este static si nu are nevoie de computing power sau o baza de date(spre deosebire de voting app unde am folosit ec2) vom putea folosi amazon s3 sa dam store la file-urile noastre publice si sa le facem disponibile lumii intregi prin http 
-ca sa incepem, trei sa creeam un bucket. In s3, file-urile sunt stored in buckets si ne putem gandi la un bucket ca la un folder supersized. File-urile pe care la bagam in galeata sunt numite obiecte, asa ca sa creeam un bucket ca sa bagam file-uri in el 
-dam Create bucket si numele e important ca trei sa fie unic si putem sa punem de ex ceva de genu learn-gitlab-202503171022 si lasam restu setarilor cum sunt si dam Create bucket la sfarsit si vedem ca avem nucketu creeat si ne duce in dashboardu S3 cu lista tuturor buckets-urilor pe care o sa o vedem mereu cand intram pe S3 in AWS 
-vedem ca ne afiseaza buckets-urile din toate regiunile, dar ne zice si in ce region a fost creeat bucketu nostru learn-gitlab, dam pe el sa-i vedem contentu si vedem ca acuma nu are nimic in el, daca dam store la un file, acela ar fi un object 
-prin aceasta interfata pe care o ofera serviciul, putem creea foldere, sa uploadam file-uri, le putem downloada si sterge, le putem da si rename deci cam toate operatiile pe care le putem face de obicei cu file-uri
-oricum, si daca am fi putut sa ne uploadam website file-urile noastre prin acest UI, nu acesta este obiectivul pe care vrem sa-l obtinem cu acest curs. Vrem sa automatizam procesu si asta vom face acuma 

AWS CLI 

-ca sa uploadam file uri pe S3 fara sa interactiunam cu UI, putem prin AWS CLI cu care putem interactiona dintr-un pipeline GitLab cu un serviciu AWS(cand folosim un serviciu in general, scirem cli dupa numele lui in searbar la google sa vedem daca exista un cli si in cele mai multe cazuri este)
-daca vrem sa instalam aws cli local, sunt instalere pt windows, macos si linux, dar putem folosi si imaginea docker oficiala pt aws cli. Sa incercam sa folosim imaginea in pipelineu nostru 
-o sa incepem cu un pipeline foarte foarte simplu unde avem doar build jobu si folosim un env var pentru vite app version
-incepem cu un pipeline foarte simplu unde avem doar jobu build_website
-acuma sa intelegem cum functioneaza aws cli in general, sa printam versiunea de aws cli 
-definim un nou job aws_s3 pe care il asignam in stageu .pre ca doar experimentam si jobu va fi executat primu in pipeline 
-acuma, punem image: amazon/aws-cli si mai tarziu o sa selectam si un tag specific
-acuma, sa vedem cum rulam acest tool ca sa printam versiunea, deci punem script: 
-mereu cand lucram cu un tool cli, trebuie sa lucram cu documentatia si fiecare tool cli va avea niste informatii si in pagina de la aws cli avem butonu Command reference 
-aici vedem ca aws cli merge cu mai multe servicii si sunt toate listate aici, dar noi dam pe Command refrence si o sa ne zica la modu general cum functioneaza aws cli 
-si vedem ca totu intr-o comanda de aws cli incepe cu aws si are urm sitaxa: aws [options] <command> <subcommand> [parameters]
-la global options vedem ca avem --version , care este o optiune globala pe care o putem aplica pe executabili aws pe comanda aws si care va printa versiunea tool-ului, deci asta cautam 
-deci trei sa scriem comanda aws --version in script . Asa stim ce comenzi sa scriem 
-acuma nu ne intereseaza restu job-urilor(sau doar jobu build) asa ca adaugam un punct in fata lor ca sa le dam disable 
-facem un branch, dam commit si ne uitam la pipeline cum da fail 
-dar vedem ca nu exista niciun pipeline
-in configuratia noastra GitLab, daca dam disable la un job care este parte din stageu build si nu mai e parte din pipeline, deci jobu e out, mai ramanem doar cu un singur job, parte din pre-stage, acuma GitLab are acest comportament, care este gen intre bug si feature, unde daca un pipeline contine doar job-uri pre sau post stages, nu va creea un pipeline
-deci daca ne intrebam de ce nu merge este din cauza acestui comprotament si doar am vrut sa demonstram pe scurt asta, deci va trebui sa lasam jobu build_website parte din pipeline sau sa schimbam stageu la jobu aws_s3, daca chiar nu vrem sa avem celalalt job, dar e un behaviour interesant despre care ar trebui sa stim
-deci dam commit dupa ce stergem punctu din fata job-ului build_website si vedem ca pipelineu este creeat si jobu aws_s3 va da fail cu exit code 252 
-avem o eroare care zice ca argument command invalid choise si ne da o lista cu toate choise-urile valide 
-chestia interesanta e ca comanda pe care am executat-o nici macar nu apare in log(aws --version) 
-deci avem using docker image si dupa care direct eroare 
-se intampla asa pt ca aceasta imagine docker are configurat un ENTRY POINT 
-un entrypoint intr-o imagine docker este o configuratie care defineste behaviour-ul(ce sa faca by default) default cand un container este pornit si specifica comenzi ar trebui sa ruleze containeru cand este pornit 
-definind un entrypoint, containeru se comporta ca un tool specializat lightweight, deci putem porni containerul din CLI si sa specificam direct interactiunea cu tool-ul. In acest caz, putem interactiona direct cu tool-ul AWS CLI 
-in timp ce acest behaviour e ok daca folosim asta pe un terminal de computer, nu e folositor intr-un pipeline ci/cd, defapt complica lucrurile pt noi 
-deci eroare asta aparte pt ca atunci cand pornim containeru, pronim deja comanda AWS si nu ii dam provide la niciuna dintre aceste optiuni sau comenzi la care se asteapta, de asta apare eroarea asta, deci prima noastra comanda nu este executata 
-ca sa lucram cu astfel de containere care au un entry point defined, putem suprascrie asta in GitLab si configuratia nu e grea deloc, dar sunte cateva lucruri pe care trei sa le facem 
-in primu rand, referitor la image, trebuie sa o impartim in doua proprietati, prima oara identam in image: o proprietate numita name: si ii dam numele actual al imaginii pe care il vom folosi 
-si urmatoarea proprietate, cea game changer, este entrypoint: care este o alta prorpietate a imaginii si in acest caz ce vrem sa facem este sa dam override la entrupoint si pt asta o sa folosim aceasta sintaxa particulara, deci de obicei, putem da provide la un entrypoint, de aceasta data, folosind parantezele patrate in care punem '' sau "" asa: ['']  , asta va defini un entrypoint gol    
-dam commit si ne uitam iar pe log sa vedem daca totu functioneaza cum ne asteptam 
-acuma, dupa executia de succes a job-ului, ne vom putea vedea comanda noastra in log si la ce va da print
-de unde vine versiunea aceasta(2.24.24)?
-cand avem in configuratia noastra ceva de genu, amazon e numele providerului si aws-cli este numele tool-ului pe care vrem sa il folosim, daca nu specificam o anumita versiune printr-un :tag, o sa primim automat ultima versiune
-deci daca rilam tool-ul acesta azi, vom primi aceasta versiune 2.24.24, dar daca il rulam maine, s-ar putea sa primim alta versiune 
-in general, asta nu e o idee buna, ar trebui sa folosim o versiune fixed pentru imaginea noastra si ca sa aflam asta, mergem pe docker hub la imaginea noastra https://hub.docker.com/r/amazon/aws-cli si mergem la Tags si alegem tagu cu versiunea pe care vrem sa o folosim
-in cazu nsotru, sa zicem ca stim ca versiunea asta 2.24.24 merge cum trebe si putem sa o folosim pe aceasta, daca dam click pe tagu acesta(2.24.24) o sa ne zica exact ce trei sa punem in pipelineu nostru, amazon/aws-cli:2.24.24 
-deci, acuma o sa folosim imaginea cu tagu asta specific si aceasta imagine va contine aws cli cu versiunea 2.24.24 azi si daca rulam asta peste o luna, va avea exact aceeasi versiune, deci acuma am blocat versiunea si daca stim ca aceasta comanda anume sau setup-u nostru merge cu aceasta versiune, atunci avem un pipeline stabil, care nu e influentat de schimbari exterioare 

Managing AWS services with AWS CLI 

-o sa mergem prin procesu de a rezolva o anume problema cand folosim aws cli 
-sa zicem ca vrem sa facem ceva basic cu serviciu amazon s3, care ar fi de ex sa listam toate obiectele care sunt intr-un anume bucket, deci cum putem sa facem asta?
-incepem cu aws cli command refrence si mergem pas cu pas sa intelegem cum sa rezolvam probleme si pt alte servicii aws https://awscli.amazonaws.com/v2/documentation/api/latest/index.html
-aici vedem o lista cu toate serviciile aws prinre care se afla si s3, pe care o sa intram si ne da explicatii tehnice despre s3 dar e bine sa ne luam niste timp sa citim documentatia sa intelegem exact care i treaba 
-daca dam scroll vedem ca sunt niste lucruri pe care le putem face, de ex daca vrem sa listam file-urile dintr-un bucket, putem folosi comanda ls pe care o folosim cu sintaxa de comanda: aws s3 <Command> [<Arg> ...]
-deci ca sa afisam/listam ceva, comanda e: $ aws s3 ls
-in josu paginii, vedem ca putem intra pe pagina dedicata comenzii ls si vedem ca poate lista buckets-urile efectiv sau obiectele unui anume bucket 
-sa punem comanda de listare a buckets-urilor s3 in scriptu nostru: - aws s3 ls 
-stiam ca va crapa pt ca nu am configurat aws cli-ul sa mearga cu contu nostru de aws si zice unable to locate credentials si ne zice si ce comanda trei sa folosim ca sa configuram aceste credentiale: $ aws configure 
-ne asteptam la eroarea asta pt ca: cum poate aws cli sa stie cine suntem? si daca asta ar merge cumva, asta ar insemna ca oricine altcineva ar avea acees la contru nostru si la bucket-urile noastre si sa le vada continuturile, deci n-ar avea niciun sens 
-deci partea asta de autentificare cand folosim un cli, este parte din proces si de obicei este cel mai greu lucru 
-de asta incepem cu o comanda basic, pt ca avem nevoie de ceva care are nevoie de credentiale si dupa ce configuram cum trebe asta, apoi va merge 
-pe scurt, tre sa i zicem lu aws cli cine suntem oferindu-i niste credentiale si atunci cand incercam sa listam content-urile unui bucket, ar trebui sa specificam si bucketu  
-putem merge in documentatie sa ne uitam sa vedem exact ce fac comenzile pe care le folosim cu exemple(de ex comanda ls)

Identity management with AWS IAM 

-ca sa reparam eroarea de mai sus, tre sa bagam numele si parola de la amazon in environment variables ascunse? nu chiar 
-cand folosim aws cli, nu putem folosi useru si parola pe care le-am folosit sa ne logam in AWS management console si oricum, nu ne trebe toate serviciile pe care credentialele root le pot oferi, incercam sa interactionam doar cu serviciul S3. Deci prin design, este un lucru bun ca asta nu se poate intampla
-acuma vom creea un set de credentiale care au un scop mult mai ingust si care ne permit sa interactionam doar cu serviciul s3 din aws cli. Ideea este ca atunci cand incercam sa folosim un serviciu, ar trebui sa asignam doar permisiunile minime de care avem nevoie sa facem jobu
-asta se numeste The principle of least privilege si ca sa ne ajute cu asta, aws are un serviciu numit Identity and Access Management(IAM) 
-intram pe iam(care de asemenea e serviciu pt menegiuirea multifactor identification-ului pt contu root si vedem ca nu avem MFA added, putem sa-i adaugam) 
-acuma vom creea un user care are doar permisiuni pt s3 buckets din meniul din stanga unde avem Users si dam Create user cu numele gitlab fara sa bifam checkboxu in care ii dam acces la AWs Management Console, deci nu creeam un user care se va loga in management console, deci de asta e ok sa nu avem optiunea bifata ca nu ne trebe 
-dam Next si acuma e cu partea permisiuni si by default useru nu e lasat sa faca nimic si o sa i atasam policies userului 
-ne putem gandi la un policy ca un set de rules care definesc ce actiuni poate performa un user pe diferite resurse AWS, de ex putem asigna un policy care permite acces full tuturor bucket-urilor s3 
-cautam s3 in search boxu pt policies si vedem ca gasim un policy numit AmazonS3FullAccess care da acces full la toate buckets-urile, o sa mergem initial cu poloci-ul acesta, il bifam si dam Next 
-ajungem pe pagina de review in care vedem ca am dat un nume userului si i-am atasat un policy si dam Create user 
-ca sa putem folosi AWS CLI cu acest user, trebuie sa-i creeam access keys, dam click pe user din pagina Users si avem doua optiuni sa facem asta
-putem da click in stanga sus la Summary oe Create access key sau putem merge la tabu Security credentials unde avem o seciune numit Access keys unde putem da Create access key 
-un Access Key in AWS este ca un user si o parola, dar e folosit pt programe si tool-uri ca AWS CLI care permite accesu la serviciile AWS, deci in loc sa avem o persoana care se logheaza in AWS Managemenent Console, folosim un access key cu AWS CLI sa menegerieze acele servicii 
-pt use caseu nostru, vom folosi Command Line Interface si o sa ne dea un warning dar bifam I understand the recommendation(care nu se aplica pt usecaseu nostru) si dam Next 
-putem sa i punem si un Description ca sa stim mai tarziu de ce am creeat acest access key, de ex: Access key for GitLab si ii dma Create access key 
-acuma vedem aici doua chestii Access key si Secret access key, pt ca access key contine doua parti, are access key id care e un identifier ca un fel de username si un Secret access key pe care nu l vedem acuma pe ecran pt ca e un secret, e ca un fel de parola. Astea doua merge doar impreuna ca un user si o parola, deci sunt o combinatie si impreuna ne pot ajuta cu AWS CLI sa interactioneze in mod securizat cu un serviciu AWS     
-ne zice aws niste recomandari aici gen sa nu tinem secret access keyu in plain text, sau intr un code repo sau in code 
-ne mai zice sa o stergem sau sa-i dam disable cand nu mai avem nevoie de ea 
-ne mai recomanda sa dan enable la least-privilege permissions, noi am folosit acuma o permisiune destul de puternica(AmazonS3FullAccess) si asta nu adera 100% la acest principiu pt ca scope-ul poate fi subtiat la un singur bucket sau chiar la o singura lista de actiuni specifice 
-pe romaneste, permisiunea AmazonS3FullAccess este prea puternica in general si ar trebui sa fie evitata, dar e mai complicat sa configuram o permisiune custom si asta nu face scopu cursului 
-ne mai recomanda sa schimbam aceste credentiale in mod regulat pt ca daca cienva reuseste sa puna mana pe aceste keys, usageu lor e foarte limitat, daca le priedem trei sa creeam altele ca nu putem sa le dam retrive nicicum si trei sa le stergem sau sa le dezactivam pe cele vechi 

Managing AWs credentials in GitLab - Assignment 

-acuma trei sa securely store aceste access keys compuse din acces keys id si secret access key in GitLab 
-deci vrem sa securely store this information in GitLab 
-tre sa ne uitam unpic pe documentatia AWS CLI configuration Variables si sa ne dam seama ce environment variables tre sa definim ca AWS CLI sa poata gasi access key id si secret access key. Daca aws cli reuseste sa le gaseasca ar trebui sa scapam de eroare unable to locate credentials si sa vedem in log ca comanda $ aws s3 ls va printa lista de buckets din contu nostru si ar trebui sa vedem si galeata learn gitlab  
-in documentatie, la inceput, ne zice ca valorile de configurare pe AWS CLI pot veni din mai multe surse, printre care si Environment variable https://docs.aws.amazon.com/cli/latest/topic/config-vars.html , deci asta ne confirma ca putem folosi env var sa configuram aws cli 
-dam scroll mai jos in documentatie si gasim subtitlul Credentials si ne confirma iar ca putem folosi env vars ca sursa pt credentials 
-aici vedem access_key si secret_key si vedem si cum ar trebui denumite aceste env vars 
-in gitlab mergem pe settings ci/cd la variables si dam Add variable si prima se numeste AWS_ACCESS_KEY_ID pe care il adaugam la Key(putem scrie doar AWS si ne va da hint uri pt denumirile stas de variabile) 
-ne mai trebe si Value pe care il luam din AWS, copiem acces key id si ii dam paste la Value 
-mai trei sa ne gandim si la Visibility si pt ca e un username si nu un secret, deci il putem avea ca si Visible, putem sa ii dam si Masked sa nu apara in logs, dar nu e o idee buna sa o avem hidden pt ca daca mai tarziu incercam sa schimbam aceste credentiale nu voi putea sti ce id am aici, deci pt ca nu e secret, nu recomand sa avem masked and hidden, deci visible pt acest usecase este super ok 
-mai avem 2 flag-uri , unul cu protect variable si daca il tinem bifat, va fi expus numa pe branchu main, daca creeam un branch secundar si vrem sa facem cv cu aws cli, aceste variabile nu vor fi disponibile acolo, deci il putem lasa bifat pt usecaseu nostru 
-expand variable nu avem nevoie deci putem debifa 
-putem sa i adaugam si Description sa stim dc am creat acest env var peste mult timp, in rest lasam variable default si environment all default pt ca jobu nostru nu e asignat la vreun environment deci putem lasa asa
-cam asta e, putem sa ii dam add variable 
-acuma creeam varu AWS_SECRET_ACCESS_KEY pe care il punem la key si ii luam valoarea din aws si ii dam paste la Value in gitlab 
-la aceasta variabila vrem sa avem Masked and hidden ca daca cineva are acces la ea sa nu o poata vedea chiar daca au interfata asta disponibila
-ii dam bifa si la Protect variable si debifam Expand variable refrence pt ca ar putea fi un $ in valueu variabilei si nu e bine si dam add variable 
-acuma le avem pe ambele adaugate la prima daca dam edit o putem vedea si edita 
-dar la cea secret ii vedem doar numele si valoarea e mascata is ascunsa permanent 
-mergem sa vedem daca merge jobu, in cazu nostru n am facut niciun code change deci nu e nimic care va da trigger la pipeline, deci trei sa mergem pe jobu care a dat fail, si dupa ce deschidem logu avem sus dreapta butonu de Retry si dam pe el 
-o sa restarteze jobu si acuma avem env vars config si vor fi preluate de aws cli 
-acuma vedem ca jobu da scuces deci authenticare a fost successful si ne da lista cu bucket urile pe care le avem in s3 incluzando pe cea pe care am creeato 
-!!!!! ATHUNG sa debifam protect variable sa mearga si pe alte bracnh uri decat main pe ca de aia ne tot crapa dreaq

Hosting a website on S3 

-acuma ne configuram bucketu s3 intr-un fel care o transforma intr-un web server care va face file-urile din bucket accesibile public, va fi un proces de 3 pasi si trei sa configuram cateva lucruri 
-mergem pe bucketu nostru learn-gitlab la Properties si dam pana jos la Stativ website hosting si vedem ca este Disabled si ca AWS ne recomanda sa nu folosim S3 pt static web hosting, il folosim ca e un exemplu usor, nu pt ca este cel mai bun use al AWS-ului, dar pt scopuri de invatare, e o idee buna sa putem da enable la asta
-deci ii dam pe Edit si ii dam Enable si apoi avem Hosting type care este Host a static website 
-un static website este un website care are doar file-uri HTML statice, file-uri CSS, imagini. Nu e un website care ruleaza un framework sau face computations, se conecteaza la o baza de date, deci e un simplu website 
-pe langa asta, sunt cateva chestii pe care trei sa le completam, una este Index document, care inseamna ca daca cienva deschide siteu, ce o sa vada exact, unde vor merge? si o sa zicem ca vrem sa ii trimitem la acest bio numit index.html(asta o sa vada ei, acesta este source fileu pt htmlu site-ului)     
-la Error document nu trei sa specificam o pagina pt asta 
-acuma dam Save changes 
-acuma am dat Enable la acest static website hosting si daca dam scroll pana jos o sa ii vedem si adresa site-ului unde acesta este acuma accesibil, nu e cea mai frumoasa adresa pe care o putem avea, dar e ok 
-daca intram pe adresa, vedem ca o sa ne luam o eroare pt ca nu suntem inca gata cu pasii 
-primim aceasta eroare pt ca bucketu nostru nu este accesibil public deocamdata 
-am creeat bucketu si by default, nu este accesibila public 
-putem sa verificam asta si daca mergem la Permissions vom vedea informatii aditionale despre bucketu nostru si mai vedem Block public access care este On, deci pt acest bucket tot accesu public este blocat 
-sa schimbam asta, dam pe Edit pt ca vrem sa dam allow la public access, pt ca vrem sa trimitem adresa la alti oameni sa il acceseze 
-dam Save changes si scriem confirm acolo pt ca e o schimbare majora si daca asta ar fi un bucket oarecare in care avem niste secret files, ar face file-urile accesibile pt alti oameni, aws vrea sa se asigure ca intelegem perfect ce inseamna asta, ne si zice ca niste obiecte ar putea deveni publice, suntem siguri ca vrem sa facem asta? si scriem confirm si dam Confirm 
-acuma accesu public nu mai este blocat, dar daca mergem iar pe pagina si dam refresh o sa avem aceeasi eroare pt ca nu avem un Access policy pt obiectu din bucket, adica pt file-urile care sunt in bucket  
-trei sa stabilim un access policy pt obiectele din bucket, adica pt file-urile care sunt in bucket si deocamdata nu avem niciun policy la Bucket policy 
-dam pe Edit si acest Policy este scris in json ca si configuratie si din fericire nu trei sa incepem de la 0, AWS o sa ne ajute unpic 
-prima oara dam pe New statement si ne da deja o mica structura si vom incepe cu un serviciu. Cautam s3 si il alegem din lista si apoi in termeni de actiune pe care o cautam, se numeste GetObject pt ca atunci cand incercam sa citim ceva dintr-un bucket, incercam defapt sa dam get la un obiect si de aia se numeste GetObject, care e din Access level - read, deci o sa oferim doar un nivel de access de read 
-dupa ce bifam GetObject o sa vedem ca aceasta actiune este acuma adaugata in acest policy  
-mai avem chestii de schimbat, mai avem aici "Principal", ce este exact Principal? Asta specifica useru, conturile, survey-urile, in general, entitatea care este allow sau denied ca si acces 
-in cazu nostru, noi dam Allow la acces pt ca asta scrie la Effect sub Principal 
-o sa inlocuim la Principal {} cu * si editoru o sa ne dea eroare pt ca am bagat un string(*) intr-un json deci trei sa folosim "" cand scriem un string asa: "Principal": "*", si nu ne mai da eroare 
-asta inseamna ca acest policy se aplica oricarui user, nu conteaza daca e un user public sau altcineva, oricine are acces 
-mai avem si partea de Resource si putem sa o adaugam in dreapta la final, dar inainte copiem numele bucket-ului de sus pt ca vom avea nevoie de acesta 
-dam pe Add resource, Service este S3 si Resource type este object si la Resource ARN vedem BucketName si ObjectName
-selectam tot {BucketName} , care e doar un place holder si dam paste in locu lui la numele bucket-ului si pe {ObjectName} il inlocuim cu un * , care inseamna orice obiect. Deci nu vrem sa specificam un anume obiect, vrem sa specificam toate obiectele de asta folosim aceasta configuratie si acuma dam Add resource 
-acuma suntem gata cu acest policy si dam Save changes si aceast policy este acuma aplicat, este aici la Permissions si il putem vedea   
-acest policy da allow la orice user, pt ca Principal este *, sa perfermeze actiunea GetObject pe aceast Resource, bucketu nostru si zicem ca asta se aplica pe toate obiectele din bucket si asta face contentu din bucket accesibil public 
-vedem ca nu avem nici macar https la site


Syncing files to S3 

-dupa ce punem comenzile - echo "<h1>Hello S3!</h1>" > index.html  si - aws s3 cp index.html s3://$AWS_S3_BUCKET/index.html 
-dam add variable cu keyul AWS_S3_BUCKET si cu valueu numele bucketului si debifam cele doo si il lasam visible ca nu i ceva secret 
-am reusit sa dam upload la un fisier cu succes pe s3, dar ca si parte din jobu de build ne facem un intreg folder cu files si sa lucram cu un folder nu e asa usor pe cat pare 
-folderu build are mai multe files si nu putem sa mergem fisier cu fisier si sa le uploadam pe fiecare
-si daca dam deploy de mai multe ori, pot fi niste fisiere vechi pe bucketu s3 de care nu mai avem nevoie, deci asta inseamna ca ar trebui sa stergem mai intai tot de pe bucket si abea dupa sa dam upload la files 
-S3 ofera o cale mai smart sa facem asta numit sync . Mergem in documentatia s3 si jos la comenzi avem sync la care zice ca da sync la file-uri si foldere 
-la Examples avem unu care da sync la toate local objects pe un bucket anume si cam asta cautam 
-o sa copiem comanda: aws s3 sync . s3://AWS_S3_BUCKET 
-si o sa o bagam in cofiguratioa noastra 
-stergem comanda in care faceam un index.html file la misto - echo "<h1>Hello S3!</h1>" > index.html 
-schimbam stageu din .pre in deploy_review ca sa o executam dupa ce s-a terminat jobu build_website ca sa avem acces la artifactu lui, folderu build
-deci noi copiem ceva local(aws s3 sync .) intr-un bucket s3 si stergem si comanda in care copiam index.html pe s3 
-vrem sa dam sync la folderu build pe care il avem local, dar avem in comanda noastra de sync doar un punct . 
-daca il lasam asa, acesta este o referinta la folderu curent unde este comanda asta executata. Folderu curent o sa aiba toate file-urile pe care le vedem in proiect plus tot ce este adaugat in timpul executiei, deci in cazu asta o sa avem aici si build directory. Dar noi vrem sa uploadam doar folderu build, deci ce o sa facem in cazu acela este relativ simplu:
-putem pastra punctul si sa-i adaugam folderu build pe care vrem sa l uploadam pe s3: - aws s3 sync ./build/ s3://... 
-deci acuma continuturile folderului build vor fi uploadate pe bucketu s3
-dam commit, vedem ca executia a fost succseful sa ne uitam sa vedem exact ce s-a intamplat pe jobu aws_s3 
-si aici vedem comanda sync in actiune care ne zice exact ce uploadeaza si mergem si pe bucket si vedem ca s-au uploadat aceste chestii aicia intr-adevar si putem sa intram pe linku galetii s3 si vedem siteu nostru up and running 

-in acest section am invatat niste concepte funtamentale AWS si acuma avem un pipeline simplu care da build si deploy la siteu nostru pe aws cloud 
-la inceput am ignorat celelalte stage-uri si job-uri, care pot fi adaugate, dar focusu nostru, cum am vazut, a fost pe jobu aws_s3 pt ca incercam sa intelegem cum sa interactionam cu AWS 
-in acest proces am acoperit doua servicii importante: S3 ca un file storage system(un serviciu fundamental AWS) si IAM , serviciul pe care l-am folosit sa controlam accesu la resursele AWS si in acest proces am configurat S3 sa functioneze ca un server web pt usecaseu asta sa dea display la un websiteu nostru static 
-pt usecase-uri simple acest setup este destul de eficient si daca vrem sa folosim asta pt propriul nostru proiect putem sa luam un domain name pe care sa-l linkam la s3 bucket, dar in general, s3 buckets nu sunt chiar designed sa fie folosite ca si static web hosting, merge dar noi am facut doar un exemplu sa ilustram aceste principii si sa intelegem cum sa folosim s3 
-in proces am invatat si de AWS CLI care e un tool asa de puternic, deci sa ne luam unpic de timp si sa mergem peste Command Reference ca sa intelegem cum sa folosim cum trebe AWS CLI, care sunt optiunile disponibile si lucrand cu exemple, putem incepe cu exemple mai simple si sa intelegem apoi cum sa facem chestii mai avansate   

Deploying over SSH to a remote server 

Amazon Elastic Compute Cloud(EC2)

-ec2 este ca un computer virtual pe care il putem inchiria in cloud, e un serviciu care face sa fie usor pt devi sau devops engineers sa aiba si sa faca setup la computing poweru de care au nevoie pt orice aplicatii care trebuiesc rulate 
-multe alte servicii aws folosesc ec2 ca o baza, e ca fundatia unei cladiri care suporta multe alte servicii aws, deci sa intelegem ce e ec2 la un nivel basic macar ne poate ajuta sa intelegem mai bine cum functioneaza serviciile aws impreuna 
-chiar daca nu vom folosi direct ec2 e important sa stim cateva chestii despre el 
-pe dashboardu ec2 avem butonu Launch instance care ne va ajuta sa pornim instance, vedem ca acuma nu ruleaza nicio instanta 
-dam pe launch instance caruia ii dam un nume MyServer si mai jos vedem mai multe sisteme de operare pe care le folosim, de obicei folosim amazon linux sau ubuntu, dar fiecare usecase poate fi unpic diferit 
-selectam ubuntu si urm pas e sa selectam amazon machine image pe care vrem sa o folosim
-ubuntu va avea diferite versiuni de ex ubuntu server 24.04 care o sa se schimbe in timp, dar nu prea conteaza ca ubuntu tinde sa lucreze la fel pe o perioada mai lunga de timp 
-o selectam pe cea 24.04 care este free tier eligible adica putem folosi imaginea asta moca si e super important ca sa nu ne arda astia 
-mai important ca imaginea este tipul instantei care dicteaza cat de puterinca o sa fie acest virtual machine si vedem ca avem 750 de ore de t2 sau t3 micro, deci ne asiguram ca alegem un isntance type care este in acest free tier 
-ne si zice la instance type ca t3 e free tier de ex 
-pe lista avem mai multe imagini si vedem si costurile lor 
-t2 micro e suficient pt ce vrem sa facem, key pairu este esential calea prin care ne conectam la aceste vm-uri 
-pt exemplu asta o sa mergem fara key pair ceea ce nu va da allow la conexiuni remote, dar tot vom putea sa ne conectam din aceasta interfata amazon la instanta, dar daca vrem sa ne conectam de pe computeru nostru, trei sa creeam un key pair si sa o folosim 
-mergem cu defaulturile mai departe, volumu va avea 8gb ceea ce e suficient pt ce avem noi nevoie si dam Launch instance 
-si amazon va porni in state vmu nostru cu imaginea de amazon pe care am specificat-o
-mergem pe Instances si vedem o lista cu toate vm-urile pe care le avem, in cazu nostru pe cea MyServer, dar daca creeam mai multe, o sa avem o lista cu mai multe machine uri 
-cand lucram cu aceste machine-uri le identificam cu Instance ID, care este idu intern pe care l-a asignat amazon
-vedem ca instance state o sa devina Running care inseamna ca machineu a fost creeat si e running
-mai avem aici si Status check unde vedem ca are 2/2 checks care au trecut
-acest vm e running dar nu face nimic, pt ca nu i-am zis sa faca nimic. Ubuntu linux a pornit si sta idle, nu face nimic
-dam pe instance id si vedem mai multe chestii 
-aceasta interfata nu are o interfata grafica pe care o putem vedea, putem interactiona cu ea doar prin comenzi, vedem ca sus avem butonu de connect pe care il vom folosi care ne va lasa sa ne conectam la aceasta instanta
-dam Connect si vom folosi EC2 Instance Connect si ne da deja useru pe care sa il folosim si care by default este ubuntu, dam pe Connect 
-o sa ne deschida un tab nou in care o sa primim un terminal window  cu Welcome to ubuntu si system loadu 
-cel mai important lucru pe care il putem face aici este sa scriem comenzi: $ whoami o sa ne dea useru ubuntu 
-comanda $ pwd o sa ne dea pathu unde sunte, acuma /home/ubuntu , comanda echo "Hello Ubuntu" > hello.txt  , comanda asta o sa dea redirect la outputu Hello Ubuntu in hello.txt 
-cu comanda $ ls putem lista toate file-urile si folderele de unde suntem acuma(in home/ubuntu) si vedem heelo.txt 
-comanda cat hello.txt putem sa scriem doar cat h si sa apasam tab si asta va autocompleta numele fileului hello.txt in terminal ca sa nu scriem asa mult. Dam enter si o sa nea dea contentu din aceste file-uri 
-asa putem interactiona cu aceasta instanta pe care am creeat-o sa scriem comenzi in terminal sau ne putem conecta din alte parti la server si sa pornim programe sau servere sau aplicatii care sunt running si asa mai departe 
-instalam cmatrix: $ sudo apt update $ sudo apt install cmatrix $ cmatrix -s  , si dam enter ca sa rulam comanda si mai dam odata enter 
-ar trebui sa vedem multe caractere care tot pica pe ecran si ca sa dam exit apasam pe orice tasta dupa tastatura 
-ne intoarcem in amazon ui la instance, selectam instanta noastra si sus dreapta la instance state si dam Terminate instance care va sterge tot ce e legat de aceasta instanta si nu va mai exista si nu ne va mai genera costuri 
-mai putem da si Stop instance dar asta e ceva gen ca si cum am da shut down la calculator , adica insanta se va opri din lucrat, dar daca avem nevoie de ea mai tarziu, selectam instanta din lista si dam Start instance dar tot ne costa sa o avem asa gen 
-mai devreme aveam info deste un elastic ip care a fost folosit 
-acest ip public e folosit ca sa ne putem conecta la instanta de aws, deci practic inchiriem un ip de la aws care costa bani 
-mergem a Elastic IPs pe meniu din stanga sa ne asiguram ca nu avem niciun ip acolo  

Creating an Nginx web server 

-o sa creeam un nou server virtual si o sa-l configuram ca un webserver folosind nginx 
-scopu e sa dam deploy la siteu nostru simplu pe acest server si sa-l accesam printr-un browser sa il vedem in actiune 
-dam launch la o noua instanta ec2 cu numele My Web Server si folosim amazon linux si mergem cu amazon linux 2023 si t3.micro 
-in loc sa folosim o parola, vom folosi un ssh key sa ne conectam la acest server virtual, care e mult mai ok decat o parola deoarece e mult mai secure 
-o cheie ssh functioneaza ca un sistem de lacat si cheie. Serveru are public key-ul si noi tinem private keyu 
-spre deoserbire de parole, ssh keys sunt protejate de o criptografie foarte puternica ca sa nu poata fi usor furate sau ghicite. E un fel de standard de industrie sa folosim ssh keys sa ne autentificam pe un server virtual 
-vedem ca key pair e required, asa ca putem sa dam Create new key pair. Se numeste asa pt ca contine un private key si un public key ii punem numele GitLab si lasam RSA si .pem si dam Create key pair si ii dam download ca sa il avem pe pcu nostru si serveru virtual o sa aiba public keyu deja configurat 
-dupa ce am facut pasu asta foarte important 
-mergem la Network settings si dam Allow SSH traffic from Anywhere cum e si default, dupa care dam Allow la HTTPS traffic from the internet si Allow HTTP traffic from the internet, care sunt importante pt ca configuram un web server si e important ca aceste vm-uri au aceste port-uri deschise
-tre sa aiba si Auto-assign public IP enabled, daca e dsiabled dam pe edit si il dam pe enabled, care o sa se asigure ca atunci cand dam launch la acest vm o sa avem un ip public sa il accesam 
-restu setarilor is ok deci dam Launch instance si asteptam pana avem 2/2 la status check 
-urm pas e sa instalam serveru nginx pe acest machine si pt asta o sa trebuiasca sa rulam niste comenzi direct pe server 
-dam connect la instanta si vedem ca are si un public ipv4 adress si ne da si un username 
-acuma instalam nginx cu comanda: $ sudo dnf install -y nginx  , pt asta folosim package manageru numit dnf care e un package manager modern pt linux distributions ca si Amazon Linux, Fedora sau cenots
-e un succesor al vechiului YUM package manager
-cu acest dnf package manager rulam comanda de install si ii zicem ca vrem sa instalam nginx, sudo se asigura ca comanda e rulata cu un super user root, ceea ce e necesar pt a instala system packages si mai avem flagu -y care se asigura ca toate intrebarile puse in timpu instalarii sunt raspunse cu yes ca sa nu intrerupem procesu de instalare 
-dam enter si se instaleaza imediat, dar doar pt ca a fost instalat nu inseamna ca e si acutally running 
-ca sa pornim serviciul nginx, tre sa dam urm comanda: $ sudo systemctl start nginx 
-acuma doar pt ca a fost pornit, urm data cand o sa dam restart la server, acest serviciu nu va fi pornit, deci web serveru nostru nu o sa mearga 
-nu e absolut necesar sa facem asta, dar urm comanda va configura nginx ca un serviciu si va fi pornit automat cand booteaza sistemu 
-acuma ca am facut toti pasii, urmatoarea comanda doar va confirma ca nginx este running properly: $ sudo systemctl status nginx  , vrem sa vedem ca e scris cu verde active(running), asta indica ca nginx merge
-acum ca am configurat un webserver sa il vedem in actiune 
-mergem inapoi pe amazon dam pe idu instantei si asta ne va da niste informatii aditionale, printre care si Public IP address si daca dam pe el ar trebui sa vedem siteu, dar browseru nostru baga https by default care e o cale securizata de a ne conecta la server folosind acest protocol securizat, care nu este configurat deocamdata deci de aceea conexiunea da fail, stergem s ul din https si dam enter si vedem ca ne baga pe siteu default a lu nginx: Welcome to nginx! ... 
-mai avem o varianta sa ne conectam cu Public IPv4 DNS care a fost generata de amazon de asemenea si o sa avem aceeasi eroare pt ca folosim https si stergem s-u si e ok 
-deci putem folosi adresa asta dns care mai arata a link normal web sau putem folosi direct ipu si asta ne va conecta la serveru nostru si Welcome to nginx care ne garanteaza ca nginx a fost instalat si merge cum trebe

Testing the connection with netcat(nc)

-inainte sa automatizam orice, e important sa ne asiguram prima data ca conexiunea la server poate fi facuta si ideal ar trebui sa incepem local pe computeru nostru folosind terminalu 
-si pt asta o sa folosim un ulility command line numit netcat si poate fi apelat folosind comanda nc , daca nu o avem instalata o instalam 
-netcat este un tool cli pe care il folosim sa interactionam cu network socket si de obicei o combinatie intre o adresa ip si un port care e considerat un socket, deci poate stabili o conexiune la un server si il folosim de obicei pt port scanning sa intelegem ce port-uri sunt deschise pe un server specific sau pt scopuri de troubleshooting    
-in cazu asta vrem sa verificam ca portu 22 pe serveru nostru este accesibil 
-folosim comanda netcat numita simplu nc in care o sa punem doua flag-uri, printre care flagu -z , care inseamna zero input/optput, adica netcat nu va da send sau recieve la orice data, ci doar verifica daca portu e deschis 
-asta e cea mai rapida cale de a verifica daca un port e deschis urmatoarea optiune dupa -z este v (-zv), care ne va da output detaliat si ne va zice daca conexiunea a fost de succes sau daca a dat fail 
-acuma ne mai trebe o adresa ip pe care vrem sa verificam conexiunea(ip-u ec2-ului), pe care il obtinem dupa ce dam click pe instance id de la Public IPv4 address, caruia ii dam copy paste in comanda noastra dupa care punem un spatiu si 22 , care este portu. Dam enter sa rulam comanda si cand portu e deschis, aceasta conexiune ar trebui sa dea succeed instant si asta e o indicatie ca totu merge bine 

$ nc -zv 13.53.192.99 22 

$ PS H:\> Test-NetConnection -ComputerName 13.53.192.99 -Port 22     //bagam asta ca e mai lejer decat netshit ala                                                                                                                                                                                                                                                       

-sa vedem si ce se intampla cand o conexiune nu este de succes 
-mergem la tabu Security si vedem ca avem un Security group asignat acestei instante ec2, dam click pe el si aici vedem Inbound rules si Outbound rules
-dam edit la Inbound rules si vedem ca acceptam conexiuni SSH de oriunde si stergem acest rule, cu portu 22 si dam Save 
-si daca incercam din terminal comanda de mai devreme din nou, vedem ca nu se intampla nimic, deci o sa dureze un minut ca nc sa vina inapoi si sa ne zica ca a incercat asta, am un timeout configurat, am incercat asta pt 30 de secunde sau 1 min si nu am reusit sa dau establish la o conexiune
-dar daca rulam comanda si vedem ca nu se intampla nimic atunci stim ca acel port nu este deschis sau cel putin din acel machine, nu putem accesa acel server particular si ar trebui sa dam troubleshoot sa vedem de ce nu putem 
-daca asteptam o sa zica Operation timed out deci conexiunea nu a putut fi realizata, daca nu vrem sa stam asa mult, dam ctrl c si iesim care va trimite un semnal de intrerupere
-daca dam comanda asta si dupa 2 3 secunde nu vine inapoi nimic, portu nu e deschis 
-mergem inapoi in aws la sec gropus si dam edit la inbound rules, dam Add rule si din lista algem SSH si ca source punem Anywhere si dam Save rules, executam iar comanda si vedem ca merge cum trebe si daca avem asta mergem mai departe cu eforturile de automatizare 

Testing the SSH connection from GitLab

-urm pas e sa ne asiguram ca GitLab runner se poate conecta la instanta de ec2 cand ruleaza un job si pt asta folosim comanda netcat iarasi 
-mergem in configu pipeline-ului si adaugam un nou job care e responsabil pt deployment numit ssh_deploy pe care il bagam in .pre stage ca sa fie rulat primu deoarece nu depinde deocamdata de build_website job 
-folosim imaginea alpine deocamdata, daca avem nevoie de altceva vedem mai incolo dar incepem cu ceva mai mic acu si in script, avem nevoie doar de comanda netcat si o sa documentam pasii mai bine sa ii intelegem 
-verificam daca portu 22 e deschis pe server, deci comanda netcat o sa fie folosita cu cede doua flag-uri -zv 
-acuma mai avem nevoie de port name sau host name pe care le gasim pe ambele in aws pe isntnta noastra la Public IPv4 adress sau Public IPv4 DNS 
-in fine, pe scurt folosim comanda de mai sus aici in linia de comanda si gata si putem sa folosim si cu host name dns:

- nc -zv 13.53.192.99 22 
- nc -zv ec2-13-53-192-99.eu-north-1.compute.amazonaws.com 22 

-dam commit si facem un branch si merge request: feature/gitlab-ssh-aws si vedem ca merg ambele comenzi si conexiunea e successful 
-nu avem nev de ambele comenzi, folosim ce e available pt situatia noastra(ip u ar trebui sa fie sigur mereu ca orice host are un ip gen) asa ca ramanem decat cu cea cu ipu o stergem decat pe cealalta 
-de obicei nu vrem sa avem adrese ip in configu pipelineului deci ar trebui sa bagam acest ip intr-un environment variable 
-mergem la Settings CI/CD la variables si dam Add variable, cum nu e nimic secret la adresa ip si debifam cele doo mizerii 
-folosim la key numele REMOTE_DEPLOY_HOST si la value bagam ec2-13-53-192-99.eu-north-1.compute.amazonaws.com public ipv4 dns care l luam dupa aws si dam Add variable 
-acuma mergem in pipeline si in loc de ipu ala bagam $REMOTE_DEPLOY_HOST , pe care o putem pune si intre "" , deci daca primim erori ciudate e mai safe sa punem variabila intre ""
-am putea pune si portu 22 intr-un env var de asemenea, dar ca sa nu comoplicam prea mult lucrurile o sa mentinem lucrurile simple, dam commit si vedem care i cioaca si vedem ca e bines 
-comanda asta este o verificare foarte importanta chiar de la inceputu deployment-ului pt ca daca nu merge conexiunea pe acest port ar trebui sa stim de indata, sa isi ia fail acest job ca mai tarziu sau cand rulam alte comenzi sa stim ca problema e defapt ca portu nu e deschis si nu altceva ca o problema de autentificare sau ceva de genu   

Storing the SSH private key in GitLab 

-cand am creeat isntanta ec2, am generat si un Key pair, pe care o sa il bagam in GitLab 
-intram pe key in vs code si selectam tot contentu care e disponibil aici si apoi sa mergem in GitLab la CI/CD si dam add variable 
-dam paste la ce am copiat in Value. Sus la Type in loc de Variable(default) o sa selectam File, care e un tip de gitlab variable in care se afla Value-ul pe care l am dat mai jos intr-un file temporar in timpul executarii pipeline-ului 
-deci in loc sa avem o variabila care contine Value-ul, o sa avem o variabila care contine un path catre un file 
-la key punem SSH_PRIVATE_KEY 
-sunt cateva lucruri importante la care trei sa fim atenti 
-daca mergem la Visibility si dam oe Masked o sa ne dea eroare pt ca contine cv caractere care nu i place de ele 
-si de asemenea butonu Add variable e disabled si nu va merge nici Masked and hidden 
-deocamdata in GitLab nu e posibil sa protejam acest private key prin masking sau hiding 
-o sa o tinem deci pe Visible si nu debifam protect si expand si ii dam add variable 
-ne intoarcem in pipeline si mai intai dam prind la valoarea variabilei sa vedem ce i acolo si asta va fi un path catre un file si apoi folosim comanda cat sa vedem contentu acelui file, dam commit si ne uitam pe log 
-vedem in job ca comanda echo ne a dat un path la un file, locatia unui file si de aceea cu comanda cat careia ii dam pathu o sa avem valoarea private key-ului printata in log 
-deci teoretic oricine care poate scrie configuratia pipeline-ului poate sa si fure cheia privata care e disponibila acolo 
-deci asa functioneaza in GitLab un file variable si o sa o folosim asa pt ca key-urile private sunt bagate in file-uri si o sa ne faca pasii urmatori unpic mai usori 
-intorcandu-ne la pipeline configuration mai sunt cateva lucruri pe care trei sa le facem cu acest private key si unu din ele este sa ii vedem permisiunile si sa ne asiguram ca are permisiuni read only 
-ii verificam permisiunile cu comanda - ls -l $SSH_PRIVATE_KEY 
-dar vrem sa folosim change mode sa ii oferim permisiuni read only owner-ului cu comanda: - chmod 400 $SSH_PRIVATE_KEY 
-400 inseamna read-only permission si specificam file nameu 
-ssh private keys ar trebui sa fie readable doar de catre owner sa prevenim accesu neautorizat 
-si daca permisiunile astea sunt de open, clienu ssh o sa dea reject probabil la key cand incercam sa o folosim 
-deci schimbam permisiunile file-ului si dupa dam iar comanda cu ls -l sa verificam daca permisiunile astea au fost schimbate cu adevarat 
-adaugam multe comenzi de trouble shoot dar ca sa intelegem ce se intampla si sa vedem diferenta in log, dar nu sunt strict necesare 
-singura comanda care e cu adevarat necesara este cea de chmod. Dam commit si ne uitam pe log 
-vedem ca prima comanda de ls ne va zice ca acest file are permisiuni read write pt mai multe group-uri de useri cred 
-deci nu e ok cum e configurata, deci de aceea vom folosi comanda chmod sa schimbam permisiunile sa fie doar read permission, cum vedem in a doua comanda unde este doar read doar pentru owneru file-ului 
-deci de asta avem nevoie neaparata de comanda chmod si am vazut ca initial nu erau configurate ok permisiunile 
-putem sa adaugam un comment sa intelegem exact ce face aceasta comanda 
-stergem restu de comenzi cu ls cat si echo 
-putem sa punem $SSH_PRIVATE_KEY intre "" pt ca in cazu in care un file contine spatii sau alte caractere care ar putea duce la probleme, dar in cazu asta numele variabilei si cum e creeata nu are asa ceva, deci prefer sa nu folosesc "" daca nu sunt strict necesare, dar am putea vedea config-uri unde aceste "" sunt adaugate doar sa se asigure ca e corect pathu 

Configuring the SSH connection

-in serveru asta o sa dam establish o conexiune ssh cu serveru nostru, dar inainte de asta mai sunt cativa pasi pe care trei sa-i facem
-prima oara trei sa instalam OpenSSH pt ca imaginea apline nu are asa SSH 
-asta trebuia sa se intample folosind comanda: - apk add openssh-client 
-avem nevoie sa deschidem clientu ssh sa ne conectam in mod securizat la serveru remote ca si cel pe care il folosim, folosind ssh 
-daca nu avem clientu openssh nu putem folosi ssh
-partea urm o sa fie mai tricky. In primu rand trei sa rulam agentu ssh care o sa se intample intr-o comanda separata. Agentu ssh are aceasta utilitate numita ssh-agent 
-acest agent este un proces de backround care menegiuieste key-urile ssh pt authentificare si o sa avem nevoie de acest agent ssh sa ne adauge key-ul ca sa nu o specificam in fiecare comanda pe care o rulam 
-cand comanda asta este executata, cand agentu de ssh e pornit, da output in consola la niste environment variables care permit altor procese sa interactioneze cu el, dar asta nu va merge by default. Trebuie sa punem comanda astra intr-un soft shell $(<comanda>) si inainte de asta folosim comanda eval sa seteze aceste env vars in sesiunea curenta shell:
- eval $(ssh-agent) 
-acuma sa adaugam ssh keyu nostru in agentu nostru cu comanda ssh-add urmata de pathu catre key pe care il avem deja bagat in variabila noastra de tip file $SSH_PRIVATE_KEY:
- ssh-add $SSH_PRIVATE_KEY
-indata ce am adaugat acest key, tool-uri ca ssh sau sep pot folosi acest key automat pt autentificare 
-astia sunt pasi de setup inainte sa putem face orice si acuma vine partea in care ne conectam defapt la server si vom folosi ssh si tre sa specificam mai intai usernameu, adica ec2-user, urmat de @ , urmat de adresa, care e bagata in variabila $REMOTE_DEPLOY_HOST(pe care o putem folosi in loc sa punem aici ipu public):
- ssh ec2-user@$REMOTE_DEPLOY_HOST 
-asta e primu pas pe care ar trebui sa il verificam sa vedem daca putem stabili o conexiune SSH pe acest server remote 
-tot o sa primim o eroare, dar sa dam commit la schimbari si sa vedem daca merge ce am tot facut 
-pe log prima comanda pe care am adaugat-o este cea care instaleaza clientu SSH si care a mers fara probleme(apk add opensshh ...)
-apoi am pornit clientu ssh care a primit un process id de 21 deci asta arata bine(comanda eval), apoi ne am adaugat private keyu nostru(ssh-add $SSH...) 
-dar apoi ultima comanda de ssh a avut o problema pt ca primim eroare host key verification failed, care poate arata la fel in mai multe variatii dar ideea principala este ca: 
-aceasta eroare inseamna ca clientu ssh nu a recunoscut serveru la care dorim sa ne conectam si din cauza setarilor stricte de securitate, refuza sa purceada  
-ideea din spate este ca fiecare server are ca un fingerprint si vrem sa ne asiguram ca ne conectam la serveru corect si ca nu este cineva intre care ne poate intercepta conexiunea si sa se dea drept serveru nostru ca sa trimitem datele prin altcineva. Tehnic vorbind, asta se numeste a man in the middle attack. Totu e despre securitate 
-deci, by default, ssh va verifica daca stie acest remote host la care incearca sa se conecteze? nu, nu stiu, deci nu o sa ma conectez la el pt ca nu il stiu 
-putem sa facem bypass la asta cu o setare la care o sa o adresam mai incolo 
-in configuratia noastra, o sa specificam un flag, o optiune aditionala: -o StrictHostKeyChecking=no 
-cand acest flag este setat pe no, clientu ssh va adauga automat host keys intr-un file numit KnownHosts si va accepta conexiuni catre orice host, chiar daca semnaturile acelor servere sunt schimbate 
-deci, facem bypass la o masura de securitate care ar trebui sa fie in-place, si desigur, oricand facem bypass la ceva, trei sa intelegem exact ce facem, sa dam commit si sa vedem daca conexiunea e de succes asa 
-daca ne uitam acuma la log-uri, comanda de incercare de a ne conecta la server este acuma successful 
-primim un warning in comanda de ssh care zice ca aceasta adresa anume(ec2-13-53-192-99.eu-north-1.compute....) pe care am folosit-o la conectare a fost adaugata permanent in known host list in mod permanent, dar nimic nu e permanent in modu in care rulam aceste job-uri deci asta va aparea mereu 
-dar cand vedem aici amazon linux 2023 inseamna ca conexiunea la acest remote server folosind ssh si acest private key a fost successful si asta voiam sa facem, chiar daca am facut bypass la un security measure pe care o vom rezolva foarte curand 
-sa ne intoarcem la job si sa-l parcurgem pas cu pas sa ne asiguram ca intelegem exact ce s-a intamplat aici 
-deci in primu rand imaginea alpine nu are inclus un client ssh, apoi trei sa pornim agentu ssh ca sa puntem in pasu urmator sa adaugam SSH_PRIVATE_KEY-ul nostru in acest agent, ca acesta sa stie de ea si apoi cand rulam comanda ssh acest private key este deja disponibila ca sa nu trebuiasca sa o specificam inca odata cu optiunea -i private_key 
-avem usernameu instantei de linux ec2 in comanda ssh(ec2-user) pe care ar trebui sa il inlocuim cu  un environment variable(pe care o definim in settings -> ci/cd) numita $REMOTE_DEPLOY_USER si astfel nu avem username sau alte configuratii hardcodate 
-DECI putem baga si ec-user intr un environment variable numit REMOTE_DEPLOY_USER ca sa nu-l mai avem hardcodat in pipeline, stim ca asta e useru din aws ec2 
-dupa cum am vazut, sunt cativa pasi care trei facuti inainte sa rulam comanda ssh si sa interactionam cu serverul 
-si asta trei sa facem mereu cand incercam sa rulam o comanda ssh dintr-un job. Sa zicem ca de ex avem mai multe job-uri care sunt deploying sau care interactioneaza cu un server remote, trebuie sa bagam acesti pasi de dinaintea comenzii ssh in fiecare job 
-daca avem nevoie de ssh in diferite job-uri, fiecare job trei sa inceapa de la 0 si sa faca toti pasii pe care i am facut noi aici in jobu ssh_deploy inainte de comanda de conexiune ssh 
-e unpic de munca da acu intelegem exact ce se intampla in fiecare pas si acesta este cel mai important aspect 

Verifing the SSH host keys 

-acuma o sa scapam de warningu permanently added ec2... to the list of known hosts si sa configuram conexiunea ssh sa fie mult mai securizata pt ca va verifica host keys 
-ca sa facem asta, mergem inapoi pe aws si dam connect la instanta noastra si acuma vom lua gen finger printu serverului
-si ca sa facem asta, folosim o comanda numita ssh-keyscan urmat de public ipv4 adress al instantei sau host nameu:
$ ssh-keyscan 13.53.192.99
-si vedem ca primim niste semnaturi criptografice care ne pot ajuta sa verificam daca serveru e chiar cine pretinde sa fie 
-trei sa bagam aceste semnaturi(signatures) intr-o variabila in GitLab ca mai tarziu sa putem creea un file care va recunoaste aceste semnaturi cand facem o conexiune ssh, suna unpic complicat dar defapt e mai usor decat credem 
-mergem in GitLab Settings CI/CD Add variabile si va fi din nou o variabila de tip File pt ca vom creea un known host file de la 0 
-ramane pe Visible, debifam alea doo porcarii si la key bagam SSH_KNOWN_HOSTS(o putem numi cum vrem) si acuma mergem inapoi pe terminalu de la instanta ec2 si copiem linia care are hasu mai lung si care inainte de el are ecdsa-sha2-nistp256, de ex: 
13.53.192.99 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBFDU4tlEuSl0DpnlbP+siWdHYJaMUOHKsNO2rOrGfhit1cABIkwJJjD7TdoBpwDbK7hSEvlIQVN0Np11aX/Odrs= 
-o copiem si ii dam paste la Value, dam enter dupa si copiem si a doua linie cu ssh-ed25519 inainte de hash:
13.53.192.99 ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIPnh1P0U8mLTv0kghjc1WSDE+7Gx0d8pzoyFxjvWp9xZ
-vedem ca aceste doua linii nu is comentate, adica nu au # la inceput si incep cu ipu ec2-ului, de aceea le copiem doar pe ele si dam Add variable 
-si acuma aceasta variabila a fost creeata, mergem in configu nostru in vs code unde trei sa adaugam inca cateva comenzi 
-avem doua cestii de facut, sa creeam un folder ssh si sa asignam niste permisiuni pt ca in acel folder ssh o sa punem acest known host file. Trei sa creeam un known host file si apoi o sa asignam permisiunea corecta acestui file, altfel ssh se va plange de ea 
-sa incepem prin creerea file-ului known_hosts si sa-i asignam permisiunile corespunzatoare, deasupra la ultima comanda cea cu ssh -o, bagam comanda de creere a file-ului:
- cp $SSH_KNOWN_HOSTS ~/.ssh/known_hosts 
-cu asta o sa copiem fileu al carui path este stored in env varu $SSH_KNOWN_HOSTS in folderu ssh. Acem ~ la inceput, asta e o referinta la home directory-ul al userului curent si ssh e folderu tipic unde ssh stores information si o sa creem de la 0 known host file care nu exista 
-si o sa i asignam permisiunile corecte acestui known host file, ceea ce este de asemenea important pt ssh:
- chmod 644 ~/.ssh/known_hosts 
-acuma inainte sa putem copia file-uri in folderu ssh, trei sa l creeam pt ca nu exista 
-deci inainte de comanda de copy(cp $SSH_KNOWN_HOSTS ..) trei sa creeam folderu ssh, daca deja exita e ok, de aceea folosim optiunea -f ca sa nu primim warning sau eroare daca exista deja, dar nu exista, si apoi ii asignam permisiunile corecte folderului acesta de asemenea:
- mkdir -p ~/.ssh 
- chmod 700 ~/.ssh  
-si acuma cu ce avem aici putem sa mergem sa stergem optiunea -o StrictHostKeyChecking=no din comanda ssh si asta ne va lasa sa avem o conexiune securizata cu ssh la serveru ec2 pe care il recunoastem pt ca, super important, am executat comanda ssh-keyscan pe ec2 direct. Sa NU executam comanda asta in GitLab Runner, pt ca daca e cineva intre gitlab si ec2 deja o sa trimita propriile lui semnaturi si nu semnatura de pe server, de aceea e probabil important de mentionat ca comanda asta trei sa fie executata pe ec2 direct  
-acu chiar daca am facut totu ok, e o sansa sa primim eroarea Host key verification failed. 
-e un aspect important de care trei sa tinem cont, cand am deschis conexiunea ssh, nu am folosit ipu, ci am folosit host name si din aceasta perspectiva de configurari, lucrurile sunt unpic diferite
-daca ne uitam pe ec2 la semnaturile pe care le-am preluat, vedem prima oara un ip si apoi semnatura si pt a doua semnatura iar avem ipu si apoi si semnatura 
-dar pt ca in aceste file-uri sunt doar adrese ip, cand rulam comanda ssh, nu o sa se potriveasca pt ca o adresa ip si un host name, chiar daca pointeaza la aceeasi instanta ec2, dintr-o perspectiva de configurari, nu sunt acelasi lucru. Putem ori sa rulam iar comanda ssh-keyscan pe ec2 cu host name dns in loc de ip si sa modificam env var file $SSH_KNOWN_HOSTS sau sa bagam ipu intr-un env var si sa il folosim practic in comanda de ssh 
-in tutorial o sa ne zica sa rulam iar comanda ssh-keyscan pe ec2 dar de data asta nu cu ipu, ci cu host nameu instantei respective:
$ ssh-keyscan ec2-13-53-192-99.eu-north-1.compute.amazonaws.com
-si o sa primim aceeasi semnatura ca inainte, dar acuma avem host name inainte de hashu signature-ului si asta ar putea fi de ce nu merge conexiunea 
-o sa fim foarte atenti cand dam copy la cele doua linii fara # la inceput si mergem la variables si ii dam edit la $SSH_KNOWN_HOSTS, dam enter sub ce este deja si bagam cele doua linii noi 
-salvam schimbarile, dam commit si vedem ce se intampla(trei sa dam commit si prima oara dupa ce am pus comenziile da dadea fail asa ca mai ljr acuma direct)
-putem baga si ec-user intr un environment variable numit REMOTE_DEPLOY_USER ca sa nu-l mai avem hardcodat in pipeline, stim ca asta e useru din aws ec2 
-in fine, vedem ca ruleaza pipelineu si e totu ok si nu ne mai da nici warningu ala cu known hosts 

Running commands over SSH

-acuma ca am dat establish la o conexiune, putem rula comenzi pe acest server remote(ec2) 
-putem muta totu in before_script, inafara de comanda ssh pt ca asta e doar set-up-ul ca sa putem face conexiunea ssh si acuma putem rula comenzi 
-efectiv punem un spatiu dupa comanda ssh si intre "" putem pune comanda "whoami" care ne va returna usernameu 
-putem sa dam commit si ne uitam pe log si vedem ca ne returneaza user ec2-user 
-e acelasi lucru ca si cum ne am conecta la instanta ec2 si am rula comanda whoami, dar diferenta este ca totu este facut de gitlab cand executam pipelineu 
-putem rula mai multe comenzi, punand ; intre dupa whoami dar sa fie tot intre "", de ex: "whoami; touch /tmp/foo.txt; ls -l /tmp" , aici creeam un file foo.txt in tmp dupa care listam tot ce e in folderu tmp -dam commit sa vedem cum sunt comenzile astea executate una dupa alta 
-si vedem outputu acestor comenzi dupa comanda de ssh, deci asa putem rula comenzi remote si securizat folosind ssh 

Uploading files using SCP 

-acuma invatam cum sa facem upload la un file pe un server remote si toolu pe care il vom folosi este SCP sau secure copy 
-deci, de obicei pe un sistem linux, daca incercam sa copiem ceva, folosim comanda cp, in cazu asta, pt ca vrem sa transferam securizat ceva remote, folosim toolu scp 
-de obicei, cand vrem sa copiem ceva, trei sa specificam originea si destinatia, sa zicem ca vrem sa transferam fileu numit bar.txt si vrem sa il punem undeva remote 
-unde remote? avem deja useru si hostu in comanda ssh, deci asta ar fi prima parte a path-ului remote, dar apoi trei sa specificam exact unde, deci dupa ce specificam useru so hostu, punem : si dupa alea, putem specifica un path, de ex /tmp 
-in folderu tmp deja am creeat un file foo.txt si acuma local, uploadam un file care e numit bar.txt, pe care tre sa il creeam unainte de comanda scp cu comanda touch bar.txt ca sa simulam ca este un local file care trei sa fie uploadat acolo 
-asa ca putem muta comanda ssh la sfarsit dupa cea de touch si scp, pt ca putem profita de comanda ls care afiseaza ce este in folderu tmp 
-deci asta ar trebui sa facem ca sa uploadam un file, il creeam si dupa in comanda scp ii zicem si unde sa o copiem(practic sa o uploadam)
-dam commit si ne uitam daca a mers cum ne asteptam si vedem ca executia a fost successful, comanda scp a mers ok dar nu ne zice ce a facut, dar pt ca avem comanda ls in comanda ssh, putem vedea ca bar.txt file a fost uploadata pe ec2 
-pt cazu nostru, am putea sa dam upload la toate file-urile care tin de site-u nostru de ex 
-toate aceste file-uri sunt stored la un path anume si trei sa stim aceste path-uri 
-copiem comanda de scp si o bagam dupa comanda ssh dar stergem comanda touch ca nu ne mai trebe a fost un exemplu
-si vom uploada tot folderu build: scp build/* $REMOTE... . Asterixu e foarte important pt ca specifica toate file-urile si folderele din folderu build, dar nu si folderu build insasi 
-deci vrem doar content-urile folderului build nu si folderu build, nu vrem sa il uploadam asa cum este 
-ca sa si mearga tre sa punem jobu in stageu deploy_review si ne mai trebe pathu: /usr/share/nginx/html/ . Acesta e pathu unde nginx pune by default toate file-urile HTML, pathu unde vedem pagina default de nginx, aia cu welcone to nginx 
-deci in acest path dam upload la continuturile folderului build. Comanda o punem dupa ssh si arata asa: 
  - scp build/* $REMOTE_DEPLOY_USER@$REMOTE_DEPLOY_HOST:/usr/share/nginx/html/
-dam commit si vedem daca merge da nu va mege si vedem ca comanda asta ne da erori legate de uploadu de file-uri, niste erori de Permission denied 
-putem investiga usor, stim ca folosim ec2-user, copiem pathu /usr/share/nginx/html/ si mergem in intanta ec2, dam comanda: $ ls -l /usr/share/nginx/html/ si aici vedem ca root este owneru file-ului, deci nu noi cu useru ec2-user si de aceea nu putem da upload la file-uri aici sau da overwrite la file-uri aici 
-deci va trebui sa rulam o comanda, ca useru ec2 sa devina owneru acestor file-uri si foldere care sunt aici(/usr/share/nginx/html/)
-folosim comanda chown, o facem recursiv cu flagu -R si ec2-user va fi si usernameu si group-ul si pathu. Comanda arata asa:
$ sudo chown -R ec2-user:ec2-user /usr/share/nginx/html/ 
-o executam pe instanta ec2 si dam print iar la file-uri cu ls -l si vedem ca acuma noi suntem ownerii acestor file-uri deci acuma mergem si dam restart la job sau ma rog commit ca sa porneasca jobu 
-si din pacate, tot primim o eroare aici: build/assets is not a refular file , care e un folder 
-chestia e ca cum am configurat comanda scp se refera doar la file-uri care sunt in folderu build, dar in folderu build, avem si alte subfoldere si comanda se uita la aceste subfoldere ca la niste file-uri si zice hei, asta nu e un file si asta e eroarea 
-trei sa i zicem lu scp sa mearga peste toate file-urile si subfolderele recursiv, deci trei sa i mai dam un flag -r dupa scp inainte de build/* ca sa mearga si cu subfolderele si file-urile care sunt in folderu build:
  - scp -r build/* $REMOTE_DEPLOY_USER@$REMOTE_DEPLOY_HOST:/usr/share/nginx/html/  
-dam commit la schimbari si ne uitam iara pe log 
-acuma folosind flagu -r nu mai primim erori si sa ne uitam sa vedem ca nu merge siteu pe dnsu nostru ca probabil foloseam https cand il accesam, am facut tot de la capat si merge pe http deci e ok 
-dupa cum putem vedea, daca ceva merge rau, scp ne da erorile, dar daca vrem sa verificam ce s-a intamplat cu scp nu este mereu asa de ideal, pt ca de ex in cazu asta, nu stim ce file-uri au fost uploadate sau daca au fost file-uri sterse, ce se intampla exact? sunt multe lucruri pe care scp nu le face by default 
-da de ex, ne conectam la server si ne uitam in folderu /usr/share/nginx/html/ si vrem sa vedem exact ce se afla acolo, o sa vedem chestii care stim ca nu sunt din folderu build, de ex  404.hhtml, 50x.html, nginx.logo 
-asta sunt chestii care nu vin din folderu nostru de build, deci pare ca am amestecat file-urile existente ci file-uri noi pe care le-am uploadat aici din folderu build, ceea ce nu e ideal 
-sigur ca am putea sa stergem mai intai folderu asta si continut-urile lui si apoi sa uploadam totu undeva unde nu e nimic 
-la unele aspecte, comanda scp nu e asa ideala, dar totusi este o comanda folositoare daca vrem sa copiem toate folderele si file-urile din folderu build, in acest caz, dar nu si folderu insasi la o destinatie remote 
-asa functioneaza, putem sa dam upload la content-urile unui folder sau doar la un singur file, deci avem multe posibilitati 

Uploading files using rsync 

-cu scp am reusit sa uploadam continutu folderului build la aceasta locatie remote, dar am vazut ca mai sunt niste file-uri aici, care sunt niste file-uri default de la instalarea lui nginx si de care nu avem nevoie, normal ca putem sterge continuturile folderului /usr/share/nginx/html/ de fiecare data cand incercam sa dam deploy si astfel sa uploadam toate file-urile intr-o locatie goala 
-dar asta ar fi un waste de timp si bandwidth, mai ales daca sizeu folderului este considerabil 
-folosirea comenzii scp sa uploadam un file este ok, dar daca chiar vrem sa facem o treaba profi sa mentimen folderu sincronizat 
-deci sa avem scinronizate folderu nostru build si acest folder remote de pe ec2, sa i zicem deploy directory(/usr/share/nginx/html/) ar trebui sa folosim rsync 
-rsync ne permite sa sincronizam doar file-urile care s au schimbat sau care sunt noi intre un folder local si unul remote si ne lasa si sa stergem file-uri pe care nu le mai avem local si prin local intelegem ce avem in folderu nostru build in timpul procesului de build, ca parte din pipelineu nostru ci/cd 
-deci asta se asigura ca folderu nostru build pe care l-am creeat in pipelineu ci/cd care exact acelasi continut cu acest folder remote pe care il folosim sa deservim content lumii, asta ne lasa sa stam linistiti ca nu avem nimic deployed care e outdated si nenecesar, dar poate oamenii il pot accesa cumva 
-rsync e usor de folosit si are multe chestii in comun cu scp, de ex modu in care copiem chestii e cam la fel 
-nu mai avem nevoie de * de la build/* , dar tot avem nevoie de flacu -r 
-mai intai inlocum scp cu rsync, care e un tool care nu vine instalat in alpine, deci mergem la before script in comanda apk add si adaugam si rsync de asemenea 
-deci cu rsync folosim folderu build sa uploadam catre folderu remote, deci pathu si useru si hostu raman la fel, dar mai avem feature-uri aditionale pe care le putem folosi, de ex, adaugam un v la flaugu -r si avem -rv , care o sa il faca pe rsync sa ne dea output cu ce face el exact, ceea ce e de ajutor pt noi cand incercam sa facem troubleshoot la ce s-a intamplat exact in timpu deployment-ului 
-pe langa flagu r, putem folosi si flagu z care va face compress la date in timpul transferului ca sa salvam bandwidth, asta nu e neaparat necesar pt sizeu folderului nostru build, dar este un flag util despre care ar trebui sa stim 
-deci pana acuma, o sa ne asiguram ca file-urile dintr-o parte sunt uploadate de asemenea si pe partea celalata, dar mai e un feature important pe care rsync il are si acela este posibilitatea de a sterge cu optiunea --delete si asta inseamna ca ii dam lu rsync abilitatea sa steagra file-urile aflate in folderu remote pe care nu le mai avem in folderu local  
-o sa o vedem in actiune imediat sa ne asiguram ca totu merge cum ne asteptam, dam commit si ne uitam pe logu job-ului ssh_deploy si vedem ca totu e ok 
-ne uitam la output-ul comenzii rsync si vedem ca la inceput o sa stearga cateva file-uri(cele existente deja pe folderu respectiv) si apoi face upload la file-urile noastre din folderu build 
-deci ne zice exact ce se intampla in timpul procesului si ne zice cate date au fost trimise(in termeni de size) deci este un tool mult mai bun ca scp pentru a da sync la foldere si file-uri 
-daca ne uitam pe site-u nostru web vedem ca nu s-a schimbat nimic in afata de versiunea commit-ului de la Application version ca sa stim ca a avut loc un deployment nou 
-mergem pe terminalu ec2 si ne uitam la file-urile din folderu html cu comanda: $ ls -l /usr/share/nginx/html/ si vedem ca multe file-uri au disparut, deci avem numa index.html, asset-urile, vite.svg deci asta e tot ce include folderu nostru build 
-deci asta concluzioneaza introducerea noastra in rsync, normal ca mai sunt flag-uri si lucruri de stiu despre rsync, asta e doar un exemplu simplu sa vedem cum functioneaza 

Running a deployment script 

-destul de des, cand dam deploy la un server remote, am putea vrea sa folosim o combinatie intre anumite file-uri, dar si un deployment script 
-avem un script care se asteapta la un file numite build.zip si va merge prin deverse stagii de a lua acel file, sa o puna intr-un anume folder si sa verifice dupa daca deploymentu a fost de succes, acest fel de script-uri sunt foarte populare si foarte folosite in lumea devops pt a da deploy pe un server 
-acuma vrem sa vedem un approach unde putem folosi un astfel de script, dar sa dam si provide la file urile pt siteu nostru un folder de build, doar ca sa intelegem conceptu de a folosi un script, nu neaparat pt ca e required in cazu nsotru, dar ca sa demonstram un usecase basic pe aceste script-uri 
-facem un folder ci in proiectu nostru si bagam scriptu deploy.sh acolo 
-prima oara avem niste unput variables ZIP_FILE , DEST_DIR si HTTP_URL care sunt doar o configuratie generala 
-ZIP_FILE="build.zip" este efectiv folderu nostru zipuit, DEST_DIR="/usr/share/nginx/html/" este pathu unde vrem sa dam deploy pe ec2 
-la HTTP_URL trei sa punem linku de la siteu nostru(DNS name ec2): HTTP_URL="http://ec2-16-171-132-128.eu-north-1.compute.amazonaws.com"
-scriptu asta functioneaza relativ simplu, prima oara creeaza un folder temporar: TEMP_DIR=$(mktemp -d) 
-si mai departe in if verifica daca exista zip file-u si daca nu exista da eroare 
-apoi da unzip la file in folderu temporar apoi copiaza fileu in folderu de destiantie cu rsync 
-la final, curata toate file-urile care au fost implicate in procesu de extragere a informatiei si apoi face un smoke test foarte simplu sa vada daca textu GitLab poate fi folosit pe adresa si la final da echo la deployment successful 
-desi e lung, scriptu face tot ce am facut si noi pana acuma cu comenzile scp si rsync dar contine verificari si mesaje de eroare in plus si ar trebui sa ofere in general o experienta de deployment mai ok daca ceva nu merge cum ne am asteptat 

-sa vedem cum putem aduce scriptu asta in pipeline-ul nostru, cum putem uploada un zip file si de asemenea si scriptu asta de deploy pe un server remote si apoi sa executam un deployment script 
-in comanda rsync din pipeline, o sa folosim scp, ii stergem flag urile si optiunile si o sa uploadam fileu numit build.zip si scriptu deploy.sh, ii copiem pathu relativ ci/deploy.sh si cu comanda scp putem uploada doua file-uri deodata, nu trei sa rulam doua comenzi separate una dupa alta:      
-inainte cand am folosit scp, am folosit un folder temporar pt upload-uri, dar in general, ar trebui sa evitam sa folosim foldere temporare pt deployment-uri si ideal ar trebui sa folosim un folder unde avem full control 
-nu vrem sa uploadam deploy.sh script sau build.zip direct in folderu user/share/nginx/html pt ca vor fi accesibile public si nu vrem asta 
-dar, in loc, o sa-i dam upload in folderu user. Folosim ~ care e o scrutatura care o sa fie expandata intr-un path full care ne duce in home directory-ul nostru ca un user numit ec2-user si dupa ~ punem /deploy , deci comanda o sa arate asa:
  - scp build.zip ci/deploy.sh $REMOTE_DEPLOY_USER@$REMOTE_DEPLOY_HOST:~/deploy 
-putem da deploy direct in folderu deploy care o sa fie in folderu nostru home, peste care avem control 100% si exact asta vrem 
-tre sa creeam fileu zip inainte de comanda scp astfel:
  - zip -r build.zip build/       // build.zip o sa se numeasca arhiva care va contine folderu build/ 
-acuma trei sa dam efectiv trigger la deployment, pt asta ne vom folosi comanda ssh dupa cea de scp pt ca trei sa rulam niste comenzi 
-in primu rand trei sa intram in folderu deploy, deci scriem "cd ~/deploy" cu care vom intra in folderu deploy din home folderu nostru 
-acuma ca sa putem face un script executabil(deploy.sh) trei sa il facem executabil cu comanda:
  chmod +x deploy.sh 
-dupa ce l-am facut executabil, ca sa il rulam scriem comanda: ./deploy.sh  
- ./ este referinta catre folderu curent si daca nu scriem comanda asa, scriptu deploy.sh nu va fi executat, deci comanda finala o sa arate asa:
  - ssh build.zip ci/deploy.sh $REMOTE_DEPLOY_USER@$REMOTE_DEPLOY_HOST "cd ~/deploy; chmod +x deploy.sh; ./deploy.sh"
-dam commit la schimbari si sa vedem asta in actiune si primim eroare ca nu e found zipu, noi incercam sa zipuim acest folder dar nu avem zip instalat ca nu e disponibil in imagine alpine 
-deci mergem in before script si in comanda apk add punem si zip dupa rsync si vedem ca acuma merge traba 
-facem un recap:
-in primu rand am creeat un build zip file dupa care cu scp am uploadat-o impreuna cu deploy.sh script, care da unzip la acest build folder si il copiaza intr-un folder temporar, de unde extragem efectiv continuturile folderului build, stergandu-l pe asta, deci vom avea infolderu tmp2dask321 doar strict continutu folderului build caruia ii dam sync in folderu destinatie a lu nginx /usr/share/nginx/html/ si stergem ce era acolo de al deployment-uri trecute sau altcv in plus fata de ce avem acuma in folderu build 
-dupa ce copiem build.zip si deploy.sh in folderu deploy din home/ec2-user, executam cateva comenzi: mergem in folderu deploy si facem deploy.sh executabil ca apoi sa il executam si sa faca tot ce am zis mai sus, adica sa dea unzip si sa bage tot in folderu default pt nginx 
-vedem outputu din comanda ssh adica efectiv ce face deploy.sh: face unzip, copiaza file-urile cu rsync, curata file-urile temporare, ruleaza comanda curl sa faca smoke testu care o sa fie ok si Deployment successful 
-deci asa putem sa executam un deployment script pe care l-am scris si sa il rulam undeva remote 